{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ef8813",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable_baselines3\n",
    "!pip install gymnasium\n",
    "!pip install torch\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install finta\n",
    "!pip install mplfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "# from stable_baselines3.common.callbacks import LearningRateSchedule\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from stable_baselines3.common.utils import get_schedule_fn\n",
    "import json\n",
    "\n",
    "def linear_schedule(start_lr = 3e-4, end_lr = 1e-5, total_timesteps=1e6):\n",
    "    lr_schedule = get_schedule_fn(1e-4)  # For constant LR\n",
    "    # OR for decaying LR:\n",
    "    lr_schedule = lambda progress: start_lr - (start_lr - end_lr) * progress\n",
    "    return lr_schedule\n",
    "\n",
    "lr_schedule = linear_schedule(3e-4, 1e-5, total_timesteps=1e6)\n",
    "print(lr_schedule(0))     # 0.0003 ထွက်လာမယ် (start_lr)\n",
    "print(lr_schedule(0.5))   # 0.00015 လောက် ထွက်လာမယ် (အလယ်မှာ)\n",
    "print(lr_schedule(1))     # 0.00001 ထွက်လာမယ် (end_lr)\n",
    "\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-based model for time series data.\n",
    "    This class projects input features to an embedding, adds positional\n",
    "    encodings, and then processes the inputs using a Transformer encoder.\n",
    "    Finally, a decoder layer is used to produce the output.\n",
    "    Args:\n",
    "        input_size (int): Number of features in the input time series data.\n",
    "        embed_dim (int): Dimensionality of the learned embedding space.\n",
    "        num_heads (int): Number of attention heads in each Transformer layer.\n",
    "        num_layers (int): Number of Transformer encoder layers.\n",
    "        sequence_length (int): Length of the input sequences (time steps).\n",
    "        dropout (float, optional): Dropout probability to apply in the\n",
    "            Transformer encoder layers. Defaults to 0.1.\n",
    "    Attributes:\n",
    "        model_type (str): Identifier for the model type ('Transformer').\n",
    "        embedding (nn.Linear): Linear layer for input feature embedding.\n",
    "        positional_encoding (torch.nn.Parameter): Parameter storing the\n",
    "            positional encodings used to retain temporal information.\n",
    "        transformer_encoder (nn.TransformerEncoder): Stack of Transformer\n",
    "            encoder layers with optional final LayerNorm.\n",
    "        decoder (nn.Linear): Linear layer used to produce the final output\n",
    "            dimensions.\n",
    "    Forward Inputs:\n",
    "        src (torch.Tensor): Input tensor of shape (batch_size, sequence_length,\n",
    "            input_size).\n",
    "    Forward Returns:\n",
    "        torch.Tensor: Output tensor of shape (batch_size, embed_dim) from the\n",
    "            last time step.\n",
    "    Raises:\n",
    "        ValueError: If the model output contains NaN or Inf values, indicating\n",
    "            numerical instability.\n",
    "    \"\"\"\n",
    "    # input_size: Input features အရေအတွက် (ဥပမာ 10၊ price + SMA/RSI indicators စတာ)။\n",
    "    # embed_dim: Internal embedding အတိုင်းအတာ (ဥပမာ 64၊ data ကို ပိုနက်ရှိုင်း အောင် ပြောင်း)။\n",
    "    # num_heads: Attention heads အရေအတွက် (multi-head attention အတွက်၊ မတူညီ အနေနဲ့ အာရုံ စိုက်)။\n",
    "    # num_layers: Encoder layers အရေအတွက် (ဥပမာ 2၊ ရိုးရှင်း ထားတာ)။\n",
    "    # sequence_length: Input sequence အရှည် (ဥပမာ 20 timesteps)။\n",
    "    # dropout=0.1: Overfitting ကနေ ကာကွယ် တဲ့ dropout rate။\n",
    "    def __init__(self, input_size, embed_dim, num_heads, num_layers,sequence_length, dropout=0.1):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Embedding layer to project input features to embed_dim dimensions\n",
    "        self.embedding = nn.Linear(input_size, embed_dim).to(device)\n",
    "\n",
    "        # Positional encoding parameter\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, sequence_length, embed_dim).to(device))\n",
    "\n",
    "        # Transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dropout=dropout,\n",
    "            norm_first=True  # Apply LayerNorm before attention and feedforward\n",
    "        ).to(device)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "            norm=nn.LayerNorm(embed_dim).to(device) # Add LayerNorm at the end of the encoder\n",
    "        )\n",
    "\n",
    "        # Decoder layer to produce final output\n",
    "        self.decoder = nn.Linear(embed_dim, embed_dim).to(device)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # Apply embedding layer and add positional encoding\n",
    "        src = self.embedding(src) + self.positional_encoding\n",
    "\n",
    "        # Pass through the transformer encoder\n",
    "        output = self.transformer_encoder(src)\n",
    "\n",
    "        # Pass through the decoder layer\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        # Check for NaN or Inf values for debugging\n",
    "        if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "            logger.error(\"Transformer output contains NaN or Inf values\")\n",
    "            raise ValueError(\"Transformer output contains NaN or Inf values\")\n",
    "\n",
    "        # Return the output from the last time step\n",
    "        return output[:, -1, :]\n",
    "    \n",
    "    \n",
    "# Test\n",
    "input_size = 10\n",
    "embed_dim = 64\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "sequence_length = 20\n",
    "\n",
    "model = TimeSeriesTransformer(input_size, embed_dim, num_heads, num_layers, sequence_length)\n",
    "\n",
    "# Dummy input\n",
    "dummy_input = torch.randn(1, sequence_length, input_size).to(device)  # <-- ဒီနေရာ ထည့်ပါ!\n",
    "\n",
    "output = model(dummy_input)\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Sample output:\", output[0][:5])\n",
    "\n",
    "\n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    A custom feature extractor that normalizes input observations and processes them\n",
    "    using a transformer-based architecture for dimensionality reduction and enhanced\n",
    "    feature representation.\n",
    "    Parameters:\n",
    "        observation_space (gym.spaces.Box): Defines the shape and limits of input data.\n",
    "        sequence_length (int): The length of the time series to be processed.\n",
    "    Attributes:\n",
    "        layernorm_before (nn.LayerNorm): Normalizes input data to improve training stability.\n",
    "        transformer (TimeSeriesTransformer): Processes normalized input sequences and extracts features.\n",
    "    Methods:\n",
    "        forward(observations):\n",
    "            Applies layer normalization to the incoming observations, then passes them\n",
    "            through the transformer. Raises a ValueError if invalid values (NaNs or inf)\n",
    "            are detected in the output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Box, sequence_length):\n",
    "        super(CustomCombinedExtractor, self).__init__(observation_space, features_dim=64)\n",
    "        num_features = observation_space.shape[1]  # Should be 10 in this case\n",
    "\n",
    "        # Ensure that embed_dim is divisible by num_heads\n",
    "        embed_dim = 64\n",
    "        num_heads = 2\n",
    "\n",
    "        self.layernorm_before = nn.LayerNorm(num_features) # Added Layer Normalization before transformer\n",
    "\n",
    "        self.transformer = TimeSeriesTransformer(\n",
    "            input_size=num_features,\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            num_layers=2,\n",
    "            sequence_length =sequence_length\n",
    "        )\n",
    "\n",
    "    def forward(self, observations):\n",
    "        # မူရင်း input tensor ရဲ့ device ကို မှတ်သားထားပါ\n",
    "        input_device = observations.device\n",
    "\n",
    "        # Apply layer normalization\n",
    "        # Apply layer normalization, ဝင်လာတဲ့ observations ကို Transformer ရဲ့ device ပေါ်ကို ရွှေ့ပါ\n",
    "        normalized_observations = self.layernorm_before(observations.float().to(device)) # Ensure float type\n",
    "\n",
    "        x = self.transformer(normalized_observations)\n",
    "        if torch.isnan(x).any() or torch.isinf(x).any():\n",
    "            logger.error(\"Invalid values in transformer output\")\n",
    "            raise ValueError(\"Invalid values in transformer output\")\n",
    "\n",
    "        # ⚠️ ပြင်ဆင်ချက်: Output tensor ကို မူရင်း input tensor ရဲ့ device သို့ ပြန်ပို့ပါ\n",
    "        # PPO Agent ရဲ့ Policy/Value Network က အလုပ်လုပ်တဲ့ device ပေါ်ကို ပြန်ပို့ဖို့ လိုပါတယ်။\n",
    "        # သို့သော်လည်း၊ Stable-Baselines3 က Policy/Value Network ကို နောက်ပိုင်းမှာ to(device) နဲ့ ရွှေ့တဲ့အတွက်\n",
    "        # ဒီနေရာမှာ အန္တရာယ်ကင်းအောင် မူရင်း input device ကို ပြန်ပို့တာ ဒါမှမဟုတ် Agent သုံးမယ့် device ပေါ်မှာပဲ ထားတာ နှစ်မျိုး လုပ်နိုင်ပါတယ်။\n",
    "        # အကောင်းဆုံးကတော့ Policy Network တွေက GPU ပေါ်မှာရှိရင် GPU မှာပဲ ထားခဲ့တာပါ။\n",
    "\n",
    "        # သို့သော်လည်း၊ SB3 ရဲ့ စံနှုန်းကို လိုက်နာဖို့၊ CPU ပေါ်ကလာရင် CPU ကို ပြန်ပို့တာ ပိုကောင်းပါတယ်။\n",
    "        if str(input_device) == 'cpu':\n",
    "            return x.to(input_device)\n",
    "        else:\n",
    "             # Agent က GPU မှာ Run ရင်တော့ GPU မှာပဲ ထားခဲ့ပါ\n",
    "            return x\n",
    "\n",
    "\n",
    "# Test\n",
    "observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(20, 10), dtype=np.float32)\n",
    "extractor = CustomCombinedExtractor(observation_space, sequence_length=20)\n",
    "extractor.to(device)  # <-- ဒီနေရာ ထည့်ပါ! Model ကို GPU ကို ရွှေ့ရန်\n",
    "\n",
    "# Dummy input\n",
    "dummy_observations = torch.randn(1, 20, 10)\n",
    "\n",
    "output = extractor(dummy_observations)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Sample output:\", output[0][:5])\n",
    "\n",
    "class EnvConfig():\n",
    "    \"\"\"environment configuration from json file\n",
    "       tgym requires you configure your own parameters in json file.\n",
    "        Args:\n",
    "            config_file path/file.json\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,config_file):\n",
    "        self.config = {}\n",
    "        with open(config_file) as j:\n",
    "            self.config = json.load(j)\n",
    "\n",
    "    def env_parameters(self,item=''):\n",
    "        \"\"\"environment variables\n",
    "        \"\"\"\n",
    "        if item:\n",
    "            return self.config[\"env\"][item]\n",
    "        else:\n",
    "            return self.config[\"env\"]\n",
    "\n",
    "    def symbol(self, asset=\"GBPUSD\", item='') :\n",
    "        \"\"\"get trading pair (symbol) information\n",
    "\n",
    "        Args:\n",
    "            asset (str, optional): symbol in config. Defaults to \"GBPUSD\".\n",
    "            item (str, optional): name of item, if '' return dict, else return item value. Defaults to ''.\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        if item:\n",
    "            return self.config[\"symbol\"][asset][item]\n",
    "        else:\n",
    "            return self.config[\"symbol\"][asset]\n",
    "\n",
    "    def data_processing_parameters(self, item=''):\n",
    "        \"\"\"Get data processing config\"\"\"\n",
    "        if item:\n",
    "            return self.config[\"data_processing\"][item]\n",
    "        return self.config[\"data_processing\"]\n",
    "\n",
    "    def trading_hour(self,place=\"New York\"):\n",
    "        \"\"\"forex trading hour from different markets\n",
    "\n",
    "        Args:\n",
    "            place (str, optional): [Sydney,Tokyo,London] Defaults to \"New York\".\n",
    "\n",
    "        Returns:\n",
    "            [dict]: from time, to time\n",
    "        \"\"\"\n",
    "        if place:\n",
    "            return self.config[\"trading_hour\"][place]\n",
    "        else:\n",
    "            return self.config[\"trading_hour\"]\n",
    "        \n",
    "        \n",
    "env_config_file = '/content/drive/MyDrive/configure.json'\n",
    "cf = EnvConfig(env_config_file)\n",
    "\n",
    "print(cf.env_parameters('indicator_period'))\n",
    "\n",
    "split_cfg = cf.data_processing_parameters(\"train_eval_split\")\n",
    "print(split_cfg)\n",
    "\n",
    "asset = \"GBPUSD\"\n",
    "base_path = split_cfg[\"base_path\"].format(symbol=asset)\n",
    "print(base_path)\n",
    "\n",
    "csv_file = f\"{base_path}/{split_cfg[\"train_dir\"]}/{asset}_2022_22.csv\"\n",
    "print(csv_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571b546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e44ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
