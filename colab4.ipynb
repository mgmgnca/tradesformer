{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "09bb9bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def convert_1m_to_5m_df(file_path: str) -> pd.DataFrame:\n",
    "    # Column Names (·Äû·ÄÑ·Ä∑·Ä∫·Äõ·Ä≤·Ä∑ Data ·Ä°·ÄÖ·ÄÆ·Ä°·ÄÖ·Äâ·Ä∫·Ä°·Äê·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏)\n",
    "    COLUMN_NAMES = ['Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    DATETIME_FORMAT = '%Y.%m.%d %H:%M'\n",
    "\n",
    "    \"\"\" CSV File ·Äô·Äæ 1-Minute Data ·ÄÄ·Ä≠·ÄØ Load ·Äï·Äº·ÄÆ·Ä∏ 5-Minute Candle ·Äû·Ä≠·ÄØ·Ä∑ ·Äï·Äº·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏·Äú·Ä≤·Äû·Ää·Ä∫·Åã \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"üö® Error: File not found at path: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep=',', header=None, names=COLUMN_NAMES,\n",
    "                         dtype={'Open': np.float64, 'High': np.float64, 'Low': np.float64, 'Close': np.float64})\n",
    "        \n",
    "        # Volume column ·ÄÄ·Ä≠·ÄØ ·Äö·Ä¨·Äö·ÄÆ float ·Ä°·Äî·Ä±·Äñ·Äº·ÄÑ·Ä∑·Ä∫ ·Äû·Äê·Ä∫·Äô·Äæ·Äê·Ä∫·Äï·Äº·ÄÆ·Ä∏ NA ·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ 0 ·Äñ·Äº·ÄÑ·Ä∑·Ä∫ ·Ä°·ÄÖ·Ä¨·Ä∏·Äë·Ä≠·ÄØ·Ä∏·Äû·Ää·Ä∫·Åã\n",
    "        df['Volume'] = pd.to_numeric(df['Volume'], errors='coerce').fillna(0)\n",
    "        df['Volume'] = df['Volume'].astype(np.int64) \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üö® Error loading CSV file: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Datetime Index ·ÄÄ·Ä≠·ÄØ ·Äê·Ää·Ä∫·ÄÜ·Ä±·Ä¨·ÄÄ·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏\n",
    "    df['Datetime'] = df['Date'].astype(str) + ' ' + df['Time'].astype(str)\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'], format=DATETIME_FORMAT, errors='coerce')\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "    df.drop(columns=['Date', 'Time'], inplace=True)\n",
    "    #df.dropna(subset=[df.index.name], inplace=True) # Invalid Datetime ·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Äñ·Äö·Ä∫·Äõ·Äæ·Ä¨·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏\n",
    "\n",
    "    ohlcv_aggregation_rules: Dict[str, Any] = {\n",
    "        'Open': 'first', 'High': 'max', 'Low': 'min', 'Close': 'last', 'Volume': 'sum'\n",
    "    }\n",
    "    df = df.resample('5Min').agg(ohlcv_aggregation_rules)\n",
    "    df.dropna(inplace=True)\n",
    "    df = df[df['Volume'] > 0]\n",
    "    \n",
    "    print(f\"‚úÖ Conversion successful! 5-Min rows: {len(df)}\")\n",
    "    return df.reset_index().rename(columns={'index': 'Datetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "058ad0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conversion successful! 5-Min rows: 149715\n"
     ]
    }
   ],
   "source": [
    "file_path_from_data = \"./content/drive/MyDrive/data/raw/EURUSD_2020_all.csv\"\n",
    "file_path_to_data = \"./content/drive/MyDrive/data/raw/EURUSD_2020_all_5.csv\"\n",
    "\n",
    "raw = convert_1m_to_5m_df(file_path_from_data)\n",
    "raw.to_csv(file_path_to_data, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0be379fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class EnvConfig():\n",
    "    \"\"\"environment configuration from json file\n",
    "       tgym requires you configure your own parameters in json file.\n",
    "        Args:\n",
    "            config_file path/file.json\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,config_file):\n",
    "        self.config = {}\n",
    "        with open(config_file) as j:\n",
    "            self.config = json.load(j)\n",
    "\n",
    "    def env_parameters(self,item=''):\n",
    "        \"\"\"environment variables\n",
    "        \"\"\"\n",
    "        if item:\n",
    "            return self.config[\"env\"][item]\n",
    "        else:\n",
    "            return self.config[\"env\"]\n",
    "\n",
    "    def symbol(self, asset=\"GBPUSD\", item='') :\n",
    "        \"\"\"get trading pair (symbol) information\n",
    "\n",
    "        Args:\n",
    "            asset (str, optional): symbol in config. Defaults to \"GBPUSD\".\n",
    "            item (str, optional): name of item, if '' return dict, else return item value. Defaults to ''.\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        if item:\n",
    "            return self.config[\"symbol\"][asset][item]\n",
    "        else:\n",
    "            return self.config[\"symbol\"][asset]\n",
    "\n",
    "    def data_processing_parameters(self, item=''):\n",
    "        \"\"\"Get data processing config\"\"\"\n",
    "        if item:\n",
    "            return self.config[\"data_processing\"][item]\n",
    "        return self.config[\"data_processing\"]\n",
    "\n",
    "    def trading_hour(self,place=\"NewYork\"):\n",
    "        \"\"\"forex trading hour from different markets\n",
    "\n",
    "        Args:\n",
    "            place (str, optional): [Sydney,Tokyo,London] Defaults to \"New York\".\n",
    "\n",
    "        Returns:\n",
    "            [dict]: from time, to time\n",
    "        \"\"\"\n",
    "        if place:\n",
    "            return self.config[\"trading_hour\"][place]\n",
    "        else:\n",
    "            return self.config[\"trading_hour\"]\n",
    "\n",
    "    def indicator(self,place=\"sma_fast_period\"):\n",
    "        \"\"\"forex trading hour from different markets\n",
    "\n",
    "        Args:\n",
    "            place (str, optional): [Sydney,Tokyo,London] Defaults to \"New York\".\n",
    "\n",
    "        Returns:\n",
    "            [dict]: from time, to time\n",
    "        \"\"\"\n",
    "        if place:\n",
    "            return self.config[\"data_processing\"][\"indicator\"][place]\n",
    "        else:\n",
    "            return self.config[\"data_processing\"][\"indicator\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b69f8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import logging\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def patch_missing_data(df, dt_col_name='time', cf=None):\n",
    "    min_bars = cf.data_processing_parameters(\"min_bars_per_week\")\n",
    "\n",
    "    # [\"time\",\"open\", \"high\", \"low\", \"close\"]\n",
    "    required_cols = cf.data_processing_parameters(\"required_cols\")\n",
    "\n",
    "    # df ·Äô·Äæ·Ä¨ 6 columns ·Äõ·Äæ·Ä≠·Äõ·ÄÑ·Ä∫ vol ·Äï·Ä´·Äë·Ää·Ä∑·Ä∫·Äô·Äö·Ä∫\n",
    "    if df.shape[1] == 6:\n",
    "        df.columns = required_cols + ['Volume']\n",
    "    elif df.shape[1] == 5:\n",
    "        df.columns = required_cols\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid number of columns: {df.shape[1]} =>{required_cols}\")\n",
    "\n",
    "    logger.warning(f\"shape of  column: {df.shape[1]}\")\n",
    "    # 1. Column validation\n",
    "    if missing := set(required_cols) - set(df.columns):\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    # 2. Auto-detect datetime column\n",
    "    dt_candidates = {'time', 'timestamp', 'date', 'datetime', 'Datetime'}\n",
    "    if dt_col_name not in df.columns:\n",
    "        found = list(dt_candidates & set(df.columns))\n",
    "        if not found:\n",
    "            raise KeyError(f\"No datetime column found. Tried: {dt_candidates}\")\n",
    "        dt_col_name = found[0]\n",
    "        logger.info(f\"Using datetime column: {dt_col_name}\")\n",
    "\n",
    "    # 3. Convert to datetime index\n",
    "    df[dt_col_name] = pd.to_datetime(df[dt_col_name], utc=True)\n",
    "    df = df.set_index(dt_col_name).sort_index()\n",
    "    groups = df.groupby(pd.Grouper(freq='W-SUN'))\n",
    "\n",
    "    patched_weeks = []  # patched weekly df storage\n",
    "\n",
    "    for w, week_df in groups:\n",
    "        if week_df.empty:\n",
    "            continue\n",
    "\n",
    "        if len(week_df) != min_bars:\n",
    "            logger.warning(f\"Week {w} has {len(week_df)}/{min_bars} bars\")\n",
    "\n",
    "        # Create 5-minute frequency index\n",
    "        new_index = pd.date_range(\n",
    "            start=week_df.index.min(),\n",
    "            end=week_df.index.max(),\n",
    "            freq='5min',\n",
    "            tz='UTC'\n",
    "        )\n",
    "\n",
    "        # Reindex + forward fill\n",
    "        week_df = week_df.reindex(new_index)\n",
    "        week_df.index = week_df.index.tz_localize(None)\n",
    "        fill_limit = 12 # ·Ä•·Äï·Äô·Ä¨: 1 ·Äî·Ä¨·Äõ·ÄÆ (12 bars) ·Äë·ÄÄ·Ä∫·Äï·Ä≠·ÄØ·Äê·Ä≤·Ä∑ ·ÄÄ·ÄΩ·ÄÄ·Ä∫·Äú·Äï·Ä∫·ÄÄ·Ä≠·ÄØ ·Äô·Äñ·Äº·Ää·Ä∑·Ä∫·Äï·Ä´\n",
    "        fill_cols = ['open', 'high', 'low', 'close', 'vol'] if 'vol' in df.columns else ['open', 'high', 'low', 'close']\n",
    "        # FFill: ·Äõ·Äæ·Ä±·Ä∑·ÄÄ data ·Äñ·Äº·ÄÑ·Ä∑·Ä∫ ·Äñ·Äº·Ää·Ä∑·Ä∫·Äï·Ä´\n",
    "        week_df[fill_cols] = week_df[fill_cols].ffill(limit=fill_limit)\n",
    "        patched_weeks.append(week_df)\n",
    "\n",
    "    # Merge back all weeks\n",
    "    if patched_weeks:\n",
    "        all_df = pd.concat(patched_weeks)\n",
    "    else:\n",
    "        all_df = df.copy()\n",
    "\n",
    "    return all_df.reset_index().rename(columns={'index': 'Datetime'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f7607077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "shape of  column: 6\n",
      "Week 2020-01-05 00:00:00+00:00 has 576/1440 bars\n",
      "Week 2020-01-12 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2020-03-29 00:00:00+00:00 has 1433/1440 bars\n",
      "Week 2020-09-20 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2020-10-04 00:00:00+00:00 has 1436/1440 bars\n",
      "Week 2020-12-27 00:00:00+00:00 has 1152/1440 bars\n",
      "Week 2021-01-03 00:00:00+00:00 has 1142/1440 bars\n",
      "Week 2021-05-23 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2021-05-30 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2021-06-06 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2021-09-19 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2021-10-10 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2021-12-12 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2021-12-26 00:00:00+00:00 has 1438/1440 bars\n",
      "Week 2022-01-02 00:00:00+00:00 has 1428/1440 bars\n"
     ]
    }
   ],
   "source": [
    "cf = EnvConfig('./content/drive/MyDrive/configure.json')\n",
    "raw = pd.read_csv(file_path_to_data)\n",
    "df = patch_missing_data(raw,cf=cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0e0f30d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149734</th>\n",
       "      <td>2021-12-31 23:45:00</td>\n",
       "      <td>1.13780</td>\n",
       "      <td>1.13801</td>\n",
       "      <td>1.13764</td>\n",
       "      <td>1.13795</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149735</th>\n",
       "      <td>2021-12-31 23:50:00</td>\n",
       "      <td>1.13796</td>\n",
       "      <td>1.13823</td>\n",
       "      <td>1.13778</td>\n",
       "      <td>1.13780</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149736</th>\n",
       "      <td>2021-12-31 23:55:00</td>\n",
       "      <td>1.13780</td>\n",
       "      <td>1.13781</td>\n",
       "      <td>1.13650</td>\n",
       "      <td>1.13660</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Datetime     open     high      low    close  Volume\n",
       "149734 2021-12-31 23:45:00  1.13780  1.13801  1.13764  1.13795   172.0\n",
       "149735 2021-12-31 23:50:00  1.13796  1.13823  1.13778  1.13780   216.0\n",
       "149736 2021-12-31 23:55:00  1.13780  1.13781  1.13650  1.13660   210.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "be70eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_feature(df_5m: pd.DataFrame, cf=None, source_tz='UTC') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    5M Data Frame (DatetimeIndex ·Äï·Ä´·Äù·ÄÑ·Ä∫·Äû·Ää·Ä∫·Äü·ÄØ ·Äö·Ä∞·ÄÜ·Äï·Ä´) ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ Temporal features ·Äë·Ää·Ä∑·Ä∫·Äû·ÄΩ·ÄÑ·Ä∫·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏·Åã\n",
    "    \"\"\"\n",
    "    # üß≠ Ensure datetime index\n",
    "    if not isinstance(df_5m.index, pd.DatetimeIndex):\n",
    "        if 'Datetime' in df_5m.columns:\n",
    "            df_5m['Datetime'] = pd.to_datetime(df_5m['Datetime'])\n",
    "            df_5m = df_5m.set_index('Datetime')\n",
    "        else:\n",
    "            raise ValueError(\"DataFrame must have datetime index or 'time' column\")\n",
    "\n",
    "    # DataFrame ·Åè Index ·ÄÄ·Ä≠·ÄØ DatetimeIndex ·Ä°·Äñ·Äº·ÄÖ·Ä∫ ·ÄÖ·ÄÖ·Ä∫·ÄÜ·Ä±·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏\n",
    "    if not isinstance(df_5m.index, pd.DatetimeIndex):\n",
    "         raise TypeError(\"DataFrame ·Åè Index ·Äû·Ää·Ä∫ DatetimeIndex ·Äñ·Äº·ÄÖ·Ä∫·Äõ·Äï·Ä´·Äô·Ää·Ä∫·Åã\")\n",
    "\n",
    "    df_5m.index = df_5m.index.tz_localize(None)\n",
    "    # Index ·ÄÄ·Ä≠·ÄØ Timezone aware (UTC) ·Ä°·Äñ·Äº·ÄÖ·Ä∫ ·Äû·Ä±·ÄÅ·Äª·Ä¨·Ä°·Ä±·Ä¨·ÄÑ·Ä∫·Äú·ÄØ·Äï·Ä∫·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏\n",
    "    if df_5m.index.tz is None:\n",
    "        # Timezone-Naive data ·ÄÄ·Ä≠·ÄØ ·Äô·Ä∞·Äõ·ÄÑ·Ä∫·Ä∏ Source Timezone ·Äñ·Äº·ÄÑ·Ä∑·Ä∫ localize\n",
    "        # Dukascopy data ·ÄÜ·Ä≠·ÄØ·Äõ·ÄÑ·Ä∫ 'UTC' ·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄÆ·Ä∏·Åä Broker data ·ÄÜ·Ä≠·ÄØ·Äõ·ÄÑ·Ä∫ 'GMT+3' ·Äú·Ä≠·ÄØ·Äô·Äª·Ä≠·ÄØ·Ä∏ ·Äû·ÄØ·Ä∂·Ä∏·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äï·Ä´·Äê·Äö·Ä∫\n",
    "        df = df_5m.tz_localize(source_tz, ambiguous='NaT', nonexistent='NaT')\n",
    "        df = df.tz_convert('UTC')\n",
    "    else:\n",
    "        df = df_5m.copy()\n",
    "    \n",
    "    # ----------------------------------------------------\n",
    "    # I. ·Ä°·ÄÅ·Äº·Ä±·ÄÅ·Ä∂ features ·Äî·Äæ·ÄÑ·Ä∑·Ä∫ Cyclical Encoding ·Äô·Äª·Ä¨·Ä∏ (Hour ·ÄÄ·Ä≠·ÄØ Index ·Äô·Äæ ·Äê·Ä≠·ÄØ·ÄÄ·Ä∫·Äõ·Ä≠·ÄØ·ÄÄ·Ä∫·Äö·Ä∞·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏)\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    # df['weekday'] = df.index.dayofweek \n",
    "    # df['day'] = df.index.day\n",
    "    # df['week'] = df.index.isocalendar().week.astype(int)\n",
    "    # df['month'] = df.index.month\n",
    "    # df['year'] = df.index.year\n",
    "    df['hour'] = df.index.hour\n",
    "    \n",
    "    # ·Äî·Ä¨·Äõ·ÄÆ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ Cyclical features\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24).round(6)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24).round(6)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # III. DST-Aware Market Sessions (Timezone Handling)\n",
    "    # ----------------------------------------------------\n",
    "    \n",
    "    # ·Äî·Ä¨·Äõ·ÄÆ·ÄÄ·Ä≠·ÄØ local time zone ·Äû·Ä≠·ÄØ·Ä∑ ·Äï·Äº·Ä±·Ä¨·ÄÑ·Ä∫·Ä∏·Äú·Ä≤ (Timezone Aware Index ·Äô·Äæ·Äû·Ä¨ tz_convert ·Äú·ÄØ·Äï·Ä∫·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äû·Ää·Ä∫)\n",
    "    london_time = df.index.tz_convert('Europe/London')\n",
    "    ny_time = df.index.tz_convert('America/New_York')\n",
    "\n",
    "    # Session Hours (cf ·Äô·Äæ Local Time ·Äî·Ä¨·Äõ·ÄÆ·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Äï·Ä±·Ä∏·Äï·Ä≠·ÄØ·Ä∑·Äõ·Äï·Ä´·Äô·Ää·Ä∫·Åã)\n",
    "    ny = cf.trading_hour('NewYork')\n",
    "    ldn = cf.trading_hour('London')\n",
    "\n",
    "    # London Session (Local Time: 08:00 - 16:00)\n",
    "    df['london_session'] = ((london_time.hour >= ldn['from']) & (london_time.hour < ldn['to'])).astype(int)\n",
    "    \n",
    "    # NY Session (Local Time: 13:00 - 21:00 UTC/GMT) -> (9:00 - 17:00 EST/EDT)\n",
    "    # cf ·Äô·Äæ Local NY Time (·Ä•·Äï·Äô·Ä¨: 9, 17) ·ÄÄ·Ä≠·ÄØ ·Äï·Ä±·Ä∏·Äï·Ä≠·ÄØ·Ä∑·Äõ·Äô·Ää·Ä∫\n",
    "    df['ny_session'] = ((ny_time.hour >= ny['from']) & (ny_time.hour < ny['to'])).astype(int)\n",
    "\n",
    "    df['overlap_session'] = (df['london_session'] & df['ny_session']).astype(int)\n",
    "\n",
    "    # ... (IV. Holiday features ·ÄÄ·Ä≠·ÄØ ·ÄÜ·ÄÄ·Ä∫·Äú·ÄÄ·Ä∫·Äë·Ää·Ä∑·Ä∫·Äû·ÄΩ·ÄÑ·Ä∫·Ä∏·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Äû·Ää·Ä∫) ...\n",
    "    \n",
    "    #df['symbol'] = symbol\n",
    "    \n",
    "    # ·Äö·Ä¨·Äö·ÄÆ columns ·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Äñ·Äö·Ä∫·Äõ·Äæ·Ä¨·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏\n",
    "    df = df.drop(columns=['hour'], errors='ignore') # minute_block_15 ·Äû·Ää·Ä∫ 1M data ·Äô·Äæ ·Äú·Ä¨·Äú·Äª·Äæ·ÄÑ·Ä∫·Äû·Ä¨ ·Äú·Ä≠·ÄØ·Ä°·Äï·Ä∫·Äû·Ää·Ä∫·Åã 5M ·Äê·ÄΩ·ÄÑ·Ä∫ ·Äô·Äú·Ä≠·ÄØ·Ä°·Äï·Ä∫·Äï·Ä´·Åã\n",
    "    \n",
    "    # Index ·ÄÄ·Ä≠·ÄØ reset ·Äô·Äú·ÄØ·Äï·Ä∫·Äò·Ä≤ ·Äï·Äº·Äî·Ä∫·Äï·Ä≠·ÄØ·Ä∑·Äï·Ä´ (Env ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ Datetime Index ·Äú·Ä≠·ÄØ·Ä°·Äï·Ä∫·Äû·Ää·Ä∫)\n",
    "    return df.reset_index().rename(columns={'index': 'Datetime'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "131d2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broker Data (00:00 ·Äô·Äæ ·ÄÖ·Äû·Ä±·Ä¨) ·ÄÄ·Ä≠·ÄØ ·ÄÅ·Ä±·Ä´·Ä∫·ÄÜ·Ä≠·ÄØ·Äû·Ää·Ä∑·Ä∫·Ä°·ÄÅ·Ä´\n",
    "# GMT+2/GMT+3 ·ÄÄ·Ä≠·ÄØ ·Ä°·Äú·Ä≠·ÄØ·Ä°·Äú·Äª·Ä±·Ä¨·ÄÄ·Ä∫ ·ÄÄ·Ä≠·ÄØ·ÄÑ·Ä∫·Äê·ÄΩ·Äö·Ä∫·Äï·Ä±·Ä∏·Äõ·Äî·Ä∫\n",
    "axiory_tz = 'Europe/Kiev'  \n",
    "\n",
    "dft = add_time_feature(df, cf=cf, source_tz=axiory_tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "001bb550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>london_session</th>\n",
       "      <th>ny_session</th>\n",
       "      <th>overlap_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 22:00:00+00:00</td>\n",
       "      <td>1.12117</td>\n",
       "      <td>1.12128</td>\n",
       "      <td>1.12087</td>\n",
       "      <td>1.12114</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 22:05:00+00:00</td>\n",
       "      <td>1.12117</td>\n",
       "      <td>1.12124</td>\n",
       "      <td>1.12103</td>\n",
       "      <td>1.12103</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime     open     high      low    close  Volume  \\\n",
       "0 2020-01-01 22:00:00+00:00  1.12117  1.12128  1.12087  1.12114    31.0   \n",
       "1 2020-01-01 22:05:00+00:00  1.12117  1.12124  1.12103  1.12103    44.0   \n",
       "\n",
       "   hour_sin  hour_cos  london_session  ny_session  overlap_session  \n",
       "0      -0.5  0.866025               0           0                0  \n",
       "1      -0.5  0.866025               0           0                0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "623a2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.to_csv('dft.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2c67d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finta import TA\n",
    "\n",
    "def tech_indicators(df, cf=None):\n",
    "    \"\"\"\n",
    "    Forex RL ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ Price Action·Åä Momentum ·Äî·Äæ·ÄÑ·Ä∑·Ä∫ Long-Term Trend Features ·Äô·Äª·Ä¨·Ä∏·ÄÄ·Ä≠·ÄØ ·Äë·Ää·Ä∑·Ä∫·Äû·ÄΩ·ÄÑ·Ä∫·Ä∏·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏·Åã\n",
    "    \"\"\"\n",
    "    price   =   df['close']\n",
    "    sma_fast_period = cf.indicator('sma_fast_period')\n",
    "    sma_mid_period = cf.indicator('sma_mid_period')\n",
    "    sma_slow_period = cf.indicator('sma_slow_period')\n",
    "    atr_period = cf.indicator('atr_period')\n",
    "    rsi_period = cf.indicator('rsi_period')\n",
    "    \n",
    "    df['fast_ma'] = TA.SMA(df, period=sma_fast_period)\n",
    "    df['mid_ma'] = TA.SMA(df, period=sma_mid_period)\n",
    "    df['slow_ma'] = TA.SMA(df, period=sma_slow_period)\n",
    "    df['rsi'] = TA.RSI(df, period=rsi_period).ffill().round(6)\n",
    "    \n",
    "    # trend strength\n",
    "    df['fast_ts']  =   (price - df['fast_ma']) / df['fast_ma']\n",
    "    df['mid_ts']  =   (price - df['mid_ma']) / df['mid_ma']\n",
    "    df['slow_ts']  =   (price - df['slow_ma']) / df['slow_ma']\n",
    "\n",
    "    df['fast_td'] = np.sign(df['fast_ts'])\n",
    "    df['mid_td'] = np.sign(df['mid_ts'])\n",
    "    df['slow_td'] = np.sign(df['slow_ts'])\n",
    "\n",
    "    df['fast_mid_gap'] = (df['fast_ma'] - df['mid_ma']) / df['mid_ma']\n",
    "    df['mid_slow_gap'] = (df['mid_ma'] - df['slow_ma']) / df['slow_ma']\n",
    "    df['fast_slow_gap'] = (df['fast_ma'] - df['slow_ma']) / df['slow_ma']\n",
    "\n",
    "    # --- ·ÅÅ·Åã Volatility Measure (ATR ·ÄÄ·Ä≠·ÄØ Base ·Ä°·Äñ·Äº·ÄÖ·Ä∫ ·Ä°·Äû·ÄØ·Ä∂·Ä∏·Äï·Äº·ÄØ·Äõ·Äî·Ä∫) ---\n",
    "    df['atr_base'] = TA.ATR(df, period=atr_period).ffill()\n",
    "    df['atr_norm'] = df['atr_base'] / price\n",
    "\n",
    "    window=100\n",
    "    df['low_thr'] = df['atr_norm'].rolling(window).quantile(0.33)\n",
    "    df['high_thr'] = df['atr_norm'].rolling(window).quantile(0.66)\n",
    "\n",
    "    # Volatility categories (one-hot)\n",
    "    df['vol_low'] = (df['atr_norm'] < df['low_thr']).astype(int)\n",
    "    df['vol_med'] = ((df['atr_norm'] >= df['low_thr']) &\n",
    "                    (df['atr_norm'] < df['high_thr'])).astype(int)\n",
    "    df['vol_high'] = (df['atr_norm'] >= df['high_thr']).astype(int)\n",
    "\n",
    "    # Momentum\n",
    "    df['momentum_score'] = (df['rsi'] - 50) / 50\n",
    "    # RSI categories one-hot\n",
    "    df['mom_bearish'] = (df['rsi'] < 45).astype(int)\n",
    "    df['mom_neutral'] = ((df['rsi'] >= 45) & (df['rsi'] <= 55)).astype(int)\n",
    "    df['mom_bullish'] = (df['rsi'] > 55).astype(int)\n",
    "\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f6d6c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('dft.csv')\n",
    "dfi = tech_indicators(dft, cf=cf)\n",
    "dfi.to_csv('dfi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d96e18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>london_session</th>\n",
       "      <th>ny_session</th>\n",
       "      <th>...</th>\n",
       "      <th>atr_norm</th>\n",
       "      <th>low_thr</th>\n",
       "      <th>high_thr</th>\n",
       "      <th>vol_low</th>\n",
       "      <th>vol_med</th>\n",
       "      <th>vol_high</th>\n",
       "      <th>momentum_score</th>\n",
       "      <th>mom_bearish</th>\n",
       "      <th>mom_neutral</th>\n",
       "      <th>mom_bullish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2020-01-02 14:35:00+00:00</td>\n",
       "      <td>1.11767</td>\n",
       "      <td>1.11802</td>\n",
       "      <td>1.11767</td>\n",
       "      <td>1.11780</td>\n",
       "      <td>518.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.434099</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2020-01-02 14:40:00+00:00</td>\n",
       "      <td>1.11780</td>\n",
       "      <td>1.11781</td>\n",
       "      <td>1.11712</td>\n",
       "      <td>1.11725</td>\n",
       "      <td>496.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.536659</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2020-01-02 14:45:00+00:00</td>\n",
       "      <td>1.11727</td>\n",
       "      <td>1.11746</td>\n",
       "      <td>1.11712</td>\n",
       "      <td>1.11727</td>\n",
       "      <td>506.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.525830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime     open     high      low    close  Volume  \\\n",
       "199  2020-01-02 14:35:00+00:00  1.11767  1.11802  1.11767  1.11780   518.0   \n",
       "200  2020-01-02 14:40:00+00:00  1.11780  1.11781  1.11712  1.11725   496.0   \n",
       "201  2020-01-02 14:45:00+00:00  1.11727  1.11746  1.11712  1.11727   506.0   \n",
       "\n",
       "     hour_sin  hour_cos  london_session  ny_session  ...  atr_norm   low_thr  \\\n",
       "199      -0.5 -0.866025               1           1  ...  0.000370  0.000224   \n",
       "200      -0.5 -0.866025               1           1  ...  0.000393  0.000229   \n",
       "201      -0.5 -0.866025               1           1  ...  0.000393  0.000232   \n",
       "\n",
       "     high_thr  vol_low  vol_med  vol_high  momentum_score  mom_bearish  \\\n",
       "199  0.000272        0        0         1       -0.434099            1   \n",
       "200  0.000273        0        0         1       -0.536659            1   \n",
       "201  0.000276        0        0         1       -0.525830            1   \n",
       "\n",
       "     mom_neutral  mom_bullish  \n",
       "199            0            0  \n",
       "200            0            0  \n",
       "201            0            0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8ca80191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_news_features(df: pd.DataFrame, news_df: pd.DataFrame, window_pre=30, window_post=30):\n",
    "    # üß≠ Ensure datetime index\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        if 'Datetime' in df.columns:\n",
    "            df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "            df = df.set_index('Datetime')\n",
    "        else:\n",
    "            raise ValueError(\"DataFrame must have datetime index or 'time' column\")\n",
    "\n",
    "    \n",
    "    df['pre_news'] = 0.0\n",
    "    df['post_news'] = 0.0\n",
    "    news_df['Start'] = pd.to_datetime(news_df['Start'], utc=True)\n",
    "\n",
    "    for _, row in news_df.iterrows():\n",
    "        news_time  = row['Start']\n",
    "        pre_mask = (df.index >= news_time - pd.Timedelta(minutes=window_pre)) & (df.index < news_time)\n",
    "\n",
    "        if pre_mask.any():\n",
    "            minutes_to_news = (news_time - df.index[pre_mask]).total_seconds() / 60\n",
    "            df.loc[pre_mask, 'pre_news'] = 1 - (minutes_to_news / window_pre)\n",
    "\n",
    "        # --- Post-news: 1 ‚Üí 0 decay ---\n",
    "        post_mask = (df.index > news_time) & (df.index <= news_time + pd.Timedelta(minutes=window_post))\n",
    "        if post_mask.any():\n",
    "            minutes_after_news = (df.index[post_mask] - news_time).total_seconds() / 60\n",
    "            df.loc[post_mask, 'post_news'] = 1 - (minutes_after_news / window_post)\n",
    "\n",
    "\n",
    "        # --- News candle itself ---\n",
    "        exact_mask = (df.index == news_time)\n",
    "        if exact_mask.any():\n",
    "            df.loc[exact_mask, ['pre_news', 'post_news']] = 1.0\n",
    "            \n",
    "    df['pre_news'] = df['pre_news'].clip(0, 1)\n",
    "    df['post_news'] = df['post_news'].clip(0, 1)\n",
    "    # Index ·ÄÄ·Ä≠·ÄØ reset ·Äô·Äú·ÄØ·Äï·Ä∫·Äò·Ä≤ ·Äï·Äº·Äî·Ä∫·Äï·Ä≠·ÄØ·Ä∑·Äï·Ä´ (Env ·Ä°·Äê·ÄΩ·ÄÄ·Ä∫ Datetime Index ·Äú·Ä≠·ÄØ·Ä°·Äï·Ä∫·Äû·Ää·Ä∫)\n",
    "    return df.reset_index().rename(columns={'index': 'Datetime'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d4331cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"calendar-event-list.csv\")\n",
    "dfi = pd.read_csv(\"dfi.csv\")\n",
    "\n",
    "dfn = add_news_features(dfi, news, window_pre=30, window_post=30)\n",
    "dfn.to_csv('dfn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51585ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
