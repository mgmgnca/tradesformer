{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1286df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable_baselines3\n",
    "!pip install gymnasium\n",
    "!pip install torch\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install finta\n",
    "!pip install mplfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed29983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import logging\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "# from stable_baselines3.common.callbacks import LearningRateSchedule\n",
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def linear_schedule(start_lr=3e-4, end_lr=1e-5):\n",
    "     # ဤသည်မှာ မှန်ကန်သော Decay Logic ဖြစ်ပါသည်။\n",
    "     return lambda progress_remaining: end_lr + (start_lr - end_lr) * progress_remaining\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-based model for time series data.\n",
    "    This class projects input features to an embedding, adds positional\n",
    "    encodings, and then processes the inputs using a Transformer encoder.\n",
    "    Finally, a decoder layer is used to produce the output.\n",
    "    Args:\n",
    "        input_size (int): Number of features in the input time series data.\n",
    "        embed_dim (int): Dimensionality of the learned embedding space.\n",
    "        num_heads (int): Number of attention heads in each Transformer layer.\n",
    "        num_layers (int): Number of Transformer encoder layers.\n",
    "        sequence_length (int): Length of the input sequences (time steps).\n",
    "        dropout (float, optional): Dropout probability to apply in the\n",
    "            Transformer encoder layers. Defaults to 0.1.\n",
    "    Attributes:\n",
    "        model_type (str): Identifier for the model type ('Transformer').\n",
    "        embedding (nn.Linear): Linear layer for input feature embedding.\n",
    "        positional_encoding (torch.nn.Parameter): Parameter storing the\n",
    "            positional encodings used to retain temporal information.\n",
    "        transformer_encoder (nn.TransformerEncoder): Stack of Transformer\n",
    "            encoder layers with optional final LayerNorm.\n",
    "        decoder (nn.Linear): Linear layer used to produce the final output\n",
    "            dimensions.\n",
    "    Forward Inputs:\n",
    "        src (torch.Tensor): Input tensor of shape (batch_size, sequence_length,\n",
    "            input_size).\n",
    "    Forward Returns:\n",
    "        torch.Tensor: Output tensor of shape (batch_size, embed_dim) from the\n",
    "            last time step.\n",
    "    Raises:\n",
    "        ValueError: If the model output contains NaN or Inf values, indicating\n",
    "            numerical instability.\n",
    "    \"\"\"\n",
    "    # input_size: Input features အရေအတွက် (ဥပမာ 10၊ price + SMA/RSI indicators စတာ)။\n",
    "    # embed_dim: Internal embedding အတိုင်းအတာ (ဥပမာ 64၊ data ကို ပိုနက်ရှိုင်း အောင် ပြောင်း)။\n",
    "    # num_heads: Attention heads အရေအတွက် (multi-head attention အတွက်၊ မတူညီ အနေနဲ့ အာရုံ စိုက်)။\n",
    "    # num_layers: Encoder layers အရေအတွက် (ဥပမာ 2၊ ရိုးရှင်း ထားတာ)။\n",
    "    # sequence_length: Input sequence အရှည် (ဥပမာ 20 timesteps)။\n",
    "    # dropout=0.1: Overfitting ကနေ ကာကွယ် တဲ့ dropout rate။\n",
    "    def __init__(self, input_size, embed_dim, num_heads, num_layers,sequence_length, dropout=0.1):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Embedding layer to project input features to embed_dim dimensions\n",
    "        self.embedding = nn.Linear(input_size, embed_dim).to(device)\n",
    "\n",
    "        # Positional encoding parameter\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, sequence_length, embed_dim).to(device))\n",
    "\n",
    "        # Transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dropout=dropout,\n",
    "            norm_first=True  # Apply LayerNorm before attention and feedforward\n",
    "        ).to(device)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "            norm=nn.LayerNorm(embed_dim).to(device) # Add LayerNorm at the end of the encoder\n",
    "        )\n",
    "\n",
    "        # Decoder layer to produce final output\n",
    "        self.decoder = nn.Linear(embed_dim, embed_dim).to(device)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # Apply embedding layer and add positional encoding\n",
    "        src = self.embedding(src) + self.positional_encoding\n",
    "\n",
    "        # Pass through the transformer encoder\n",
    "        output = self.transformer_encoder(src)\n",
    "\n",
    "        # Pass through the decoder layer\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        # Check for NaN or Inf values for debugging\n",
    "        if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "            logger.error(\"Transformer output contains NaN or Inf values\")\n",
    "            raise ValueError(\"Transformer output contains NaN or Inf values\")\n",
    "\n",
    "        # Return the output from the last time step\n",
    "        return output[:, -1, :]\n",
    "\n",
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    A custom feature extractor that normalizes input observations and processes them\n",
    "    using a transformer-based architecture for dimensionality reduction and enhanced\n",
    "    feature representation.\n",
    "    Parameters:\n",
    "        observation_space (gym.spaces.Box): Defines the shape and limits of input data.\n",
    "        sequence_length (int): The length of the time series to be processed.\n",
    "    Attributes:\n",
    "        layernorm_before (nn.LayerNorm): Normalizes input data to improve training stability.\n",
    "        transformer (TimeSeriesTransformer): Processes normalized input sequences and extracts features.\n",
    "    Methods:\n",
    "        forward(observations):\n",
    "            Applies layer normalization to the incoming observations, then passes them\n",
    "            through the transformer. Raises a ValueError if invalid values (NaNs or inf)\n",
    "            are detected in the output.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Box, sequence_length):\n",
    "        super(CustomCombinedExtractor, self).__init__(observation_space, features_dim=64)\n",
    "        num_features = observation_space.shape[1]  # Should be 10 in this case\n",
    "\n",
    "        # Ensure that embed_dim is divisible by num_heads\n",
    "        embed_dim = 64\n",
    "        num_heads = 2\n",
    "\n",
    "        self.layernorm_before = nn.LayerNorm(num_features) # Added Layer Normalization before transformer\n",
    "\n",
    "        self.transformer = TimeSeriesTransformer(\n",
    "            input_size=num_features,\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            num_layers=2,\n",
    "            sequence_length =sequence_length\n",
    "        )\n",
    "\n",
    "    def forward(self, observations):\n",
    "        # မူရင်း input tensor ရဲ့ device ကို မှတ်သားထားပါ\n",
    "        input_device = observations.device\n",
    "\n",
    "        # Apply layer normalization\n",
    "        # Apply layer normalization, ဝင်လာတဲ့ observations ကို Transformer ရဲ့ device ပေါ်ကို ရွှေ့ပါ\n",
    "        normalized_observations = self.layernorm_before(observations.float().to(device)) # Ensure float type\n",
    "\n",
    "        x = self.transformer(normalized_observations)\n",
    "        if torch.isnan(x).any() or torch.isinf(x).any():\n",
    "            logger.error(\"Invalid values in transformer output\")\n",
    "            raise ValueError(\"Invalid values in transformer output\")\n",
    "\n",
    "        # ⚠️ ပြင်ဆင်ချက်: Output tensor ကို မူရင်း input tensor ရဲ့ device သို့ ပြန်ပို့ပါ\n",
    "        # PPO Agent ရဲ့ Policy/Value Network က အလုပ်လုပ်တဲ့ device ပေါ်ကို ပြန်ပို့ဖို့ လိုပါတယ်။\n",
    "        # သို့သော်လည်း၊ Stable-Baselines3 က Policy/Value Network ကို နောက်ပိုင်းမှာ to(device) နဲ့ ရွှေ့တဲ့အတွက်\n",
    "        # ဒီနေရာမှာ အန္တရာယ်ကင်းအောင် မူရင်း input device ကို ပြန်ပို့တာ ဒါမှမဟုတ် Agent သုံးမယ့် device ပေါ်မှာပဲ ထားတာ နှစ်မျိုး လုပ်နိုင်ပါတယ်။\n",
    "        # အကောင်းဆုံးကတော့ Policy Network တွေက GPU ပေါ်မှာရှိရင် GPU မှာပဲ ထားခဲ့တာပါ။\n",
    "\n",
    "        # သို့သော်လည်း၊ SB3 ရဲ့ စံနှုန်းကို လိုက်နာဖို့၊ CPU ပေါ်ကလာရင် CPU ကို ပြန်ပို့တာ ပိုကောင်းပါတယ်။\n",
    "        if str(input_device) == 'cpu':\n",
    "            return x.to(input_device)\n",
    "        else:\n",
    "             # Agent က GPU မှာ Run ရင်တော့ GPU မှာပဲ ထားခဲ့ပါ\n",
    "            return x\n",
    "\n",
    "class EnvConfig():\n",
    "    \"\"\"environment configuration from json file\n",
    "       tgym requires you configure your own parameters in json file.\n",
    "        Args:\n",
    "            config_file path/file.json\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,config_file):\n",
    "        self.config = {}\n",
    "        with open(config_file) as j:\n",
    "            self.config = json.load(j)\n",
    "\n",
    "    def env_parameters(self,item=''):\n",
    "        \"\"\"environment variables\n",
    "        \"\"\"\n",
    "        if item:\n",
    "            return self.config[\"env\"][item]\n",
    "        else:\n",
    "            return self.config[\"env\"]\n",
    "\n",
    "    def symbol(self, asset=\"GBPUSD\", item='') :\n",
    "        \"\"\"get trading pair (symbol) information\n",
    "\n",
    "        Args:\n",
    "            asset (str, optional): symbol in config. Defaults to \"GBPUSD\".\n",
    "            item (str, optional): name of item, if '' return dict, else return item value. Defaults to ''.\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        if item:\n",
    "            return self.config[\"symbol\"][asset][item]\n",
    "        else:\n",
    "            return self.config[\"symbol\"][asset]\n",
    "\n",
    "    def data_processing_parameters(self, item=''):\n",
    "        \"\"\"Get data processing config\"\"\"\n",
    "        if item:\n",
    "            return self.config[\"data_processing\"][item]\n",
    "        return self.config[\"data_processing\"]\n",
    "\n",
    "    def trading_hour(self,place=\"New York\"):\n",
    "        \"\"\"forex trading hour from different markets\n",
    "\n",
    "        Args:\n",
    "            place (str, optional): [Sydney,Tokyo,London] Defaults to \"New York\".\n",
    "\n",
    "        Returns:\n",
    "            [dict]: from time, to time\n",
    "        \"\"\"\n",
    "        if place:\n",
    "            return self.config[\"trading_hour\"][place]\n",
    "        else:\n",
    "            return self.config[\"trading_hour\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fda80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from finta import TA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def patch_missing_data(df, dt_col_name='time', cf=None):\n",
    "    min_bars = cf.data_processing_parameters(\"min_bars_per_week\")\n",
    "\n",
    "    # [\"time\",\"open\", \"high\", \"low\", \"close\"]\n",
    "    required_cols = cf.data_processing_parameters(\"required_cols\")\n",
    "\n",
    "    # df မှာ 6 columns ရှိရင် vol ပါထည့်မယ်\n",
    "    if df.shape[1] == 6:\n",
    "        df.columns = required_cols + ['vol']\n",
    "    elif df.shape[1] == 5:\n",
    "        df.columns = required_cols\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid number of columns: {df.shape[1]} =>{required_cols}\")\n",
    "\n",
    "    logger.warning(f\"shape of  column: {df.shape[1]}\")\n",
    "    # 1. Column validation\n",
    "    if missing := set(required_cols) - set(df.columns):\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    # 2. Auto-detect datetime column\n",
    "    dt_candidates = {'time', 'timestamp', 'date', 'datetime'}\n",
    "    if dt_col_name not in df.columns:\n",
    "        found = list(dt_candidates & set(df.columns))\n",
    "        if not found:\n",
    "            raise KeyError(f\"No datetime column found. Tried: {dt_candidates}\")\n",
    "        dt_col_name = found[0]\n",
    "        logger.info(f\"Using datetime column: {dt_col_name}\")\n",
    "\n",
    "    # 3. Convert to datetime index\n",
    "    df[dt_col_name] = pd.to_datetime(df[dt_col_name], utc=True)\n",
    "    df = df.set_index(dt_col_name).sort_index()\n",
    "\n",
    "    # Week by Week Group (Friday-end week)\n",
    "    groups = df.groupby(pd.Grouper(freq='W-FRI'))\n",
    "\n",
    "    patched_weeks = []  # patched weekly df storage\n",
    "\n",
    "    for w, week_df in groups:\n",
    "        if week_df.empty:\n",
    "            continue\n",
    "\n",
    "        if len(week_df) != min_bars:\n",
    "            logger.warning(f\"Week {w} has {len(week_df)}/{min_bars} bars\")\n",
    "\n",
    "        # Create 5-minute frequency index\n",
    "        new_index = pd.date_range(\n",
    "            start=week_df.index.min(),\n",
    "            end=week_df.index.max(),\n",
    "            freq='5min',\n",
    "            tz='UTC'\n",
    "        )\n",
    "\n",
    "        # Reindex + forward fill\n",
    "        week_df = week_df.reindex(new_index)\n",
    "        fill_limit = 12 # ဥပမာ: 1 နာရီ (12 bars) ထက်ပိုတဲ့ ကွက်လပ်ကို မဖြည့်ပါ\n",
    "        fill_cols = ['open', 'high', 'low', 'close', 'vol'] if 'vol' in df.columns else ['open', 'high', 'low', 'close']\n",
    "        # FFill: ရှေ့က data ဖြင့် ဖြည့်ပါ\n",
    "        week_df[fill_cols] = week_df[fill_cols].ffill(limit=fill_limit)\n",
    "        patched_weeks.append(week_df)\n",
    "\n",
    "    # Merge back all weeks\n",
    "    if patched_weeks:\n",
    "        all_df = pd.concat(patched_weeks)\n",
    "    else:\n",
    "        all_df = df.copy()\n",
    "\n",
    "    return all_df.reset_index().rename(columns={'index': dt_col_name})\n",
    "\n",
    "\n",
    "def add_time_feature(df, symbol):\n",
    "    \"\"\"Add temporal features with proper index handling\"\"\"\n",
    "\n",
    "    if 'time' not in df.columns:\n",
    "        raise KeyError(\"'time' column missing after patch_missing_data\")\n",
    "\n",
    "    df = df.set_index('time')\n",
    "    df.index = pd.to_datetime(df.index, utc=True)\n",
    "\n",
    "    # Cyclical time features\n",
    "    df['weekday'] = df.index.dayofweek  # 0=Monday\n",
    "    df['day'] = df.index.day\n",
    "    df['week'] = df.index.isocalendar().week\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['hour'] = df.index.hour\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24).round(6)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24).round(6)\n",
    "    df['minute_block'] = df.index.minute // 5  # 0-11\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute_block']/12).round(6)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute_block']/12).round(6)\n",
    "\n",
    "    # Market sessions (GMT)\n",
    "    df['london_session'] = ((df['hour'] >= 8) & (df['hour'] < 16)).astype(int)\n",
    "    df['ny_session'] = ((df['hour'] >= 13) & (df['hour'] < 21)).astype(int)\n",
    "    df['overlap_session'] = ((df['hour'] >= 13) & (df['hour'] < 16)).astype(int)\n",
    "\n",
    "    df['symbol'] = symbol\n",
    "    return df.reset_index()\n",
    "\n",
    "def tech_indicators(df, cf=None):  # 288 = 24hrs in 5-min bars\n",
    "    \"\"\"Calculate technical indicators with proper NaN handling\"\"\"\n",
    "    period = cf.data_processing_parameters(\"indicator_period\")\n",
    "    # 1. Preserve raw prices before normalization\n",
    "    raw_cols = ['mean_std_open','mean_std_high','mean_std_low','mean_std_close']\n",
    "    df[raw_cols] = df[['open','high','low','close']].copy()\n",
    "    # Calculate indicators\n",
    "    df['macd'] = TA.MACD(df).SIGNAL.ffill().round(6)\n",
    "    bb = TA.BBANDS(df)\n",
    "    df['boll_ub'] = bb['BB_UPPER'].ffill()\n",
    "    df['boll_lb'] = bb['BB_LOWER'].ffill()\n",
    "\n",
    "    df['rsi_30'] = TA.RSI(df, period=period).ffill()\n",
    "    df['dx_30'] = TA.ADX(df, period=period).ffill()\n",
    "    df['close_30_sma'] = TA.SMA(df, period=period).ffill()\n",
    "    df['close_60_sma'] = TA.SMA(df, period=period*2).ffill()\n",
    "    df['atr'] = TA.ATR(df, period=period).ffill()\n",
    "     # Add returns and volatility ratio\n",
    "    df['returns_5'] = df['close'].pct_change(5,fill_method=None).round(6)\n",
    "    df['returns_24'] = df['close'].pct_change(24,fill_method=None).round(6)\n",
    "    df['volatility_ratio'] = (df['high'] - df['low']) / df['close'].round(6)\n",
    "\n",
    "    # Normalize\n",
    "    scaler = StandardScaler()\n",
    "    scale_cols = cf.data_processing_parameters(\"scale_cols\")\n",
    "\n",
    "    df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    # 1. Identify numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    # 2. Apply clipping only to numeric features\n",
    "    df[numeric_cols] = df[numeric_cols].clip(lower=-1e5, upper=1e5)\n",
    "    # 3. Round decimal values\n",
    "    df[numeric_cols] = df[numeric_cols].round(6).clip(-1e5, 1e5)\n",
    "    return df\n",
    "class TimeSeriesScaler:\n",
    "    \"\"\"\n",
    "    Manages the MinMax Scaling process for time series features.\n",
    "    It fits the scaler on the first chunk of data (expected to be the training start)\n",
    "    and uses that fitted scaler to transform all subsequent data chunks (including eval).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # MinMaxScaler ကို အသုံးပြုပြီး 0 နဲ့ 1 ကြားကို ပြောင်းပါ\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.is_fitted = False\n",
    "        self.price_cols = ['mean_std_open', 'mean_std_high', 'mean_std_low', 'mean_std_close']\n",
    "\n",
    "    def fit_and_transform(self, df):\n",
    "        \"\"\"Fit the scaler on the data and transform it.\"\"\"\n",
    "        logger.info(\"Fitting Scaler on current week data (TRAIN set base)\")\n",
    "        # .copy() လုပ်ပြီးမှ transform လုပ်ပါ\n",
    "        df_copy = df.copy()\n",
    "        df_copy[self.price_cols] = self.scaler.fit_transform(df_copy[self.price_cols])\n",
    "        self.is_fitted = True\n",
    "        return df_copy\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"Transform data using the previously fitted scaler.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Scaler must be fitted on the training data first!\")\n",
    "\n",
    "        logger.info(\"Transforming current week data using fitted scaler.\")\n",
    "        # .copy() လုပ်ပြီးမှ transform လုပ်ပါ\n",
    "        df_copy = df.copy()\n",
    "        df_copy[self.price_cols] = self.scaler.transform(df_copy[self.price_cols])\n",
    "        return df_copy\n",
    "\n",
    "\n",
    "def split_time_series_v2(df, symbol='EURUSD', cf=None, scaler_manager=None):\n",
    "    \"\"\"\n",
    "    Split data with weekly alignment, adds a lookback context (overlap) from the\n",
    "    previous week for continuous sequence processing (e.g., Transformer),\n",
    "    and performs MinMax scaling.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Time Series Data.\n",
    "        freq (str): Frequency string for pandas Grouper (e.g., 'W-FRI' for weekly split ending Friday).\n",
    "        symbol (str): Trading symbol.\n",
    "        cf (object): Configuration manager.\n",
    "        scaler_manager (object): TimeSeriesScaler instance.\n",
    "        sequence_length (int): The lookback window size needed for the Transformer.\n",
    "    \"\"\"\n",
    "    if scaler_manager is None:\n",
    "        raise ValueError(\"scaler_manager (TimeSeriesScaler instance) must be provided.\")\n",
    "\n",
    "    split_cfg = cf.data_processing_parameters(\"train_eval_split\")\n",
    "    base_path = split_cfg[\"base_path\"].format(symbol=symbol)\n",
    "\n",
    "    sequence_length = cf.data_processing_parameters(\"sequence_length\")\n",
    "\n",
    "    # Align with Forex week (Monday-Friday/Sunday)\n",
    "    # df['time'] သည် ဤနေရာတွင် datetime object ဖြစ်ရမည်။\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "        df = df.set_index('time')\n",
    "    elif not pd.api.types.is_datetime64_any_dtype(df.index):\n",
    "        raise ValueError(\"DataFrame must have a 'time' column or a datetime index.\")\n",
    "\n",
    "    # W-FRI သည် သောကြာနေ့တွင် အဆုံးသတ်သော အပတ်ကို ကိုယ်စားပြုသည်။\n",
    "    groups = df.groupby(pd.Grouper(freq='W-FRI'))\n",
    "\n",
    "    # Indicators columns\n",
    "    indicator_cols = ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'atr']\n",
    "\n",
    "\n",
    "    prev_week_df = None # ယခင် Week ရဲ့ DataFrame အပြည့်အစုံကို သိမ်းဆည်းရန်\n",
    "\n",
    "    # Loop စတင်ခြင်း\n",
    "    for week_start, week_df in groups:\n",
    "        if week_df.empty:\n",
    "            continue\n",
    "\n",
    "        # 1. Context (Overlap Data) ကို ဆုံးဖြတ်ခြင်း\n",
    "        # [NEW ACTION] ယခင် Week ရဲ့ နောက်ဆုံး sequence_length စာရှိတဲ့ data ကို ဖြတ်ယူပြီး ကပ်ပါ\n",
    "        context_df = pd.DataFrame()\n",
    "        if prev_week_df is not None:\n",
    "            # နောက်ဆုံး sequence_length စာ rows ကို ဖြတ်ယူပါ\n",
    "            # NOTE: Index Slicing မှန်စေရန် .iloc ကို အသုံးပြုပါ\n",
    "            context_df = prev_week_df.iloc[-sequence_length:].copy()\n",
    "\n",
    "        # [NEW ACTION] လက်ရှိ week_df နဲ့ Context ကို ပေါင်းစပ်ခြင်း\n",
    "        # Concat လုပ်ရာတွင် index ကို ဆက်ထိန်းထားရပါမည် (ignore_index=False)\n",
    "        # Context သည် week_df ၏ ရှေ့တွင် ရှိရမည်\n",
    "        current_chunk = pd.concat([context_df, week_df])\n",
    "\n",
    "        # 2. Check raw indicators to determine Eval set (Data Leakage မဖြစ်စေရန်)\n",
    "        # Check လုပ်ရာတွင် context မပါသော week_df ကိုသာ အသုံးပြုသင့်သည်၊ သို့မဟုတ်\n",
    "        # context မပါသော ပထမဆုံး row ကိုသာ အသုံးပြုသင့်သည်။\n",
    "        first_row = week_df[indicator_cols].iloc[0] # week_df (context မပါ) ကိုသာ စစ်ဆေး\n",
    "        has_nan = first_row.isna().any()\n",
    "        has_zero = (first_row == 0).any()\n",
    "        is_eval = has_nan or has_zero # Indicator များ မပြည့်စုံသေးသော အပတ်ကို Eval အဖြစ် သတ်မှတ်\n",
    "\n",
    "        # # Data အရေအတွက် စစ်ဆေးခြင်း (1440 bars per week)\n",
    "        # if len(week_df) < 1440: # Context ပါသော current_chunk ကို စစ်ဆေးရန် မလို\n",
    "        #     logger.warning(f\"Skipping {week_start}: {len(week_df)}/{1440} bars (original week)\")\n",
    "        #     continue\n",
    "\n",
    "        # 3. Normalize and validate (Fit-Transform Logic)\n",
    "        if not scaler_manager.is_fitted and not is_eval:\n",
    "            # Scaler ကို ပထမဆုံးသော၊ Indicators ပြည့်စုံသော (is_eval=False) Training Set တွင် Fit လုပ်ပါ\n",
    "            # [ACTION] Fit လုပ်ပြီး Transform လုပ်မည့် data မှာ Context ပါဝင်ရန် မလို၊ Original Data ကိုသာ Fit လုပ်ရမည်\n",
    "            # [ACTION] Fit လုပ်ပြီး Transform လုပ်မည့် data မှာ Context မပါဝင်ရန်\n",
    "            week_df_transformed = scaler_manager.fit_and_transform(current_chunk) # Context ပါသော chunk ကို Transform\n",
    "            dir_type = 'train'\n",
    "        elif scaler_manager.is_fitted:\n",
    "            # Scaler Fit ပြီးပါက၊ Train နှင့် Eval နှစ်ခုလုံးကို Transform လုပ်ပါ\n",
    "            # [ACTION] Context ပါသော chunk ကို Transform\n",
    "            week_df_transformed = scaler_manager.transform(current_chunk)\n",
    "            dir_type = 'eval' if is_eval else 'train'\n",
    "        else:\n",
    "            # Fit မလုပ်ရသေးဘဲ is_eval ဖြစ်နေရင် ကျော်သွားပါ\n",
    "            logger.warning(f\"Skipping {week_start}: Indicators not ready for fitting and not fitted yet.\")\n",
    "            # [ACTION] နောက်တစ်ကြိမ်အတွက် prev_week_df ကိုလည်း update လုပ်ရန် လိုအပ်သည် (မသိမ်းမီ)\n",
    "            prev_week_df = week_df.copy()\n",
    "            continue\n",
    "\n",
    "        # 4. Save to appropriate directory\n",
    "        path = os.path.join(base_path, split_cfg[f\"{dir_type}_dir\"])\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        iso_year, iso_week, _ = week_start.isocalendar()\n",
    "        fname = f\"{symbol}_{iso_year}_{iso_week:02d}.csv\"\n",
    "\n",
    "        # [ACTION] Context ပါဝင်ပြီး၊ Normalize ပြီးသော DataFrame ကိုသာ သိမ်းပါ\n",
    "        week_df_transformed.reset_index().to_csv(f\"{path}/{fname}\", index=False)\n",
    "        logger.critical(f\"Saved {dir_type} file: {fname} (Total rows: {len(week_df_transformed)})\")\n",
    "\n",
    "        # 5. လက်ရှိ week_df ကို နောက်တစ်ကြိမ်အတွက် Context အဖြစ် မှတ်သားခြင်း\n",
    "        # [ACTION] prev_week_df သည် Context မပါဝင်သေးသော Original Week Data ဖြစ်ရမည်။\n",
    "        prev_week_df = week_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'EURUSD'\n",
    "file = f'/content/drive/MyDrive/data/raw/{symbol}_M5.csv'\n",
    "# 1. Load & clean\n",
    "raw = pd.read_csv(file)\n",
    "cf = EnvConfig('/content/drive/MyDrive/configure.json')\n",
    "df = patch_missing_data(raw,cf=cf)\n",
    "# 2. Feature engineering\n",
    "df = add_time_feature(df, symbol=symbol)\n",
    "df = tech_indicators(df, cf=cf)\n",
    "\n",
    "# 3. Split & save\n",
    "# Scaler instance ကို တည်ဆောက်ပါ\n",
    "scaler_manager = TimeSeriesScaler()\n",
    "\n",
    "# Function ကို ခေါ်ပါ\n",
    "split_time_series_v2(df, symbol=symbol, cf=cf, scaler_manager=scaler_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee433a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import numpy as np\n",
    "class TrainingMetricsCallback(BaseCallback):\n",
    "    def __init__(self, check_freq=1000, verbose=1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.sharpe_ratios = []\n",
    "        self.drawdowns = []\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Track metrics only when episodes complete\n",
    "        if \"sharpe\" in self.locals['infos'][0] and \"drawdown\" in self.locals['infos'][0]:\n",
    "            self.episode_count += 1\n",
    "            self.sharpe_ratios.append(self.locals['infos'][0]['sharpe'])\n",
    "            self.drawdowns.append(self.locals['infos'][0]['drawdown'])\n",
    "\n",
    "            # Log to tensorboard every N episodes\n",
    "            if self.episode_count % 10 == 0:\n",
    "                self.logger.record('train/mean_sharpe', np.mean(self.sharpe_ratios[-10:]))\n",
    "                self.logger.record('train/max_drawdown', np.mean(self.drawdowns[-10:]))\n",
    "                self.logger.record('train/episodes', self.episode_count)\n",
    "\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f269a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_to_file(**kwargs):\n",
    "    log_header                  =   kwargs.get(\"log_header\",False)\n",
    "    log_filename                =   kwargs.get(\"log_filename\",\"\")\n",
    "    printout                    =   kwargs.get(\"printout\",False)\n",
    "    balance                     =   kwargs.get(\"balance\")\n",
    "    balance_initial             =   kwargs.get(\"balance_initial\")\n",
    "    transaction_close_this_step =   kwargs.get(\"transaction_close_this_step\",[])\n",
    "    done_information            =   kwargs.get(\"done_information\",\"\")\n",
    "    profit                      =   balance - balance_initial\n",
    "\n",
    "    tr_lines                    =   \"\"\n",
    "    tr_lines_comma              =   \"\"\n",
    "    _header                     =   \"\"\n",
    "    _header_comma               =   \"\"\n",
    "    if log_header:\n",
    "        _header = f'{\"Ticket\":>8} {\"Type\":>4} {\"ActionStep\":16} \\\n",
    "                    {\"ActionPrice\":>12} {\"CloseStep\":8} {\"ClosePrice\":>12} \\\n",
    "                    {\"OpenBal\":>12} {\"CloseBal\":>12} {\"Status\":8} {\"Info\":>8} {\"PIPS\":>6} {\"SL\":>6} {\"PT\":>6} {\"DeltaStep\":8}\\n'\n",
    "\n",
    "\n",
    "        _header_comma = f'{\"Ticket,Type,ActionTime,ActionStep,ActionPrice,CloseTime,ClosePrice, OpenBal, CloseBal, Status, Info, PIPS,SL,PT,CloseStep,DeltaStep\"}\\n'\n",
    "    if transaction_close_this_step:\n",
    "        for _tr in transaction_close_this_step:\n",
    "            if _tr[\"CloseStep\"] >=0:\n",
    "                tr_lines += f'{_tr[\"Ticket\"]:>8} {_tr[\"Type\"]:>4} {_tr[\"ActionStep\"]:16} \\\n",
    "                    {_tr[\"ActionPrice\"]:.5f} {_tr[\"CloseStep\"]:8} {_tr[\"ClosePrice\"]:.5f} \\\n",
    "                    {_tr[\"OpenBal\"]:.2f} {_tr[\"CloseBal\"]:.2f} {_tr[\"Status\"]:8}  {_tr[\"Info\"]:>8}  {_tr[\"PIPS\"]:4.0f} {_tr[\"SL\"]:4.0f} {_tr[\"PT\"]:4.0f} {_tr[\"DeltaStep\"]:8}\\n'\n",
    "\n",
    "                tr_lines_comma += f'{_tr[\"Ticket\"]},{_tr[\"Type\"]},{_tr[\"ActionTime\"]},{_tr[\"ActionStep\"]}, \\\n",
    "                    {_tr[\"ActionPrice\"]},{_tr[\"CloseTime\"]},{_tr[\"ClosePrice\"]}, \\\n",
    "                    {_tr[\"OpenBal\"]},{_tr[\"CloseBal\"]}, {_tr[\"Status\"]},{_tr[\"Info\"]},{_tr[\"PIPS\"]},{_tr[\"SL\"]},{_tr[\"PT\"]},{_tr[\"CloseStep\"]},{_tr[\"DeltaStep\"]}\\n'\n",
    "\n",
    "    log = _header_comma + tr_lines_comma\n",
    "    # log = f\"Step: {current_step}   Balance: {balance}, Profit: {profit} \\\n",
    "    #     MDD: {max_draw_down_pct}\\n{tr_lines_comma}\\n\"\n",
    "    if done_information:\n",
    "        log += done_information\n",
    "    if log:\n",
    "        # os.makedirs(log_filename, exist_ok=True)\n",
    "        dir_path = os.path.dirname(log_filename)\n",
    "        if dir_path and not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "        with open(log_filename, 'a+') as _f:\n",
    "            _f.write(log)\n",
    "            _f.close()\n",
    "\n",
    "    tr_lines = _header + tr_lines\n",
    "    if printout and tr_lines:\n",
    "        print(tr_lines)\n",
    "        if done_information:\n",
    "            print(done_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForexTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, file, cf, asset, features, sequence_length=24, logger_show=False, save_plot=False):\n",
    "        super(ForexTradingEnv, self).__init__()\n",
    "        # ကိန်းရှင်များကို စတင်သတ်မှတ်သည်။\n",
    "        self._initialize_parameters(file, cf, asset, features, sequence_length, logger_show, save_plot)\n",
    "        # Action နှင့် Observation Spaces ကို သတ်မှတ်သည်။\n",
    "        self._initialize_spaces()\n",
    "        # Environment ကို အစပြုအခြေအနေသို့ ပြန်လည်သတ်မှတ်သည်။\n",
    "        self.reset()\n",
    "\n",
    "    # ကိန်းရှင်များကို စတင်သတ်မှတ်သည်။\n",
    "    def _initialize_parameters(self, file, cf, asset, features, sequence_length, logger_show, save_plot):\n",
    "        # Params to variables\n",
    "        self.csv_file               =   file\n",
    "        self.cf                     =   cf\n",
    "        self.symbol_col             =   asset\n",
    "        self.features               =   features\n",
    "        self.sequence_length        =   sequence_length\n",
    "        self.logger_show            =   logger_show\n",
    "        self.save_plot              =   save_plot\n",
    "\n",
    "        self.data                   =   pd.read_csv(file)\n",
    "        # We use sequence transformer, so max steps will be this\n",
    "        self.max_steps              =   len(self.data) - self.sequence_length - 1\n",
    "\n",
    "        # Configs to variables\n",
    "        # Agent က Action က Continuous Action ကို Discrete Action သို့ပြောင်းပေးသော threshold\n",
    "        self.action_threshold       =   self.cf.env_parameters('action_threshold')\n",
    "        self.balance_initial        =   self.cf.env_parameters('balance')\n",
    "\n",
    "        # position close မဖြစ်သေးရင်\n",
    "        # buy ထားပြီး price up ဖြစ်နေရင် reward ပေး။ sell ထားပြီး price down ဖြစ်နေရင် reward ပေး\n",
    "        # position management မှာလည်း သုံး။\n",
    "        # buy မှာ မြတ်နေရင် tp အပေါ်ရွေ့ sl အပေါ်ရွေ့။  ရှုံးနေရင် tp အောက်ရွေ့ sl အပေါ်တင်,\n",
    "        # sell မှာ မြတ်နေရင် tp အောက်ရွေ့ sl အောက်ရွေ့။ ရှုံးနေရင် tp အပေါ်တင် sl အောက်ချ\n",
    "        self.good_position_reward_scale = self.cf.env_parameters(\"good_position_reward_scale\") # ဥပမာ: 0.01\n",
    "        # ရည်ရွယ်ချက် ၂: SL/PT Trailing အတွက် တန်ဖိုး (Move Step Size)\n",
    "        self.trailing_distance = self.cf.env_parameters(\"trailing_stop_distance_points\")\n",
    "\n",
    "        # အရှုံးနဲ့အမြတ် မျှတမှုရှိတဲ့ trading performance အတွက် ပေးတဲ့ bonus reward 0.01\n",
    "        # self.consistency_reward = self.cf.env_parameters(\"consistency_reward\")\n",
    "        self.stop_loss = self.cf.symbol(self.symbol_col, \"stop_loss_max\")\n",
    "        self.profit_taken = self.cf.symbol(self.symbol_col, \"profit_taken_max\")\n",
    "        self.point = self.cf.symbol(self.symbol_col, \"point\")\n",
    "        self.transaction_fee = self.cf.symbol(self.symbol_col, \"transaction_fee\")\n",
    "        self.over_night_penalty = self.cf.symbol(self.symbol_col, \"over_night_penalty\")\n",
    "        self.max_current_holding = self.cf.symbol(self.symbol_col, \"max_current_holding\")\n",
    "        # Drawdown Penalty Factor\n",
    "        self.drawdown_penalty_factor = self.cf.env_parameters(\"drawdown_penalty_factor\")\n",
    "        self.margin_requirement = self.cf.env_parameters('margin_requirement')\n",
    "\n",
    "\n",
    "    # Action နှင့် Observation Spaces ကို သတ်မှတ်သည်။\n",
    "    def _initialize_spaces(self):\n",
    "        # Continuous actions: [1 -> 0.5] LONG | [0.5 -> -0.5] HOLD |[-0.5 -> -1] SHORT\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1,\n",
    "            high=1,\n",
    "            shape=(1,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        # Transformer သုံးထားသော features တွေရဲ့ previous sequence length candle ကိုပါ တပြိုင်တည်းကြည့်\n",
    "        obs_shape = (self.sequence_length, len(self.features))\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=obs_shape,\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    # Environment ကို အစပြုအခြေအနေသို့ ပြန်လည်သတ်မှတ်သည်။\n",
    "    def reset(self, *, seed = None, options = None):\n",
    "        super().reset(seed=seed, options=options)\n",
    "\n",
    "        self.ticket_id          =   0\n",
    "        self.ttl_rewards        =   0 # total rewards\n",
    "\n",
    "        self.balance            =   self.balance_initial\n",
    "        self.positions          =   []\n",
    "\n",
    "        # equity tracking\n",
    "        self.equity_curve       =   [self.balance_initial] # Starting with initial balance\n",
    "        # အမြင့်ဆုံးရောက်ဖူးတဲ့ eq value\n",
    "        self.peak_equity        =   self.balance_initial # Start with initial balance as peak\n",
    "\n",
    "        self.max_drawdown       =   0.0\n",
    "        self.current_drawdown   =   0.0\n",
    "\n",
    "        # transformer အသုံးပြုထားခြင်းကြောင့်\n",
    "        self.current_step       =   self.sequence_length\n",
    "        logger.info(f\"--- Environment reset. Starting at step {self.current_step} --total rewards: {self.ttl_rewards}\")\n",
    "\n",
    "        observation             =   self._next_observation()\n",
    "        info                    =   {}\n",
    "        return  observation, info\n",
    "\n",
    "\n",
    "    # AI model အတွက် လက်ရှိ market condition ကိုကိုယ်စားပြုတဲ့ observation data ကို ပြင်ဆင်ပေးဖို့ဖြစ်ပါတယ်။\n",
    "    def _next_observation(self):\n",
    "\n",
    "        # သင့်တော်တဲ့ obs Historical Data ယူခြင်း\n",
    "        obs = self.data.iloc[\n",
    "            self.current_step - self.sequence_length: self.current_step\n",
    "        ][self.features].values\n",
    "\n",
    "        # NumPy array → PyTorch tensor ပြောင်းမယ်\n",
    "        # Data type ကို float32 လုပ်မယ်\n",
    "        # GPU/CPU device ပေါ်ကို ရွှေ့မယ်\n",
    "        obs = torch.tensor(obs, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Data Validation စစ်ဆေးခြင်း\n",
    "        # NaN (Not a Number) values ရှိမရှိစစ်မယ်\n",
    "        # Infinite values ရှိမရှိစစ်မယ်\n",
    "        # Invalid data ရှိရင် error ပြမယ်\n",
    "        if torch.isnan(obs).any() or torch.isinf(obs).any():\n",
    "            logger.error(f\"Invalid observation at step {self.current_step}\")\n",
    "            raise ValueError(f\"Invalid observation at step {self.current_step}\")\n",
    "\n",
    "        # NumPy Array ပြန်ပြောင်းခြင်း\n",
    "        # GPU memory → CPU memory ပြန်ရွှေ့မယ်\n",
    "        # PyTorch tensor → NumPy array ပြန်ပြောင်းမယ်\n",
    "        # Gym environment က NumPy arrays ကို ပိုကြိုက်တယ်။ Memory management အတွက် ကောင်းတယ်\n",
    "        return obs.cpu().numpy()  # obs\n",
    "\n",
    "\n",
    "\n",
    "    def _get_action_name(self, _action):\n",
    "        \"\"\"Convert continuous action to discrete action name\"\"\"\n",
    "        if _action >= self.action_threshold:\n",
    "            return \"BUY\"\n",
    "        elif _action <= -self.action_threshold:\n",
    "            return \"SELL\"\n",
    "        else:\n",
    "            return \"HOLD\"\n",
    "\n",
    "    def step(self, action):\n",
    "        _o, _h, _l, _c, _t, _day    =   self.data.iloc[self.current_step][['open', 'high', 'low', 'close', 'time', 'day']]\n",
    "        reward                      =   0 # ဒီ step အတွက် စုစုပေါင်း reward\n",
    "        position_reward             =   0 # Position ပိတ်ရင် ရတဲ့ reward\n",
    "        action_hold_reward          =   0 # Hold action အတွက် reward/penalty\n",
    "\n",
    "        _msg                        =   []\n",
    "        _action                     =   action[0] # action value eg. [0.75]\n",
    "        open_position               =   0\n",
    "        for position in self.positions:\n",
    "            if position['Status']   ==  0:\n",
    "                position_reward, closed, _msg   =   self._calculate_reward(position)\n",
    "                if not closed: open_position += 1  # Count what we already knew\n",
    "                reward += position_reward\n",
    "\n",
    "        # Continuous actions: [1 -> 0.5] LONG | [0.5 -> -0.5] HOLD |[-0.5 -> -1] SHORT\n",
    "        action_name = self._get_action_name(_action)\n",
    "\n",
    "        if open_position < self.max_current_holding and action_name in ['BUY', 'SELL']:\n",
    "            self.ticket_id  +=  1\n",
    "\n",
    "            # Real trading မှာ margin requirement ရှိသလိုမျိုး\n",
    "            # Position ဖွင့်ရင် capital ချုပ်ငြားနေရတယ်\n",
    "            # Position ပိတ်တဲ့အခါ ပြန်ပေါင်းထည့်ပေးတယ်\n",
    "            self.balance -= self.margin_requirement # hold up, this will make sure model can not open a lot of\n",
    "\n",
    "            position        =   {\n",
    "                \"Ticket\"        :   self.ticket_id,\n",
    "                \"Symbol\"        :   self.symbol_col,\n",
    "                \"ActionTime\"    :   _t,\n",
    "                \"Type\"          :   action_name,\n",
    "                \"Lot\"           :   1,\n",
    "                \"ActionPrice\"   :   _c,\n",
    "                \"SL\"            :   self.stop_loss,\n",
    "                \"PT\"            :   self.profit_taken,\n",
    "                \"MaxDD\"         :   0,\n",
    "                \"Swap\"          :   0.0,\n",
    "                \"CloseTime\"     :   \"\",\n",
    "                \"ClosePrice\"    :   0.0,\n",
    "                \"Point\"         :   self.point,\n",
    "                \"Reward\"        :   self.transaction_fee,\n",
    "                \"DateDuration\"  :   _day,\n",
    "                \"Status\"        :   0, # 0 is Position is currently OPEN and active\n",
    "                #\"PIPS\"          :   self.transaction_fee, # Price Interest Point (profit/loss ကို measure လုပ်တဲ့ unit)\n",
    "                \"PIPS\"          :   0,\n",
    "                \"ActionStep\"    :   self.current_step,\n",
    "                \"CloseStep\"     :   -1, # Step number when position closed, not close yet is -1\n",
    "                \"DeltaStep\"     :   0,\n",
    "                \"OpenBal\"       :   self.balance,\n",
    "                \"CloseBal\"       :   0,\n",
    "                \"HighestPrice\"  :   _c,\n",
    "                \"LowestPrice\"   :   _c,\n",
    "            }\n",
    "\n",
    "            self.positions.append(position)\n",
    "            # do not use transaction_fee penalty\n",
    "            # reward = self.transaction_fee #open cost\n",
    "            # model က အလွန်အကျွံ position တွေ မဖွင့်မိအောင် ထိန်းချုပ်တဲ့ mechanism ဖြစ်ပါတယ်။\n",
    "            _msg.append(f'Step:{self.current_step} Tkt:{position[\"Ticket\"]} {position[\"Type\"]} Rwd:{position[\"PIPS\"]} SL:{position[\"SL\"]} PT:{position[\"PT\"]}')\n",
    "\n",
    "        # HOLD Penalty ကို အလွန်သေးငယ်သော တန်ဖိုး\n",
    "        # (ဥပမာ: -0.0001) သို့ ပြောင်းပါ။ အကောင်းဆုံးမှာ\n",
    "        # Trading မလုပ်ခြင်းအတွက် Penalty မပေးဘဲ action_hold_reward = 0 ထားပါ။\n",
    "        elif open_position < self.max_current_holding and action_name == \"HOLD\":\n",
    "            action_hold_reward  =   0  # no open any position, encourage open position\n",
    "        else:\n",
    "            action_hold_reward  =   0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        reward              +=  action_hold_reward\n",
    "\n",
    "        # Move to the next time step\n",
    "        self.current_step   +=  1\n",
    "\n",
    "        # check if episode is done\n",
    "        terminated          =   (self.balance <= 0)\n",
    "        truncated           =   (self.current_step > self.max_steps)\n",
    "\n",
    "        # get next observation\n",
    "        obs                 =   self._next_observation()\n",
    "        _msg.append(f'---idle----step:{self.current_step}, RF:{action_name} Action:{_action} Balance: {self.balance} reward:{reward} total_rewards:{self.ttl_rewards} position_reward:{position_reward} action_hold_reward:{action_hold_reward}')\n",
    "\n",
    "\n",
    "        current_equity = self._calculate_current_equity()\n",
    "        self.equity_curve.append(current_equity)\n",
    "        self._calculate_drawdown()  # This updates peak_equity and drawdowns\n",
    "\n",
    "        # =========================================================================\n",
    "        # START: Drawdown Penalty Logic\n",
    "        # =========================================================================\n",
    "        # self.current_drawdown သည် Percentage (0.0 မှ 1.0) ဖြစ်သည်။\n",
    "\n",
    "\n",
    "        drawdown_penalty = self.current_drawdown * self.drawdown_penalty_factor\n",
    "        # Reward တွင် နုတ်ပေးခြင်း\n",
    "        reward -= drawdown_penalty\n",
    "\n",
    "        # Log the penalty for debugging\n",
    "        _msg.append(f'Drawdown Penalty: -{drawdown_penalty:.4f} (DD:{self.current_drawdown:.4f})')\n",
    "        # =========================================================================\n",
    "        # END: Drawdown Penalty Logic\n",
    "        # =========================================================================\n",
    "        # Drawdown Penalty နုတ်ပြီးမှသာ စုစုပေါင်း Reward ကို အပ်ဒိတ်လုပ်ပါ\n",
    "        self.ttl_rewards += reward  # <--- ဤနေရာတွင် ပြန်ထည့်ပါ\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        if terminated or truncated:\n",
    "            buy_positions = [p for p in self.positions if p[\"Type\"] == \"BUY\"]\n",
    "            sell_positions = [p for p in self.positions if p[\"Type\"] == \"SELL\"]\n",
    "\n",
    "            buy_count = len(buy_positions)\n",
    "            sell_count = len(sell_positions)\n",
    "            total_positions = len(self.positions)\n",
    "\n",
    "            # Calculate win rates\n",
    "            buy_wins = len([p for p in buy_positions if p[\"PIPS\"] > 0])\n",
    "            sell_wins = len([p for p in sell_positions if p[\"PIPS\"] > 0])\n",
    "\n",
    "            buy_win_rate = buy_wins / buy_count if buy_count > 0 else 0\n",
    "            sell_win_rate = sell_wins / sell_count if sell_count > 0 else 0\n",
    "\n",
    "            _m = f'--- Positions: {total_positions} (Buy:{buy_count}, Sell:{sell_count}) | '\n",
    "            _m += f'WinRates: Buy:{buy_win_rate:.1%}, Sell:{sell_win_rate:.1%} | '\n",
    "            _m += f'TotalRewards: {self.ttl_rewards} Balance: {self.balance}'\n",
    "\n",
    "            logger.info(_m)\n",
    "            _msg.append(_m)\n",
    "\n",
    "            # Additional info\n",
    "            if self.logger_show:\n",
    "                for _m in _msg:\n",
    "                    logger.info(_m)\n",
    "\n",
    "            info[\"info\"]                = _msg\n",
    "            info[\"sharpe\"]              = self._calculate_sharpe()  # ✅ Now works! 💡 'sharpe_ratio' မှ 'sharpe' သို့ပြောင်းပါ။\n",
    "            info[\"drawdown\"]            = self.max_drawdown         # ✅ Now accurate!'max_drawdown' မှ 'drawdown' သို့ပြောင်းပါ။\n",
    "            info[\"current_equity\"]      = current_equity            # ✅ For debugging\n",
    "            info[\"peak_equity\"]         = self.peak_equity          # ✅ For debugging\n",
    "            info[\"equity_curve_length\"] = len(self.equity_curve)    # ✅ Monitor growth\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _calculate_reward(self, position):\n",
    "        _o, _h, _l, _c, _t, _day    =   self.data.iloc[self.current_step][['open', 'high', 'low', 'close', 'time', 'day']]\n",
    "        _msg                        =   []\n",
    "\n",
    "        entry_price                 =   position['ActionPrice']\n",
    "        direction                   =   position['Type']\n",
    "        profit_target_price         =   entry_price + position['PT']/ self.point if direction == 'BUY' else entry_price - position['PT']/self.point\n",
    "        stop_loss_price             =   entry_price + position['SL']/ self.point if direction == 'BUY' else entry_price - position['SL']/self.point\n",
    "        closed                      =   False\n",
    "        close_position_reward       =   0.0\n",
    "        good_position_reward        =   0.0\n",
    "\n",
    "        # Check for stoploss hit\n",
    "        if (direction == 'BUY' and _l <= stop_loss_price) or (direction == 'SELL' and _h >= stop_loss_price):\n",
    "            close_position_reward   =   position['SL'] # position sl က minus value ဖြစ်တယ်\n",
    "\n",
    "            position['CloseTime']   =   _t\n",
    "            position['ClosePrice']  =   stop_loss_price\n",
    "            position['Status']      =   1   # Status က open ဆို 0 close ဆို 1\n",
    "            position['CloseStep']   =   self.current_step\n",
    "            position['PIPS']        =   close_position_reward - self.transaction_fee\n",
    "            position['DeltaStep']   =   self.current_step - position['ActionStep']\n",
    "            position['Info']        =   f'{profit_target_price:.5f} | {stop_loss_price:.5f}'\n",
    "\n",
    "            self.balance            +=  self.margin_requirement + position['PIPS'] # return 100 is margin hold\n",
    "            position['CloseBal']    =   self.balance\n",
    "            closed                  =   True\n",
    "            _msg.append(f'Step:{self.current_step} Tkt:{position[\"Ticket\"]}: Rwd:{position[\"PIPS\"]}, SL:{position[\"SL\"]}, DeltaStep:{position[\"DeltaStep\"]}')\n",
    "\n",
    "        elif (direction == 'BUY' and _h >= profit_target_price) or (direction == 'SELL' and _l <= profit_target_price):\n",
    "            close_position_reward   =    position['PT'] # position tp က plus value ဖြစ်တယ်\n",
    "\n",
    "            position['CloseTime']   =   _t\n",
    "            position['ClosePrice']  =   profit_target_price\n",
    "            position['Status']      =   2   # Status က open ဆို 0 close ဆို 1\n",
    "            position['CloseStep']   =   self.current_step\n",
    "            position['PIPS']        =   close_position_reward - self.transaction_fee\n",
    "            position['DeltaStep']   =   self.current_step - position['ActionStep']\n",
    "            position['Info']        =   f'{profit_target_price:.5f} | {stop_loss_price:.5f}'\n",
    "\n",
    "            self.balance            +=  self.margin_requirement + position['PIPS'] # return 100 is margin hold\n",
    "            position['CloseBal']    =   self.balance\n",
    "            closed                  =   True\n",
    "            _msg.append(f'Step:{self.current_step} Tkt:{position[\"Ticket\"]}: Rwd:{position[\"PIPS\"]}, SL:{position[\"SL\"]}, DeltaStep:{position[\"DeltaStep\"]}')\n",
    "\n",
    "        else:\n",
    "            if self.current_step + 5 + self.sequence_length >= len(self.data):\n",
    "                close_position_reward   =   (_c - position[\"ActionPrice\"] if direction == 'BUY' else position[\"ActionPrice\"] - _c)* self.point\n",
    "\n",
    "                position['CloseTime']   =   _t\n",
    "                position['ClosePrice']  =   _c\n",
    "                position['Status']      =   3   # Status က open ဆို 0 close ဆို 1, force close 2\n",
    "                position['CloseStep']   =   self.current_step\n",
    "                position['PIPS']        =   close_position_reward - self.transaction_fee\n",
    "                position['DeltaStep']   =   self.current_step - position['ActionStep']\n",
    "                position['Info']        =   f'{profit_target_price:.5f} | {stop_loss_price:.5f}'\n",
    "                self.balance            +=  self.margin_requirement + position[\"PIPS\"] # return 100 is margin hold\n",
    "                position['CloseBal']    =   self.balance\n",
    "\n",
    "                closed                  =   True\n",
    "                _msg.append(f'Step:{self.current_step} Tkt:{position[\"Ticket\"]}: Rwd:{position[\"PIPS\"]}, Cls:End, DeltaStep:{position[\"DeltaStep\"]}')\n",
    "\n",
    "            else:\n",
    "                # =========================================================================\n",
    "                # Real Trailing Stop Logic (အမြင့်ဆုံး ရောက်ဖူးသော ဈေးနှုန်းကို မှတ်တမ်းတင်ခြင်း)\n",
    "                # =========================================================================\n",
    "                # 1. Highest/Lowest Price Update\n",
    "\n",
    "                if direction == \"BUY\":\n",
    "                  # Buy position အတွက် အမြင့်ဆုံး ရောက်ဖူးသော ဈေးနှုန်းကို မှတ်တမ်းတင်\n",
    "                  if _c > position[\"HighestPrice\"]:\n",
    "                      position[\"HighestPrice\"] = _c\n",
    "\n",
    "                  # 2. New SL Target Price (Trailing Price) ကို တွက်ချက်ခြင်း\n",
    "                  # New_SL_Price = HighestPrice - (Trailing Distance Pips ကို Price Change သို့ ပြောင်း)\n",
    "                  trailing_price = position[\"HighestPrice\"] - self.trailing_distance / self.point\n",
    "\n",
    "                  # 3. SL ကို အဆင့်မြှင့်တင်ခြင်း\n",
    "                  # လက်ရှိ SL ထက် ပိုကောင်းမှသာ ရွေ့ပါ\n",
    "                  if trailing_price > stop_loss_price:\n",
    "\n",
    "                      stop_loss_price = trailing_price\n",
    "                      # SL_Price အသစ်ကို Points သို့ ပြန်ပြောင်းပြီး position['SL'] ကို အပ်ဒိတ်လုပ်ပါ\n",
    "                      position[\"SL\"] = (stop_loss_price - entry_price) * self.point\n",
    "                      if position[\"SL\"] > 0:\n",
    "                          position[\"SL\"]    =   -abs(position[\"SL\"])\n",
    "                      trailing_happened = True\n",
    "                  else:\n",
    "                      trailing_happened = False\n",
    "\n",
    "\n",
    "                elif direction == \"SELL\":\n",
    "                  # Sell position အတွက် အနိမ့်ဆုံး ရောက်ဖူးသော ဈေးနှုန်းကို မှတ်တမ်းတင်\n",
    "                  if _c < position[\"LowestPrice\"]:\n",
    "                      position[\"LowestPrice\"] = _c\n",
    "\n",
    "                  # New SL Target Price (Trailing Price) ကို တွက်ချက်ခြင်း\n",
    "                  trailing_price = position[\"LowestPrice\"] + self.trailing_distance / self.point\n",
    "\n",
    "                  # SL ကို အဆင့်မြှင့်တင်ခြင်း\n",
    "                  if trailing_price < stop_loss_price:\n",
    "                      stop_loss_price = trailing_price\n",
    "                      # SL_Price အသစ်ကို Points သို့ ပြန်ပြောင်းပြီး position['SL'] ကို အပ်ဒိတ်လုပ်ပါ\n",
    "                      position[\"SL\"] = (entry_price - stop_loss_price) * self.point\n",
    "                      if position[\"SL\"] > 0:\n",
    "                          position[\"SL\"]    =   -abs(position[\"SL\"])\n",
    "                      trailing_happened = True\n",
    "                  else:\n",
    "                      trailing_happened = False\n",
    "\n",
    "                # =========================================================================\n",
    "                # Reward Logic (Trailing လုပ်ခြင်းအတွက် Bonus ပေးခြင်း)\n",
    "                # =========================================================================\n",
    "                # Reward Sign ကို ယခင်အတိုင်း တွက်ပါ။\n",
    "                delta = _c - entry_price\n",
    "                if direction == \"BUY\":\n",
    "                    reward_sign = 1 if delta >= 0 else -1\n",
    "                elif direction == \"SELL\":\n",
    "                    reward_sign = -1 if delta >= 0 else 1\n",
    "\n",
    "                good_position_reward = reward_sign * self.good_position_reward_scale\n",
    "\n",
    "                # Trailing အမှန်တကယ် ဖြစ်သွားမှသာ Bonus Reward ကို ပေးပါ\n",
    "                if trailing_happened:\n",
    "                    good_position_reward += 0.001\n",
    "\n",
    "                position['Info']        =   f'{profit_target_price:.5f} | {stop_loss_price:.5f}'\n",
    "                position['CloseBal']    =   self.balance\n",
    "                _msg.append(f'Step:{self.current_step} Tkt:{position[\"Ticket\"]}: NO_Close, PT:{position[\"PT\"]}, SL:{position[\"SL\"]}')\n",
    "\n",
    "        return close_position_reward + good_position_reward, closed, _msg\n",
    "\n",
    "\n",
    "    def _calculate_sharpe(self, risk_free_rate=0.0):\n",
    "        \"\"\"Calculate Sharpe ratio for the current episode\"\"\"\n",
    "        if len(self.equity_curve) < 2:\n",
    "            return 0.0\n",
    "\n",
    "        returns = np.diff(self.equity_curve) / self.equity_curve[:-1]\n",
    "\n",
    "        if np.std(returns) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        sharpe = (np.mean(returns) - risk_free_rate) / np.std(returns)\n",
    "        return float(sharpe * np.sqrt(288))  # Annualized (5-min bars → 288/day)\n",
    "\n",
    "    def _calculate_drawdown(self):\n",
    "        \"\"\"Update max drawdown during episode\"\"\"\n",
    "        current_equity          =   self.equity_curve[-1]\n",
    "        self.peak_equity        =   max(self.peak_equity, current_equity)\n",
    "        self.current_drawdown   =   (self.peak_equity - current_equity) / self.peak_equity\n",
    "        self.max_drawdown       =   max(self.max_drawdown, self.current_drawdown)\n",
    "\n",
    "\n",
    "    def _calculate_current_equity(self):\n",
    "        \"\"\"Calculate total current equity (balance + unrealized P/L)\"\"\"\n",
    "        total_equity = self.balance  # Start with cash balance\n",
    "\n",
    "        # Add unrealized P/L from open positions\n",
    "        for position in self.positions:\n",
    "            if position['Status'] == 0:  # Only open positions\n",
    "                current_price = self.data.iloc[self.current_step][\"close\"]\n",
    "                entry_price = position['ActionPrice']\n",
    "\n",
    "                if position['Type'] == 'BUY':\n",
    "                    unrealized_pnl = (current_price - entry_price) * self.point\n",
    "                else:  # Sell\n",
    "                    unrealized_pnl = (entry_price - current_price) * self.point\n",
    "\n",
    "                total_equity += unrealized_pnl\n",
    "\n",
    "        return total_equity\n",
    "\n",
    "    def render(self, mode='human', title=None, **kwargs):\n",
    "        # Render the environment to the screen\n",
    "        if mode in ('human', 'file'):\n",
    "            log_header      =   True\n",
    "            printout        =   False\n",
    "            if mode == 'human':\n",
    "                printout    =   True\n",
    "\n",
    "            log_file = self.csv_file.replace(\"split/\", \"log/\")\n",
    "            pm = {\n",
    "                \"log_header\": log_header,\n",
    "                \"log_filename\": log_file,\n",
    "                \"printout\": printout,\n",
    "                \"balance\": self.balance,\n",
    "                \"balance_initial\": self.balance_initial,\n",
    "                \"transaction_close_this_step\": self.positions,\n",
    "                \"done_information\": False\n",
    "            }\n",
    "            render_to_file(**pm)\n",
    "            if log_header:\n",
    "                    log_header = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17aaf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3 import PPO\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "# Assume logger is defined elsewhere, e.g., import logging; logger = logging.getLogger(__name__)\n",
    "\n",
    "BASE_SEED = 42\n",
    "number_envs = 4\n",
    "# Stable-Baselines3 ရဲ့ Global Seed ကို သတ်မှတ်ပါ\n",
    "set_random_seed(BASE_SEED)\n",
    "\n",
    "\n",
    "def single_csv_training(csv_file, env_config_file, asset, model_name='', cf=None, number_envs=1, week_num=0):  # Added week_num for varying seed\n",
    "    # 1. Log Root Directory နှင့် Run Name ကို တွက်ချက်ခြင်း\n",
    "    BASE_LOG_DIR = \"/content/drive/MyDrive/data/log\"\n",
    "    RUN_NAME = f\"{asset}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "    # 2. Log Root Directory ရှိမရှိ စစ်ဆေးပြီး ဖန်တီးခြင်း\n",
    "    os.makedirs(BASE_LOG_DIR, exist_ok=True)\n",
    "\n",
    "    features = cf.env_parameters(\"observation_list\")\n",
    "    sequence_length = cf.env_parameters(\"backward_window\")\n",
    "    print(features)\n",
    "    lr_schedule = linear_schedule(1e-4, 5e-6)\n",
    "    policy_kwargs = dict(\n",
    "        # Repo ရဲ့ custom feature extractor (Transformer + MLP ပေါင်းထားတာ၊ time series data အတွက် သင့်တော်တယ်)။\n",
    "        features_extractor_class=CustomCombinedExtractor,\n",
    "        # features_extractor_kwargs: Sequence length ကို ထည့်။\n",
    "        features_extractor_kwargs=dict(sequence_length=sequence_length),\n",
    "        # net_arch: Actor (pi - policy network) နဲ့ Critic (vf - value function) နှစ်ခု လုံး အတွက် hidden layers [256, 256] သုံး။ (Updated vf to [512,256] for better explained variance)\n",
    "        net_arch=dict(pi=[256, 256], vf=[512, 256]),  # Increased vf capacity\n",
    "        # Activation function အနေနဲ့ ReLU သုံး (non-linear ဖြစ်အောင်)။\n",
    "        activation_fn=nn.ReLU,\n",
    "        # Orthogonal initialization မသုံး (financial data မှာ ပိုကောင်း တယ်လို့ comment မှာ ရေး ထားတယ်၊ ဒါက weights ကို ပိုရိုးရှင်း စ လုပ်တယ်)။\n",
    "        ortho_init=False  # better for financial data\n",
    "    )\n",
    "\n",
    "    # Environment Factories များ ဖန်တီးပါ\n",
    "    env_fns = [\n",
    "        lambda: ForexTradingEnv(\n",
    "            csv_file,\n",
    "            cf,\n",
    "            asset,\n",
    "            features=features,\n",
    "            sequence_length=sequence_length,\n",
    "            logger_show=True\n",
    "        )\n",
    "        for _ in range(number_envs)\n",
    "    ]\n",
    "    # DummyVecEnv ကို တည်ဆောက်ပါ (SubprocVecEnv)\n",
    "    env = SubprocVecEnv(env_fns)\n",
    "    # ဤနေရာသည် အဓိကကျသည်။ ၎င်းက Environment တစ်ခုချင်းစီကို\n",
    "    # BASE_SEED, BASE_SEED+1, BASE_SEED+2... စသည်ဖြင့် Seed များ သတ်မှတ်ပေးပြီး\n",
    "    # ၎င်းတို့၏ reset() ကို ပြန်လည်ခေါ်ပေးလိမ့်မည်။\n",
    "    # Vary seed per week to avoid overfitting in incremental training\n",
    "    varied_seed = BASE_SEED + week_num  # Example: Pass week_num=1 for week 2, etc.\n",
    "    env.seed(varied_seed)\n",
    "\n",
    "    if model_name:\n",
    "        model = PPO.load(model_name, env=env, learning_rate=lr_schedule)\n",
    "    else:\n",
    "        model = PPO(\n",
    "            # 'CnnPolicy' , # support GPU\n",
    "            'MlpPolicy',  # CPU only\n",
    "            env,\n",
    "            device='cuda',\n",
    "            verbose=1,\n",
    "            # ✅ အရေးကြီးဆုံး ပြင်ဆင်ချက်\n",
    "            tensorboard_log=BASE_LOG_DIR,\n",
    "            # Updated params based on plots analysis\n",
    "            vf_coef=0.5,  # Reduced from 0.7 to balance policy vs value\n",
    "            target_kl=0.02,  # Increased from 0.005 for better updates\n",
    "            normalize_advantage=True,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            learning_rate=lr_schedule,  # Reduced learning rate\n",
    "            max_grad_norm=0.3,  # Tighter gradient control\n",
    "            seed=varied_seed,  # Use varied seed\n",
    "\n",
    "            # ⬆️ ပြင်ဆင်ချက် ၂: Trajectory Length ကို လျှော့ချပြီး Batch Size တိုးမြှင့်ခြင်း\n",
    "            n_steps=1024,  # n_steps သည် Policy Update မလုပ်မီ စုဆောင်းမည့် Data ပမာဏ ဖြစ်သည်။ သင်၏ data အရေအတွက်နှင့် ညီမျှသော သိုမဟုတ် နီးစပ်သော တန်ဖိုး (ဥပမာ: 1024 သိုမဟုတ် 512) သည် အပတ်စဉ် data ကို ကောင်းစွာ အသုံးချစေသည်။\n",
    "            batch_size=256,\n",
    "\n",
    "            # ⬇️ ပြင်ဆင်ချက် ၃: Epochs ကို လျှော့ချခြင်း\n",
    "            n_epochs=5,  # Prevent overfitting to recent week\n",
    "\n",
    "            # 🛠️ အခြား Fine-tuning များ\n",
    "            ent_coef=0.005,  # Reduced from 0.01 for controlled exploration\n",
    "            clip_range=0.01,  # Increased from 0.002 to reduce high clip_fraction\n",
    "            gamma=0.99,\n",
    "            # Added GAE for better returns estimation\n",
    "            use_gae=True,\n",
    "            gae_lambda=0.95,\n",
    "        )\n",
    "\n",
    "    # Train the agent\n",
    "    logger.info(\"Starting model training...\")\n",
    "    callback = TrainingMetricsCallback()\n",
    "    model.learn(\n",
    "        total_timesteps=100000,\n",
    "        callback=callback,\n",
    "        # 🚨 ပြင်ဆင်ချက် ၂: tb_log_name နေရာမှာ Run Folder Name ကိုပဲ ပေးပါ။\n",
    "        tb_log_name=RUN_NAME,\n",
    "        reset_num_timesteps=False if model_name else True  # 🔄 Existing model ဆိုရင် timesteps ဆက်မှတ်\n",
    "    )\n",
    "    logger.info(\"Model training complete\")\n",
    "    model_filename = csv_file.replace(\"split/\", \"model/\").replace(\".csv\", \"_single_test.zip\")\n",
    "    model.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "log_dir = '/content/drive/MyDrive/data/log'\n",
    "\n",
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d394ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "asset = \"EURUSD\"\n",
    "env_config_file = '/content/drive/MyDrive/configure.json'\n",
    "cf = EnvConfig(env_config_file)\n",
    "split_cfg = cf.data_processing_parameters(\"train_eval_split\")\n",
    "base_path = split_cfg[\"base_path\"].format(symbol=asset)\n",
    "csv_file = f\"{base_path}/{split_cfg[\"train_dir\"]}/{asset}_2022_12.csv\"\n",
    "model_name = '' #f'/content/drive/MyDrive/data/model/{asset}/train/{asset}_2022_12_single_test.zip'\n",
    "single_csv_training(csv_file=csv_file, env_config_file =env_config_file, asset= asset, model_name=model_name, cf=cf, number_envs=4, week_num=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"{base_path}/{split_cfg[\"train_dir\"]}/{asset}_2022_13.csv\"\n",
    "model_name = f'/content/drive/MyDrive/data/model/{asset}/train/{asset}_2022_12_single_test.zip'\n",
    "single_csv_training(csv_file=csv_file, env_config_file =env_config_file, asset= asset, model_name=model_name, cf=cf, number_envs=4, week_num=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9971ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"{base_path}/{split_cfg[\"train_dir\"]}/{asset}_2022_14.csv\"\n",
    "model_name = f'/content/drive/MyDrive/data/model/{asset}/train/{asset}_2022_13_single_test.zip'\n",
    "single_csv_training(csv_file=csv_file, env_config_file =env_config_file, asset= asset, model_name=model_name, cf=cf, number_envs=4, week_num=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce89845",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"{base_path}/{split_cfg[\"train_dir\"]}/{asset}_2022_15.csv\"\n",
    "model_name = f'/content/drive/MyDrive/data/model/{asset}/train/{asset}_2022_14_single_test.zip'\n",
    "single_csv_training(csv_file=csv_file, env_config_file =env_config_file, asset= asset, model_name=model_name, cf=cf, number_envs=4, week_num=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f7eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"{base_path}/{split_cfg[\"train_dir\"]}/{asset}_2022_16.csv\"\n",
    "model_name = f'/content/drive/MyDrive/data/model/{asset}/train/{asset}_2022_15_single_test.zip'\n",
    "single_csv_training(csv_file=csv_file, env_config_file =env_config_file, asset= asset, model_name=model_name, cf=cf, number_envs=4, week_num=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ef5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"{base_path}/{split_cfg[\"train_dir\"]}/{asset}_2022_17.csv\"\n",
    "model_name = f'/content/drive/MyDrive/data/model/{asset}/train/{asset}_2022_16_single_test.zip'\n",
    "single_csv_training(csv_file=csv_file, env_config_file =env_config_file, asset= asset, model_name=model_name, cf=cf, number_envs=4, week_num=6)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
