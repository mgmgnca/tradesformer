{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b433a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from finta import TA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import logging\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EnvConfig():\n",
    "    \"\"\"environment configuration from json file\n",
    "       tgym requires you configure your own parameters in json file.\n",
    "        Args:\n",
    "            config_file path/file.json\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,config_file):\n",
    "        self.config = {}\n",
    "        with open(config_file) as j: \n",
    "            self.config = json.load(j)\n",
    "\n",
    "    def env_parameters(self,item=''):   \n",
    "        \"\"\"environment variables \n",
    "        \"\"\" \n",
    "        if item:\n",
    "            return self.config[\"env\"][item]\n",
    "        else:\n",
    "            return self.config[\"env\"]\n",
    "        \n",
    "    def symbol(self, asset=\"GBPUSD\", item='') :\n",
    "        \"\"\"get trading pair (symbol) information\n",
    "\n",
    "        Args:\n",
    "            asset (str, optional): symbol in config. Defaults to \"GBPUSD\".\n",
    "            item (str, optional): name of item, if '' return dict, else return item value. Defaults to ''.\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        if item:\n",
    "            return self.config[\"symbol\"][asset][item]\n",
    "        else:\n",
    "            return self.config[\"symbol\"][asset]\n",
    "        \n",
    "    def data_processing_parameters(self, item=''):\n",
    "        \"\"\"Get data processing config\"\"\"\n",
    "        if item:\n",
    "            return self.config[\"data_processing\"][item]\n",
    "        return self.config[\"data_processing\"]\n",
    "            \n",
    "    def trading_hour(self,place=\"New York\"):\n",
    "        \"\"\"forex trading hour from different markets\n",
    "\n",
    "        Args:\n",
    "            place (str, optional): [Sydney,Tokyo,London] Defaults to \"New York\".\n",
    "\n",
    "        Returns:\n",
    "            [dict]: from time, to time\n",
    "        \"\"\"\n",
    "        if place:\n",
    "            return self.config[\"trading_hour\"][place]\n",
    "        else:\n",
    "            return self.config[\"trading_hour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bd17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_missing_data(df, dt_col_name='time', cf=None):\n",
    "    # [\"time\",\"open\", \"high\", \"low\", \"close\"]\n",
    "    required_cols = cf.data_processing_parameters(\"required_cols\")    \n",
    "    \n",
    "    # df မှာ 6 columns ရှိရင် vol ပါထည့်မယ် \n",
    "    if df.shape[1] == 6:\n",
    "        df.columns = required_cols + ['vol']  \n",
    "    elif df.shape[1] == 5:\n",
    "        df.columns = required_cols\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid number of columns: {df.shape[1]} =>{required_cols}\")\n",
    "    \n",
    "    logger.warning(f\"shape of  column: {df.shape[1]}\")\n",
    "    # 1. Column validation\n",
    "    if missing := set(required_cols) - set(df.columns):\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    # 2. Auto-detect datetime column\n",
    "    dt_candidates = {'time', 'timestamp', 'date', 'datetime'}\n",
    "    if dt_col_name not in df.columns:\n",
    "        found = list(dt_candidates & set(df.columns))\n",
    "        if not found:\n",
    "            raise KeyError(f\"No datetime column found. Tried: {dt_candidates}\")\n",
    "        dt_col_name = found[0]\n",
    "        logger.info(f\"Using datetime column: {dt_col_name}\")\n",
    "\n",
    "    # 3. Convert to datetime index\n",
    "    df[dt_col_name] = pd.to_datetime(df[dt_col_name], utc=True)\n",
    "    df = df.set_index(dt_col_name).sort_index()\n",
    "\n",
    "    # 4. Create complete 5-min grid (Mon 00:00 - Fri 23:55 UTC)\n",
    "    new_index = pd.date_range(\n",
    "        start=df.index.min().floor('D'),\n",
    "        end=df.index.max().ceil('D'),\n",
    "        freq='5T',\n",
    "        tz='UTC'\n",
    "    )\n",
    "    \n",
    "    # 5. Forward-fill OHLC prices\n",
    "    df = df.reindex(new_index)\n",
    "    # 6. Apply Limited Forward-Fill (FFILL) - Internal Gaps ကိုသာ ဖြည့်ရန်\n",
    "    # fill_limit = 12 # ဥပမာ: 1 နာရီ (12 bars) ထက်ပိုတဲ့ ကွက်လပ်ကို မဖြည့်ပါ\n",
    "    # df[['open', 'high', 'low', 'close', 'vol']] = df[['open', 'high', 'low', 'close', 'vol']].ffill(fill_limit)\n",
    "    # 6. Apply Limited Forward-Fill (FFILL) - Internal Gaps ကိုသာ ဖြည့်ရန်\n",
    "    fill_limit = 12 # ဥပမာ: 1 နာရီ (12 bars) ထက်ပိုတဲ့ ကွက်လပ်ကို မဖြည့်ပါ\n",
    "    fill_cols = ['open', 'high', 'low', 'close', 'vol'] if 'vol' in df.columns else ['open', 'high', 'low', 'close']\n",
    "    \n",
    "    # FFill: ရှေ့က data ဖြင့် ဖြည့်ပါ\n",
    "    df[fill_cols] = df[fill_cols].ffill(limit=fill_limit)\n",
    "\n",
    "    # # 6. Filter weekends (keep Friday 22:00-23:55 as \"pseudo Sunday\")\n",
    "    # df = df[(df.index.weekday < 5) | (\n",
    "    #     (df.index.weekday == 4) & (df.index.hour >= 22)\n",
    "    # )]\n",
    "\n",
    "    # 7. Validate bars per week\n",
    "    # min bar per week က timeframe အလိုက် အပြောင်းလဲရှိမယ်\n",
    "    # 5-min timeframe (repo မှာ သုံး ထားတဲ့ အတိုင်း): \n",
    "    # တစ်ရက် ၂၄ နာရီ x ၆၀ မိနစ် / ၅ = ၂၈၈ bars/ရက်။ တစ်ပတ် (၅ ရက်) ဆို ၁၄၄၀ bars လောက် ရှိ ရမယ် \n",
    "    # (min_bars_per_week=1440 လောက်)။\n",
    "    # 5-min: min_bars_per_week = 1440 (၂၈၈ bars/ရက် x ၅ ရက်)\n",
    "    # 15-min: 480 (၉၆ bars/ရက် x ၅)\n",
    "    # 1-hour: 120 (၂၄ bars/ရက် x ၅)\n",
    "    min_bars = cf.data_processing_parameters(\"min_bars_per_week\")\n",
    "    for week, group in df.groupby(pd.Grouper(freq='W-MON')):\n",
    "        if len(group) != min_bars:\n",
    "            logger.warning(f\"Week {week} has {len(group)}/{min_bars} bars\")\n",
    "            \n",
    "    # 7. ❗️ NaN အဖြစ် ကျန်ရှိနေသော Rows များကို ဖယ်ရှားခြင်း ❗️\n",
    "    # Open price မရှိတဲ့ rows တွေကို စစ်ဆေးပြီး ဖယ်ရှားပါ (Weekend Gap ကြောင့် NaN ကျန်ခဲ့သော bars များ)\n",
    "    df = df.dropna(subset=['open'])\n",
    "    logger.warning(f\"Total rows dropped due to NaN (likely weekend gap): {len(new_index) - len(df)}\")\n",
    "\n",
    "    return df.reset_index().rename(columns={'index': dt_col_name})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b015ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_feature(df, symbol):\n",
    "    \"\"\"Add temporal features with proper index handling\"\"\"\n",
    "    \n",
    "    if 'time' not in df.columns:\n",
    "        raise KeyError(\"'time' column missing after patch_missing_data\")\n",
    "        \n",
    "    df = df.set_index('time')\n",
    "    df.index = pd.to_datetime(df.index, utc=True)\n",
    "    \n",
    "    # Cyclical time features\n",
    "    df['weekday'] = df.index.dayofweek  # 0=Monday\n",
    "    df['day'] = df.index.day\n",
    "    df['week'] = df.index.isocalendar().week\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['hour'] = df.index.hour\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24).round(6)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24).round(6)\n",
    "    df['minute_block'] = df.index.minute // 5  # 0-11\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute_block']/12).round(6)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute_block']/12).round(6)\n",
    "    \n",
    "    # Market sessions (GMT)\n",
    "    df['london_session'] = ((df['hour'] >= 8) & (df['hour'] < 16)).astype(int)\n",
    "    df['ny_session'] = ((df['hour'] >= 13) & (df['hour'] < 21)).astype(int)\n",
    "    df['overlap_session'] = ((df['hour'] >= 13) & (df['hour'] < 16)).astype(int)\n",
    "    \n",
    "    df['symbol'] = symbol\n",
    "    return df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67881b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tech_indicators(df, cf=None):  # 288 = 24hrs in 5-min bars\n",
    "    \"\"\"Calculate technical indicators with proper NaN handling\"\"\"\n",
    "    period = cf.data_processing_parameters(\"indicator_period\")\n",
    "    # 1. Preserve raw prices before normalization\n",
    "    raw_cols = ['mean_std_open','mean_std_high','mean_std_low','mean_std_close']\n",
    "    df[raw_cols] = df[['open','high','low','close']].copy()\n",
    "    # Calculate indicators\n",
    "    df['macd'] = TA.MACD(df).SIGNAL.ffill().round(6)\n",
    "    bb = TA.BBANDS(df)\n",
    "    df['boll_ub'] = bb['BB_UPPER'].ffill()\n",
    "    df['boll_lb'] = bb['BB_LOWER'].ffill()\n",
    "    \n",
    "    df['rsi_30'] = TA.RSI(df, period=period).ffill()\n",
    "    df['dx_30'] = TA.ADX(df, period=period).ffill()\n",
    "    df['close_30_sma'] = TA.SMA(df, period=period).ffill()\n",
    "    df['close_60_sma'] = TA.SMA(df, period=period*2).ffill()\n",
    "    df['atr'] = TA.ATR(df, period=period).ffill()\n",
    "     # Add returns and volatility ratio\n",
    "    df['returns_5'] = df['close'].pct_change(5).round(6)\n",
    "    df['returns_24'] = df['close'].pct_change(24).round(6)\n",
    "    df['volatility_ratio'] = (df['high'] - df['low']) / df['close'].round(6)\n",
    "        \n",
    "    # Normalize\n",
    "    scaler = StandardScaler()\n",
    "    scale_cols = cf.data_processing_parameters(\"scale_cols\")  \n",
    "\n",
    "    df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    # 1. Identify numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    # 2. Apply clipping only to numeric features\n",
    "    df[numeric_cols] = df[numeric_cols].clip(lower=-1e5, upper=1e5)\n",
    "    # 3. Round decimal values\n",
    "    df[numeric_cols] = df[numeric_cols].round(6).clip(-1e5, 1e5)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f8cae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesScaler:\n",
    "    \"\"\"\n",
    "    Manages the MinMax Scaling process for time series features.\n",
    "    It fits the scaler on the first chunk of data (expected to be the training start)\n",
    "    and uses that fitted scaler to transform all subsequent data chunks (including eval).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # MinMaxScaler ကို အသုံးပြုပြီး 0 နဲ့ 1 ကြားကို ပြောင်းပါ\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.is_fitted = False\n",
    "        self.price_cols = ['mean_std_open', 'mean_std_high', 'mean_std_low', 'mean_std_close']\n",
    "        \n",
    "    def fit_and_transform(self, df):\n",
    "        \"\"\"Fit the scaler on the data and transform it.\"\"\"\n",
    "        logger.info(\"Fitting Scaler on current week data (TRAIN set base)\")\n",
    "        # .copy() လုပ်ပြီးမှ transform လုပ်ပါ\n",
    "        df_copy = df.copy() \n",
    "        df_copy[self.price_cols] = self.scaler.fit_transform(df_copy[self.price_cols])\n",
    "        self.is_fitted = True\n",
    "        return df_copy\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"Transform data using the previously fitted scaler.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Scaler must be fitted on the training data first!\")\n",
    "            \n",
    "        logger.info(\"Transforming current week data using fitted scaler.\")\n",
    "        # .copy() လုပ်ပြီးမှ transform လုပ်ပါ\n",
    "        df_copy = df.copy() \n",
    "        df_copy[self.price_cols] = self.scaler.transform(df_copy[self.price_cols])\n",
    "        return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c8d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series_v2(df, freq='W-FRI', symbol='EURUSD', cf=None, scaler_manager=None):\n",
    "    \"\"\"\n",
    "    Split data with weekly alignment and performs MinMax scaling using \n",
    "    Fit-Transform for the first non-NaN chunk and then Transform for others.\n",
    "    \"\"\"\n",
    "    if scaler_manager is None:\n",
    "        raise ValueError(\"scaler_manager (TimeSeriesScaler instance) must be provided.\")\n",
    "        \n",
    "    split_cfg = cf.data_processing_parameters(\"train_eval_split\")\n",
    "    base_path = split_cfg[\"base_path\"].format(symbol=symbol)\n",
    "        \n",
    "    # Align with Forex week (Monday-Sunday)\n",
    "    df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "    df = df.set_index('time')\n",
    "    \n",
    "    # W-MON သည် တနင်္လာနေ့တွင် စတင်သော အပတ်ကို ကိုယ်စားပြုသည်။\n",
    "    groups = df.groupby(pd.Grouper(freq=freq))\n",
    "    \n",
    "    # Indicators columns\n",
    "    indicator_cols = ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'atr']\n",
    "    \n",
    "    for week_start, week_df in groups:\n",
    "        if week_df.empty:\n",
    "            continue\n",
    "        \n",
    "        # 1. Check raw indicators to determine Eval set (Data Leakage မဖြစ်စေရန်)\n",
    "        first_row = week_df[indicator_cols].iloc[0]\n",
    "        has_nan = first_row.isna().any()\n",
    "        has_zero = (first_row == 0).any()\n",
    "        is_eval = has_nan or has_zero # Indicator များ မပြည့်စုံသေးသော အပတ်ကို Eval အဖြစ် သတ်မှတ်\n",
    "        \n",
    "        # Data အရေအတွက် စစ်ဆေးခြင်း\n",
    "        if len(week_df) < 1440:\n",
    "            logger.warning(f\"Skipping {week_start}: {len(week_df)}/1440 bars\")\n",
    "            continue\n",
    "        \n",
    "        # 2. Normalize and validate (Fit-Transform Logic)\n",
    "        if not scaler_manager.is_fitted and not is_eval:\n",
    "            # Scaler ကို ပထမဆုံးသော၊ Indicators ပြည့်စုံသော (is_eval=False) Training Set တွင် Fit လုပ်ပါ\n",
    "            week_df = scaler_manager.fit_and_transform(week_df)\n",
    "            dir_type = 'train'\n",
    "        elif scaler_manager.is_fitted:\n",
    "            # Scaler Fit ပြီးပါက၊ Train နှင့် Eval နှစ်ခုလုံးကို Transform လုပ်ပါ\n",
    "            week_df = scaler_manager.transform(week_df)\n",
    "            dir_type = 'eval' if is_eval else 'train'\n",
    "        else:\n",
    "            # Fit မလုပ်ရသေးဘဲ is_eval ဖြစ်နေရင် ကျော်သွားပါ (Indicators မပြည့်သေးလို့ Fit မလုပ်သင့်)\n",
    "            logger.warning(f\"Skipping {week_start}: Indicators not ready for fitting and not fitted yet.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # 3. Save to appropriate directory\n",
    "        path = os.path.join(base_path, split_cfg[f\"{dir_type}_dir\"])\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        iso_year, iso_week, _ = week_start.isocalendar()\n",
    "        fname = f\"{symbol}_{iso_year}_{iso_week:02d}.csv\"\n",
    "        week_df.reset_index().to_csv(f\"{path}/{fname}\", index=False)\n",
    "        logger.critical(f\"Saved {dir_type} file: {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601984af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022-03-16 15:25</th>\n",
       "      <th>1.10006</th>\n",
       "      <th>1.10027</th>\n",
       "      <th>1.09966</th>\n",
       "      <th>1.1002</th>\n",
       "      <th>679</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2024-11-15 02:45</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05426</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2024-11-15 02:50</td>\n",
       "      <td>1.05399</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2024-11-15 02:55</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.05410</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2022-03-16 15:25  1.10006  1.10027  1.09966   1.1002   679\n",
       "199996  2024-11-15 02:45  1.05378  1.05426  1.05378  1.05398  1085\n",
       "199997  2024-11-15 02:50  1.05399  1.05416  1.05398  1.05416   964\n",
       "199998  2024-11-15 02:55  1.05416  1.05422  1.05405  1.05410  1170"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = 'EURUSD'\n",
    "file = f'./drive/MyDrive/data/raw/{symbol}_M5.csv'\n",
    "# 1. Load & clean\n",
    "raw = pd.read_csv(file)\n",
    "raw.tail(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf193cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "shape of  column: 6\n",
      "C:\\Users\\mgmgn\\AppData\\Local\\Temp\\ipykernel_18912\\250263962.py:32: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  new_index = pd.date_range(\n",
      "Week 2022-03-21 00:00:00+00:00 has 1728/1440 bars\n",
      "Week 2022-03-28 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-04-04 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-04-11 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-04-18 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-04-25 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-05-02 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-05-09 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-05-16 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-05-23 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-05-30 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-06-06 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-06-13 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-06-20 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-06-27 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-07-04 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-07-11 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-07-18 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-07-25 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-08-01 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-08-08 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-08-15 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-08-22 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-08-29 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-09-05 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-09-12 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-09-19 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-09-26 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-10-03 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-10-10 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-10-17 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-10-24 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-10-31 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-11-07 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-11-14 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-11-21 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-11-28 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-12-05 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-12-12 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-12-19 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2022-12-26 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-01-02 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-01-09 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-01-16 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-01-23 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-01-30 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-02-06 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-02-13 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-02-20 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-02-27 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-03-06 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-03-13 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-03-20 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-03-27 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-04-03 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-04-10 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-04-17 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-04-24 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-05-01 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-05-08 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-05-15 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-05-22 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-05-29 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-06-05 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-06-12 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-06-19 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-06-26 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-07-03 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-07-10 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-07-17 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-07-24 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-07-31 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-08-07 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-08-14 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-08-21 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-08-28 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-09-04 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-09-11 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-09-18 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-09-25 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-10-02 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-10-09 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-10-16 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-10-23 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-10-30 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-11-06 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-11-13 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-11-20 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-11-27 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-12-04 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-12-11 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-12-18 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2023-12-25 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-01-01 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-01-08 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-01-15 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-01-22 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-01-29 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-02-05 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-02-12 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-02-19 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-02-26 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-03-04 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-03-11 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-03-18 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-03-25 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-04-01 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-04-08 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-04-15 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-04-22 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-04-29 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-05-06 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-05-13 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-05-20 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-05-27 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-06-03 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-06-10 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-06-17 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-06-24 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-07-01 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-07-08 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-07-15 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-07-22 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-07-29 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-08-05 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-08-12 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-08-19 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-08-26 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-09-02 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-09-09 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-09-16 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-09-23 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-09-30 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-10-07 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-10-14 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-10-21 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-10-28 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-11-04 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-11-11 00:00:00+00:00 has 2016/1440 bars\n",
      "Week 2024-11-18 00:00:00+00:00 has 1153/1440 bars\n",
      "Total rows dropped due to NaN (likely weekend gap): 79299\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201787</th>\n",
       "      <td>2024-11-15 03:45:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>1170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201788</th>\n",
       "      <td>2024-11-15 03:50:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>1170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201789</th>\n",
       "      <td>2024-11-15 03:55:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>1170.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time     open     high      low   close     vol\n",
       "201787 2024-11-15 03:45:00+00:00  1.05416  1.05422  1.05405  1.0541  1170.0\n",
       "201788 2024-11-15 03:50:00+00:00  1.05416  1.05422  1.05405  1.0541  1170.0\n",
       "201789 2024-11-15 03:55:00+00:00  1.05416  1.05422  1.05405  1.0541  1170.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = EnvConfig('./drive/MyDrive/configure.json')  \n",
    "df = patch_missing_data(raw,cf=cf)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a0c856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>minute_block</th>\n",
       "      <th>minute_sin</th>\n",
       "      <th>minute_cos</th>\n",
       "      <th>london_session</th>\n",
       "      <th>ny_session</th>\n",
       "      <th>overlap_session</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201787</th>\n",
       "      <td>2024-11-15 03:45:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201788</th>\n",
       "      <td>2024-11-15 03:50:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201789</th>\n",
       "      <td>2024-11-15 03:55:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time     open     high      low   close     vol  \\\n",
       "201787 2024-11-15 03:45:00+00:00  1.05416  1.05422  1.05405  1.0541  1170.0   \n",
       "201788 2024-11-15 03:50:00+00:00  1.05416  1.05422  1.05405  1.0541  1170.0   \n",
       "201789 2024-11-15 03:55:00+00:00  1.05416  1.05422  1.05405  1.0541  1170.0   \n",
       "\n",
       "        weekday  day  week  month  ...  hour  hour_sin  hour_cos  \\\n",
       "201787        4   15    46     11  ...     3  0.707107  0.707107   \n",
       "201788        4   15    46     11  ...     3  0.707107  0.707107   \n",
       "201789        4   15    46     11  ...     3  0.707107  0.707107   \n",
       "\n",
       "        minute_block  minute_sin  minute_cos  london_session  ny_session  \\\n",
       "201787             9   -1.000000   -0.000000               0           0   \n",
       "201788            10   -0.866025    0.500000               0           0   \n",
       "201789            11   -0.500000    0.866025               0           0   \n",
       "\n",
       "        overlap_session  symbol  \n",
       "201787                0  EURUSD  \n",
       "201788                0  EURUSD  \n",
       "201789                0  EURUSD  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Feature engineering\n",
    "df = add_time_feature(df, symbol=symbol)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe15964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>atr</th>\n",
       "      <th>returns_5</th>\n",
       "      <th>returns_24</th>\n",
       "      <th>volatility_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201787</th>\n",
       "      <td>2024-11-15 03:45:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054244</td>\n",
       "      <td>1.053825</td>\n",
       "      <td>-0.575375</td>\n",
       "      <td>1.088574</td>\n",
       "      <td>1.053937</td>\n",
       "      <td>1.056404</td>\n",
       "      <td>0.567566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201788</th>\n",
       "      <td>2024-11-15 03:50:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054244</td>\n",
       "      <td>1.053847</td>\n",
       "      <td>-0.575375</td>\n",
       "      <td>1.083338</td>\n",
       "      <td>1.053935</td>\n",
       "      <td>1.056391</td>\n",
       "      <td>0.566534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201789</th>\n",
       "      <td>2024-11-15 03:55:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.0541</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054241</td>\n",
       "      <td>1.053871</td>\n",
       "      <td>-0.575375</td>\n",
       "      <td>1.078119</td>\n",
       "      <td>1.053933</td>\n",
       "      <td>1.056377</td>\n",
       "      <td>0.566792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time     open     high      low   close     vol  \\\n",
       "201787 2024-11-15 03:45:00+00:00  1.05416  1.05422  1.05405  1.0541  1170.0   \n",
       "201788 2024-11-15 03:50:00+00:00  1.05416  1.05422  1.05405  1.0541  1170.0   \n",
       "201789 2024-11-15 03:55:00+00:00  1.05416  1.05422  1.05405  1.0541  1170.0   \n",
       "\n",
       "        weekday  day  week  month  ...   boll_ub   boll_lb    rsi_30  \\\n",
       "201787        4   15    46     11  ...  1.054244  1.053825 -0.575375   \n",
       "201788        4   15    46     11  ...  1.054244  1.053847 -0.575375   \n",
       "201789        4   15    46     11  ...  1.054241  1.053871 -0.575375   \n",
       "\n",
       "           dx_30  close_30_sma  close_60_sma       atr  returns_5  returns_24  \\\n",
       "201787  1.088574      1.053937      1.056404  0.567566        0.0    0.000798   \n",
       "201788  1.083338      1.053935      1.056391  0.566534        0.0    0.000703   \n",
       "201789  1.078119      1.053933      1.056377  0.566792        0.0    0.000874   \n",
       "\n",
       "        volatility_ratio  \n",
       "201787          0.000161  \n",
       "201788          0.000161  \n",
       "201789          0.000161  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tech_indicators(df, cf=cf) \n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e9af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping 2022-03-18 00:00:00+00:00: 654/1440 bars\n",
      "Saved train file: EURUSD_2022_12.csv\n",
      "Saved train file: EURUSD_2022_13.csv\n",
      "Saved train file: EURUSD_2022_14.csv\n",
      "Saved train file: EURUSD_2022_15.csv\n",
      "Saved train file: EURUSD_2022_16.csv\n",
      "Saved train file: EURUSD_2022_17.csv\n",
      "Saved train file: EURUSD_2022_18.csv\n",
      "Saved train file: EURUSD_2022_19.csv\n",
      "Saved train file: EURUSD_2022_20.csv\n",
      "Saved train file: EURUSD_2022_21.csv\n",
      "Saved train file: EURUSD_2022_22.csv\n",
      "Saved train file: EURUSD_2022_23.csv\n",
      "Saved train file: EURUSD_2022_24.csv\n",
      "Saved train file: EURUSD_2022_25.csv\n",
      "Saved train file: EURUSD_2022_26.csv\n",
      "Saved train file: EURUSD_2022_27.csv\n",
      "Saved train file: EURUSD_2022_28.csv\n",
      "Saved train file: EURUSD_2022_29.csv\n",
      "Saved train file: EURUSD_2022_30.csv\n",
      "Saved train file: EURUSD_2022_31.csv\n",
      "Saved train file: EURUSD_2022_32.csv\n",
      "Saved train file: EURUSD_2022_33.csv\n",
      "Saved train file: EURUSD_2022_34.csv\n",
      "Saved train file: EURUSD_2022_35.csv\n",
      "Saved train file: EURUSD_2022_36.csv\n",
      "Saved train file: EURUSD_2022_37.csv\n",
      "Saved train file: EURUSD_2022_38.csv\n",
      "Saved train file: EURUSD_2022_39.csv\n",
      "Saved train file: EURUSD_2022_40.csv\n",
      "Saved train file: EURUSD_2022_41.csv\n",
      "Saved train file: EURUSD_2022_42.csv\n",
      "Saved train file: EURUSD_2022_43.csv\n",
      "Saved train file: EURUSD_2022_44.csv\n",
      "Saved train file: EURUSD_2022_45.csv\n",
      "Saved train file: EURUSD_2022_46.csv\n",
      "Saved train file: EURUSD_2022_47.csv\n",
      "Saved train file: EURUSD_2022_48.csv\n",
      "Saved train file: EURUSD_2022_49.csv\n",
      "Saved train file: EURUSD_2022_50.csv\n",
      "Saved train file: EURUSD_2022_51.csv\n",
      "Saved train file: EURUSD_2022_52.csv\n",
      "Saved train file: EURUSD_2023_01.csv\n",
      "Saved train file: EURUSD_2023_02.csv\n",
      "Saved train file: EURUSD_2023_03.csv\n",
      "Saved train file: EURUSD_2023_04.csv\n",
      "Saved train file: EURUSD_2023_05.csv\n",
      "Saved train file: EURUSD_2023_06.csv\n",
      "Saved train file: EURUSD_2023_07.csv\n",
      "Saved train file: EURUSD_2023_08.csv\n",
      "Saved train file: EURUSD_2023_09.csv\n",
      "Saved train file: EURUSD_2023_10.csv\n",
      "Saved train file: EURUSD_2023_11.csv\n",
      "Saved train file: EURUSD_2023_12.csv\n",
      "Saved train file: EURUSD_2023_13.csv\n",
      "Saved train file: EURUSD_2023_14.csv\n",
      "Saved train file: EURUSD_2023_15.csv\n",
      "Saved train file: EURUSD_2023_16.csv\n",
      "Saved train file: EURUSD_2023_17.csv\n",
      "Saved train file: EURUSD_2023_18.csv\n",
      "Saved train file: EURUSD_2023_19.csv\n",
      "Saved train file: EURUSD_2023_20.csv\n",
      "Saved train file: EURUSD_2023_21.csv\n",
      "Saved train file: EURUSD_2023_22.csv\n",
      "Saved train file: EURUSD_2023_23.csv\n",
      "Saved train file: EURUSD_2023_24.csv\n",
      "Saved train file: EURUSD_2023_25.csv\n",
      "Saved train file: EURUSD_2023_26.csv\n",
      "Saved train file: EURUSD_2023_27.csv\n",
      "Saved train file: EURUSD_2023_28.csv\n",
      "Saved train file: EURUSD_2023_29.csv\n",
      "Saved train file: EURUSD_2023_30.csv\n",
      "Saved train file: EURUSD_2023_31.csv\n",
      "Saved train file: EURUSD_2023_32.csv\n",
      "Saved train file: EURUSD_2023_33.csv\n",
      "Saved train file: EURUSD_2023_34.csv\n",
      "Saved train file: EURUSD_2023_35.csv\n",
      "Saved train file: EURUSD_2023_36.csv\n",
      "Saved train file: EURUSD_2023_37.csv\n",
      "Saved train file: EURUSD_2023_38.csv\n",
      "Saved train file: EURUSD_2023_39.csv\n",
      "Saved train file: EURUSD_2023_40.csv\n",
      "Saved train file: EURUSD_2023_41.csv\n",
      "Saved train file: EURUSD_2023_42.csv\n",
      "Saved train file: EURUSD_2023_43.csv\n",
      "Saved train file: EURUSD_2023_44.csv\n",
      "Saved train file: EURUSD_2023_45.csv\n",
      "Saved train file: EURUSD_2023_46.csv\n",
      "Saved train file: EURUSD_2023_47.csv\n",
      "Saved train file: EURUSD_2023_48.csv\n",
      "Saved train file: EURUSD_2023_49.csv\n",
      "Saved train file: EURUSD_2023_50.csv\n",
      "Saved train file: EURUSD_2023_51.csv\n",
      "Skipping 2023-12-29 00:00:00+00:00: 1284/1440 bars\n",
      "Skipping 2024-01-05 00:00:00+00:00: 1164/1440 bars\n",
      "Saved train file: EURUSD_2024_02.csv\n",
      "Saved train file: EURUSD_2024_03.csv\n",
      "Saved train file: EURUSD_2024_04.csv\n",
      "Saved train file: EURUSD_2024_05.csv\n",
      "Saved train file: EURUSD_2024_06.csv\n",
      "Saved train file: EURUSD_2024_07.csv\n",
      "Saved train file: EURUSD_2024_08.csv\n",
      "Saved train file: EURUSD_2024_09.csv\n",
      "Saved train file: EURUSD_2024_10.csv\n",
      "Saved train file: EURUSD_2024_11.csv\n",
      "Saved train file: EURUSD_2024_12.csv\n",
      "Saved train file: EURUSD_2024_13.csv\n",
      "Saved train file: EURUSD_2024_14.csv\n",
      "Saved train file: EURUSD_2024_15.csv\n",
      "Saved train file: EURUSD_2024_16.csv\n",
      "Saved train file: EURUSD_2024_17.csv\n",
      "Saved train file: EURUSD_2024_18.csv\n",
      "Saved train file: EURUSD_2024_19.csv\n",
      "Saved train file: EURUSD_2024_20.csv\n",
      "Saved train file: EURUSD_2024_21.csv\n",
      "Saved train file: EURUSD_2024_22.csv\n",
      "Saved train file: EURUSD_2024_23.csv\n",
      "Saved train file: EURUSD_2024_24.csv\n",
      "Saved train file: EURUSD_2024_25.csv\n",
      "Saved train file: EURUSD_2024_26.csv\n",
      "Saved train file: EURUSD_2024_27.csv\n",
      "Saved train file: EURUSD_2024_28.csv\n",
      "Saved train file: EURUSD_2024_29.csv\n",
      "Saved train file: EURUSD_2024_30.csv\n",
      "Saved train file: EURUSD_2024_31.csv\n",
      "Saved train file: EURUSD_2024_32.csv\n",
      "Saved train file: EURUSD_2024_33.csv\n",
      "Saved train file: EURUSD_2024_34.csv\n",
      "Saved train file: EURUSD_2024_35.csv\n",
      "Saved train file: EURUSD_2024_36.csv\n",
      "Saved train file: EURUSD_2024_37.csv\n",
      "Saved train file: EURUSD_2024_38.csv\n",
      "Saved train file: EURUSD_2024_39.csv\n",
      "Saved train file: EURUSD_2024_40.csv\n",
      "Saved train file: EURUSD_2024_41.csv\n",
      "Saved train file: EURUSD_2024_42.csv\n",
      "Saved train file: EURUSD_2024_43.csv\n",
      "Saved train file: EURUSD_2024_44.csv\n",
      "Saved train file: EURUSD_2024_45.csv\n",
      "Skipping 2024-11-15 00:00:00+00:00: 1224/1440 bars\n"
     ]
    }
   ],
   "source": [
    "# Scaler instance ကို တည်ဆောက်ပါ\n",
    "scaler_manager = TimeSeriesScaler()\n",
    "\n",
    "# Function ကို ခေါ်ပါ\n",
    "split_time_series_v2(df, freq='W-FRI', symbol=symbol, cf=cf, scaler_manager=scaler_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c4024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
