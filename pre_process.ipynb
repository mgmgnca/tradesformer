{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b433a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from finta import TA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import logging\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EnvConfig():\n",
    "    \"\"\"environment configuration from json file\n",
    "       tgym requires you configure your own parameters in json file.\n",
    "        Args:\n",
    "            config_file path/file.json\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,config_file):\n",
    "        self.config = {}\n",
    "        with open(config_file) as j: \n",
    "            self.config = json.load(j)\n",
    "\n",
    "    def env_parameters(self,item=''):   \n",
    "        \"\"\"environment variables \n",
    "        \"\"\" \n",
    "        if item:\n",
    "            return self.config[\"env\"][item]\n",
    "        else:\n",
    "            return self.config[\"env\"]\n",
    "        \n",
    "    def symbol(self, asset=\"GBPUSD\", item='') :\n",
    "        \"\"\"get trading pair (symbol) information\n",
    "\n",
    "        Args:\n",
    "            asset (str, optional): symbol in config. Defaults to \"GBPUSD\".\n",
    "            item (str, optional): name of item, if '' return dict, else return item value. Defaults to ''.\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        if item:\n",
    "            return self.config[\"symbol\"][asset][item]\n",
    "        else:\n",
    "            return self.config[\"symbol\"][asset]\n",
    "        \n",
    "    def data_processing_parameters(self, item=''):\n",
    "        \"\"\"Get data processing config\"\"\"\n",
    "        if item:\n",
    "            return self.config[\"data_processing\"][item]\n",
    "        return self.config[\"data_processing\"]\n",
    "            \n",
    "    def trading_hour(self,place=\"New York\"):\n",
    "        \"\"\"forex trading hour from different markets\n",
    "\n",
    "        Args:\n",
    "            place (str, optional): [Sydney,Tokyo,London] Defaults to \"New York\".\n",
    "\n",
    "        Returns:\n",
    "            [dict]: from time, to time\n",
    "        \"\"\"\n",
    "        if place:\n",
    "            return self.config[\"trading_hour\"][place]\n",
    "        else:\n",
    "            return self.config[\"trading_hour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "10bd17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_missing_data(df, dt_col_name='time', cf=None):\n",
    "    min_bars = cf.data_processing_parameters(\"min_bars_per_week\")\n",
    "\n",
    "        # [\"time\",\"open\", \"high\", \"low\", \"close\"]\n",
    "    required_cols = cf.data_processing_parameters(\"required_cols\")    \n",
    "    \n",
    "    # df မှာ 6 columns ရှိရင် vol ပါထည့်မယ် \n",
    "    if df.shape[1] == 6:\n",
    "        df.columns = required_cols + ['vol']  \n",
    "    elif df.shape[1] == 5:\n",
    "        df.columns = required_cols\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid number of columns: {df.shape[1]} =>{required_cols}\")\n",
    "    \n",
    "    logger.warning(f\"shape of  column: {df.shape[1]}\")\n",
    "    # 1. Column validation\n",
    "    if missing := set(required_cols) - set(df.columns):\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    # 2. Auto-detect datetime column\n",
    "    dt_candidates = {'time', 'timestamp', 'date', 'datetime'}\n",
    "    if dt_col_name not in df.columns:\n",
    "        found = list(dt_candidates & set(df.columns))\n",
    "        if not found:\n",
    "            raise KeyError(f\"No datetime column found. Tried: {dt_candidates}\")\n",
    "        dt_col_name = found[0]\n",
    "        logger.info(f\"Using datetime column: {dt_col_name}\")\n",
    "\n",
    "    # 3. Convert to datetime index\n",
    "    df[dt_col_name] = pd.to_datetime(df[dt_col_name], utc=True)\n",
    "    df = df.set_index(dt_col_name).sort_index()\n",
    "\n",
    "    # Week by Week Group (Friday-end week)\n",
    "    groups = df.groupby(pd.Grouper(freq='W-FRI'))\n",
    "\n",
    "    patched_weeks = []  # patched weekly df storage\n",
    "\n",
    "    for w, week_df in groups:\n",
    "        if week_df.empty:\n",
    "            continue\n",
    "\n",
    "        if len(week_df) != min_bars:\n",
    "            logger.warning(f\"Week {w} has {len(week_df)}/{min_bars} bars\")\n",
    "\n",
    "        # Create 5-minute frequency index\n",
    "        new_index = pd.date_range(\n",
    "            start=week_df.index.min(),\n",
    "            end=week_df.index.max(),\n",
    "            freq='5min',\n",
    "            tz='UTC'\n",
    "        )\n",
    "\n",
    "        # Reindex + forward fill\n",
    "        week_df = week_df.reindex(new_index)\n",
    "        fill_limit = 12 # ဥပမာ: 1 နာရီ (12 bars) ထက်ပိုတဲ့ ကွက်လပ်ကို မဖြည့်ပါ\n",
    "        fill_cols = ['open', 'high', 'low', 'close', 'vol'] if 'vol' in df.columns else ['open', 'high', 'low', 'close']\n",
    "        # FFill: ရှေ့က data ဖြင့် ဖြည့်ပါ\n",
    "        week_df[fill_cols] = week_df[fill_cols].ffill(limit=fill_limit)\n",
    "        patched_weeks.append(week_df)\n",
    "\n",
    "    # Merge back all weeks\n",
    "    if patched_weeks:\n",
    "        all_df = pd.concat(patched_weeks)\n",
    "    else:\n",
    "        all_df = df.copy()\n",
    "\n",
    "    return all_df.reset_index().rename(columns={'index': dt_col_name})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "44b015ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_feature(df, symbol):\n",
    "    \"\"\"Add temporal features with proper index handling\"\"\"\n",
    "    \n",
    "    if 'time' not in df.columns:\n",
    "        raise KeyError(\"'time' column missing after patch_missing_data\")\n",
    "        \n",
    "    df = df.set_index('time')\n",
    "    df.index = pd.to_datetime(df.index, utc=True)\n",
    "    \n",
    "    # Cyclical time features\n",
    "    df['weekday'] = df.index.dayofweek  # 0=Monday\n",
    "    df['day'] = df.index.day\n",
    "    df['week'] = df.index.isocalendar().week\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['hour'] = df.index.hour\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour']/24).round(6)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour']/24).round(6)\n",
    "    df['minute_block'] = df.index.minute // 5  # 0-11\n",
    "    df['minute_sin'] = np.sin(2 * np.pi * df['minute_block']/12).round(6)\n",
    "    df['minute_cos'] = np.cos(2 * np.pi * df['minute_block']/12).round(6)\n",
    "    \n",
    "    # Market sessions (GMT)\n",
    "    df['london_session'] = ((df['hour'] >= 8) & (df['hour'] < 16)).astype(int)\n",
    "    df['ny_session'] = ((df['hour'] >= 13) & (df['hour'] < 21)).astype(int)\n",
    "    df['overlap_session'] = ((df['hour'] >= 13) & (df['hour'] < 16)).astype(int)\n",
    "    \n",
    "    df['symbol'] = symbol\n",
    "    return df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67881b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tech_indicators(df, cf=None):  # 288 = 24hrs in 5-min bars\n",
    "    \"\"\"Calculate technical indicators with proper NaN handling\"\"\"\n",
    "    period = cf.data_processing_parameters(\"indicator_period\")\n",
    "    # 1. Preserve raw prices before normalization\n",
    "    raw_cols = ['mean_std_open','mean_std_high','mean_std_low','mean_std_close']\n",
    "    df[raw_cols] = df[['open','high','low','close']].copy()\n",
    "    # Calculate indicators\n",
    "    df['macd'] = TA.MACD(df).SIGNAL.ffill().round(6)\n",
    "    bb = TA.BBANDS(df)\n",
    "    df['boll_ub'] = bb['BB_UPPER'].ffill()\n",
    "    df['boll_lb'] = bb['BB_LOWER'].ffill()\n",
    "    \n",
    "    df['rsi_30'] = TA.RSI(df, period=period).ffill()\n",
    "    df['dx_30'] = TA.ADX(df, period=period).ffill()\n",
    "    df['close_30_sma'] = TA.SMA(df, period=period).ffill()\n",
    "    df['close_60_sma'] = TA.SMA(df, period=period*2).ffill()\n",
    "    df['atr'] = TA.ATR(df, period=period).ffill()\n",
    "     # Add returns and volatility ratio\n",
    "    df['returns_5'] = df['close'].pct_change(5,fill_method=None).round(6)\n",
    "    df['returns_24'] = df['close'].pct_change(24,fill_method=None).round(6)\n",
    "    df['volatility_ratio'] = (df['high'] - df['low']) / df['close'].round(6)\n",
    "        \n",
    "    # Normalize\n",
    "    scaler = StandardScaler()\n",
    "    scale_cols = cf.data_processing_parameters(\"scale_cols\")  \n",
    "\n",
    "    df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    # 1. Identify numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    # 2. Apply clipping only to numeric features\n",
    "    df[numeric_cols] = df[numeric_cols].clip(lower=-1e5, upper=1e5)\n",
    "    # 3. Round decimal values\n",
    "    df[numeric_cols] = df[numeric_cols].round(6).clip(-1e5, 1e5)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4f8cae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesScaler:\n",
    "    \"\"\"\n",
    "    Manages the MinMax Scaling process for time series features.\n",
    "    It fits the scaler on the first chunk of data (expected to be the training start)\n",
    "    and uses that fitted scaler to transform all subsequent data chunks (including eval).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # MinMaxScaler ကို အသုံးပြုပြီး 0 နဲ့ 1 ကြားကို ပြောင်းပါ\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.is_fitted = False\n",
    "        self.price_cols = ['mean_std_open', 'mean_std_high', 'mean_std_low', 'mean_std_close']\n",
    "        \n",
    "    def fit_and_transform(self, df):\n",
    "        \"\"\"Fit the scaler on the data and transform it.\"\"\"\n",
    "        logger.info(\"Fitting Scaler on current week data (TRAIN set base)\")\n",
    "        # .copy() လုပ်ပြီးမှ transform လုပ်ပါ\n",
    "        df_copy = df.copy() \n",
    "        df_copy[self.price_cols] = self.scaler.fit_transform(df_copy[self.price_cols])\n",
    "        self.is_fitted = True\n",
    "        return df_copy\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"Transform data using the previously fitted scaler.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Scaler must be fitted on the training data first!\")\n",
    "            \n",
    "        logger.info(\"Transforming current week data using fitted scaler.\")\n",
    "        # .copy() လုပ်ပြီးမှ transform လုပ်ပါ\n",
    "        df_copy = df.copy() \n",
    "        df_copy[self.price_cols] = self.scaler.transform(df_copy[self.price_cols])\n",
    "        return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time_series_v2(df, symbol='EURUSD', cf=None, scaler_manager=None):\n",
    "    \"\"\"\n",
    "    Split data with weekly alignment, adds a lookback context (overlap) from the\n",
    "    previous week for continuous sequence processing (e.g., Transformer), \n",
    "    and performs MinMax scaling.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input Time Series Data.\n",
    "        freq (str): Frequency string for pandas Grouper (e.g., 'W-FRI' for weekly split ending Friday).\n",
    "        symbol (str): Trading symbol.\n",
    "        cf (object): Configuration manager.\n",
    "        scaler_manager (object): TimeSeriesScaler instance.\n",
    "        sequence_length (int): The lookback window size needed for the Transformer.\n",
    "    \"\"\"\n",
    "    if scaler_manager is None:\n",
    "        raise ValueError(\"scaler_manager (TimeSeriesScaler instance) must be provided.\")\n",
    "\n",
    "    split_cfg = cf.data_processing_parameters(\"train_eval_split\")\n",
    "    base_path = split_cfg[\"base_path\"].format(symbol=symbol)\n",
    "\n",
    "    sequence_length = cf.data_processing_parameters(\"sequence_length\")\n",
    "        \n",
    "    # Align with Forex week (Monday-Friday/Sunday)\n",
    "    # df['time'] သည် ဤနေရာတွင် datetime object ဖြစ်ရမည်။\n",
    "    if 'time' in df.columns:\n",
    "        df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "        df = df.set_index('time')\n",
    "    elif not pd.api.types.is_datetime64_any_dtype(df.index):\n",
    "        raise ValueError(\"DataFrame must have a 'time' column or a datetime index.\")\n",
    "    \n",
    "    # W-FRI သည် သောကြာနေ့တွင် အဆုံးသတ်သော အပတ်ကို ကိုယ်စားပြုသည်။\n",
    "    groups = df.groupby(pd.Grouper(freq='W-FRI'))\n",
    "    \n",
    "    # Indicators columns\n",
    "    indicator_cols = ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'dx_30', 'close_30_sma', 'close_60_sma', 'atr']\n",
    "    \n",
    "    \n",
    "    prev_week_df = None # ယခင် Week ရဲ့ DataFrame အပြည့်အစုံကို သိမ်းဆည်းရန်\n",
    "    \n",
    "    # Loop စတင်ခြင်း\n",
    "    for week_start, week_df in groups:\n",
    "        if week_df.empty:\n",
    "            continue\n",
    "        \n",
    "        # 1. Context (Overlap Data) ကို ဆုံးဖြတ်ခြင်း\n",
    "        # [NEW ACTION] ယခင် Week ရဲ့ နောက်ဆုံး sequence_length စာရှိတဲ့ data ကို ဖြတ်ယူပြီး ကပ်ပါ\n",
    "        context_df = pd.DataFrame() \n",
    "        if prev_week_df is not None:\n",
    "            # နောက်ဆုံး sequence_length စာ rows ကို ဖြတ်ယူပါ\n",
    "            # NOTE: Index Slicing မှန်စေရန် .iloc ကို အသုံးပြုပါ\n",
    "            context_df = prev_week_df.iloc[-sequence_length:].copy()\n",
    "        \n",
    "        # [NEW ACTION] လက်ရှိ week_df နဲ့ Context ကို ပေါင်းစပ်ခြင်း\n",
    "        # Concat လုပ်ရာတွင် index ကို ဆက်ထိန်းထားရပါမည် (ignore_index=False)\n",
    "        # Context သည် week_df ၏ ရှေ့တွင် ရှိရမည်\n",
    "        current_chunk = pd.concat([context_df, week_df])\n",
    "        \n",
    "        # 2. Check raw indicators to determine Eval set (Data Leakage မဖြစ်စေရန်)\n",
    "        # Check လုပ်ရာတွင် context မပါသော week_df ကိုသာ အသုံးပြုသင့်သည်၊ သို့မဟုတ်\n",
    "        # context မပါသော ပထမဆုံး row ကိုသာ အသုံးပြုသင့်သည်။\n",
    "        first_row = week_df[indicator_cols].iloc[0] # week_df (context မပါ) ကိုသာ စစ်ဆေး\n",
    "        has_nan = first_row.isna().any()\n",
    "        has_zero = (first_row == 0).any()\n",
    "        is_eval = has_nan or has_zero # Indicator များ မပြည့်စုံသေးသော အပတ်ကို Eval အဖြစ် သတ်မှတ်\n",
    "        \n",
    "        # # Data အရေအတွက် စစ်ဆေးခြင်း (1440 bars per week)\n",
    "        # if len(week_df) < 1440: # Context ပါသော current_chunk ကို စစ်ဆေးရန် မလို\n",
    "        #     logger.warning(f\"Skipping {week_start}: {len(week_df)}/{1440} bars (original week)\")\n",
    "        #     continue\n",
    "        \n",
    "        # 3. Normalize and validate (Fit-Transform Logic)\n",
    "        if not scaler_manager.is_fitted and not is_eval:\n",
    "            # Scaler ကို ပထမဆုံးသော၊ Indicators ပြည့်စုံသော (is_eval=False) Training Set တွင် Fit လုပ်ပါ\n",
    "            # [ACTION] Fit လုပ်ပြီး Transform လုပ်မည့် data မှာ Context ပါဝင်ရန် မလို၊ Original Data ကိုသာ Fit လုပ်ရမည်\n",
    "            # [ACTION] Fit လုပ်ပြီး Transform လုပ်မည့် data မှာ Context မပါဝင်ရန် \n",
    "            week_df_transformed = scaler_manager.fit_and_transform(current_chunk) # Context ပါသော chunk ကို Transform\n",
    "            dir_type = 'train'\n",
    "        elif scaler_manager.is_fitted:\n",
    "            # Scaler Fit ပြီးပါက၊ Train နှင့် Eval နှစ်ခုလုံးကို Transform လုပ်ပါ\n",
    "            # [ACTION] Context ပါသော chunk ကို Transform\n",
    "            week_df_transformed = scaler_manager.transform(current_chunk)\n",
    "            dir_type = 'eval' if is_eval else 'train'\n",
    "        else:\n",
    "            # Fit မလုပ်ရသေးဘဲ is_eval ဖြစ်နေရင် ကျော်သွားပါ\n",
    "            logger.warning(f\"Skipping {week_start}: Indicators not ready for fitting and not fitted yet.\")\n",
    "            # [ACTION] နောက်တစ်ကြိမ်အတွက် prev_week_df ကိုလည်း update လုပ်ရန် လိုအပ်သည် (မသိမ်းမီ)\n",
    "            prev_week_df = week_df.copy() \n",
    "            continue\n",
    "\n",
    "        # 4. Save to appropriate directory\n",
    "        path = os.path.join(base_path, split_cfg[f\"{dir_type}_dir\"])\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        iso_year, iso_week, _ = week_start.isocalendar()\n",
    "        fname = f\"{symbol}_{iso_year}_{iso_week:02d}.csv\"\n",
    "        \n",
    "        # [ACTION] Context ပါဝင်ပြီး၊ Normalize ပြီးသော DataFrame ကိုသာ သိမ်းပါ\n",
    "        week_df_transformed.reset_index().to_csv(f\"{path}/{fname}\", index=False)\n",
    "        logger.critical(f\"Saved {dir_type} file: {fname} (Total rows: {len(week_df_transformed)})\")\n",
    "\n",
    "        # 5. လက်ရှိ week_df ကို နောက်တစ်ကြိမ်အတွက် Context အဖြစ် မှတ်သားခြင်း\n",
    "        # [ACTION] prev_week_df သည် Context မပါဝင်သေးသော Original Week Data ဖြစ်ရမည်။\n",
    "        prev_week_df = week_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "601984af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022-03-16 15:25</th>\n",
       "      <th>1.10006</th>\n",
       "      <th>1.10027</th>\n",
       "      <th>1.09966</th>\n",
       "      <th>1.1002</th>\n",
       "      <th>679</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2024-11-15 02:45</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05426</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2024-11-15 02:50</td>\n",
       "      <td>1.05399</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2024-11-15 02:55</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.05410</td>\n",
       "      <td>1170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        2022-03-16 15:25  1.10006  1.10027  1.09966   1.1002   679\n",
       "199996  2024-11-15 02:45  1.05378  1.05426  1.05378  1.05398  1085\n",
       "199997  2024-11-15 02:50  1.05399  1.05416  1.05398  1.05416   964\n",
       "199998  2024-11-15 02:55  1.05416  1.05422  1.05405  1.05410  1170"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = 'EURUSD'\n",
    "file = f'./drive/MyDrive/data/raw/{symbol}_M5.csv'\n",
    "# 1. Load & clean\n",
    "raw = pd.read_csv(file)\n",
    "raw.tail(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bf193cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "shape of  column: 6\n",
      "Week 2022-03-18 00:00:00+00:00 has 678/1440 bars\n",
      "Week 2022-04-01 00:00:00+00:00 has 1404/1440 bars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Week 2022-07-29 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2022-08-19 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2022-10-14 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2022-10-21 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2022-11-04 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2022-12-30 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2023-01-06 00:00:00+00:00 has 1436/1440 bars\n",
      "Week 2023-01-27 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2023-02-03 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2023-03-10 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2023-03-17 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2023-04-07 00:00:00+00:00 has 1436/1440 bars\n",
      "Week 2023-05-05 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2023-05-12 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2023-05-19 00:00:00+00:00 has 1438/1440 bars\n",
      "Week 2023-06-02 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2023-06-16 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2023-06-23 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2023-07-07 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2023-08-18 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2023-09-15 00:00:00+00:00 has 1437/1440 bars\n",
      "Week 2023-09-22 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2023-09-29 00:00:00+00:00 has 1430/1440 bars\n",
      "Week 2023-12-01 00:00:00+00:00 has 1419/1440 bars\n",
      "Week 2023-12-29 00:00:00+00:00 has 1249/1440 bars\n",
      "Week 2024-01-05 00:00:00+00:00 has 1152/1440 bars\n",
      "Week 2024-05-03 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2024-05-17 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2024-06-21 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2024-06-28 00:00:00+00:00 has 1439/1440 bars\n",
      "Week 2024-07-05 00:00:00+00:00 has 1438/1440 bars\n",
      "Week 2024-10-11 00:00:00+00:00 has 1428/1440 bars\n",
      "Week 2024-11-15 00:00:00+00:00 has 1212/1440 bars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200271</th>\n",
       "      <td>2024-11-15 02:45:00+00:00</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05426</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200272</th>\n",
       "      <td>2024-11-15 02:50:00+00:00</td>\n",
       "      <td>1.05399</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200273</th>\n",
       "      <td>2024-11-15 02:55:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.05410</td>\n",
       "      <td>1170.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time     open     high      low    close     vol\n",
       "200271 2024-11-15 02:45:00+00:00  1.05378  1.05426  1.05378  1.05398  1085.0\n",
       "200272 2024-11-15 02:50:00+00:00  1.05399  1.05416  1.05398  1.05416   964.0\n",
       "200273 2024-11-15 02:55:00+00:00  1.05416  1.05422  1.05405  1.05410  1170.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = EnvConfig('./drive/MyDrive/configure.json')  \n",
    "df = patch_missing_data(raw,cf=cf)\n",
    "df.tail(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e1a0c856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>minute_block</th>\n",
       "      <th>minute_sin</th>\n",
       "      <th>minute_cos</th>\n",
       "      <th>london_session</th>\n",
       "      <th>ny_session</th>\n",
       "      <th>overlap_session</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200271</th>\n",
       "      <td>2024-11-15 02:45:00+00:00</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05426</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200272</th>\n",
       "      <td>2024-11-15 02:50:00+00:00</td>\n",
       "      <td>1.05399</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>964.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200273</th>\n",
       "      <td>2024-11-15 02:55:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.05410</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EURUSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time     open     high      low    close     vol  \\\n",
       "200271 2024-11-15 02:45:00+00:00  1.05378  1.05426  1.05378  1.05398  1085.0   \n",
       "200272 2024-11-15 02:50:00+00:00  1.05399  1.05416  1.05398  1.05416   964.0   \n",
       "200273 2024-11-15 02:55:00+00:00  1.05416  1.05422  1.05405  1.05410  1170.0   \n",
       "\n",
       "        weekday  day  week  month  ...  hour  hour_sin  hour_cos  \\\n",
       "200271        4   15    46     11  ...     2       0.5  0.866025   \n",
       "200272        4   15    46     11  ...     2       0.5  0.866025   \n",
       "200273        4   15    46     11  ...     2       0.5  0.866025   \n",
       "\n",
       "        minute_block  minute_sin  minute_cos  london_session  ny_session  \\\n",
       "200271             9   -1.000000   -0.000000               0           0   \n",
       "200272            10   -0.866025    0.500000               0           0   \n",
       "200273            11   -0.500000    0.866025               0           0   \n",
       "\n",
       "        overlap_session  symbol  \n",
       "200271                0  EURUSD  \n",
       "200272                0  EURUSD  \n",
       "200273                0  EURUSD  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Feature engineering\n",
    "df = add_time_feature(df, symbol=symbol)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dfe15964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>atr</th>\n",
       "      <th>returns_5</th>\n",
       "      <th>returns_24</th>\n",
       "      <th>volatility_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200271</th>\n",
       "      <td>2024-11-15 02:45:00+00:00</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05426</td>\n",
       "      <td>1.05378</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054321</td>\n",
       "      <td>1.053070</td>\n",
       "      <td>-0.611885</td>\n",
       "      <td>1.157269</td>\n",
       "      <td>1.053982</td>\n",
       "      <td>1.056578</td>\n",
       "      <td>0.612940</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200272</th>\n",
       "      <td>2024-11-15 02:50:00+00:00</td>\n",
       "      <td>1.05399</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05398</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>964.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054375</td>\n",
       "      <td>1.053093</td>\n",
       "      <td>-0.564441</td>\n",
       "      <td>1.151940</td>\n",
       "      <td>1.053979</td>\n",
       "      <td>1.056563</td>\n",
       "      <td>0.608299</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200273</th>\n",
       "      <td>2024-11-15 02:55:00+00:00</td>\n",
       "      <td>1.05416</td>\n",
       "      <td>1.05422</td>\n",
       "      <td>1.05405</td>\n",
       "      <td>1.05410</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054409</td>\n",
       "      <td>1.053130</td>\n",
       "      <td>-0.579196</td>\n",
       "      <td>1.146514</td>\n",
       "      <td>1.053976</td>\n",
       "      <td>1.056548</td>\n",
       "      <td>0.600307</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time     open     high      low    close     vol  \\\n",
       "200271 2024-11-15 02:45:00+00:00  1.05378  1.05426  1.05378  1.05398  1085.0   \n",
       "200272 2024-11-15 02:50:00+00:00  1.05399  1.05416  1.05398  1.05416   964.0   \n",
       "200273 2024-11-15 02:55:00+00:00  1.05416  1.05422  1.05405  1.05410  1170.0   \n",
       "\n",
       "        weekday  day  week  month  ...   boll_ub   boll_lb    rsi_30  \\\n",
       "200271        4   15    46     11  ...  1.054321  1.053070 -0.611885   \n",
       "200272        4   15    46     11  ...  1.054375  1.053093 -0.564441   \n",
       "200273        4   15    46     11  ...  1.054409  1.053130 -0.579196   \n",
       "\n",
       "           dx_30  close_30_sma  close_60_sma       atr  returns_5  returns_24  \\\n",
       "200271  1.157269      1.053982      1.056578  0.612940  -0.000057    0.001197   \n",
       "200272  1.151940      1.053979      1.056563  0.608299   0.000104    0.001187   \n",
       "200273  1.146514      1.053976      1.056548  0.600307   0.000161    0.000988   \n",
       "\n",
       "        volatility_ratio  \n",
       "200271          0.000455  \n",
       "200272          0.000171  \n",
       "200273          0.000161  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = tech_indicators(df, cf=cf) \n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c5e9af0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping 2022-03-18 00:00:00+00:00: Indicators not ready for fitting and not fitted yet.\n",
      "Saved train file: EURUSD_2022_12.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_13.csv (Total rows: 1424)\n",
      "Saved train file: EURUSD_2022_14.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_15.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_16.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_17.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_18.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_19.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_20.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_21.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_22.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_23.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_24.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_25.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_26.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_27.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_28.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_29.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_30.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_31.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_32.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_33.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_34.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_35.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_36.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_37.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_38.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_39.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_40.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_41.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_42.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_43.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_44.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_45.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_46.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_47.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_48.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_49.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_50.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_51.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2022_52.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_01.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_02.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_03.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_04.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_05.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_06.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_07.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_08.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_09.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_10.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_11.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_12.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_13.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_14.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_15.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_16.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_17.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_18.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_19.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_20.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_21.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_22.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_23.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_24.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_25.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_26.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_27.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_28.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_29.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_30.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_31.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_32.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_33.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_34.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_35.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_36.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_37.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_38.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_39.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_40.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_41.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_42.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_43.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_44.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_45.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_46.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_47.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_48.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_49.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_50.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_51.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2023_52.csv (Total rows: 1448)\n",
      "Saved train file: EURUSD_2024_01.csv (Total rows: 1172)\n",
      "Saved train file: EURUSD_2024_02.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_03.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_04.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_05.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_06.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_07.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_08.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_09.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_10.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_11.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_12.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_13.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_14.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_15.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_16.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_17.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_18.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_19.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_20.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_21.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_22.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_23.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_24.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_25.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_26.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_27.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_28.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_29.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_30.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_31.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_32.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_33.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_34.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_35.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_36.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_37.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_38.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_39.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_40.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_41.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_42.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_43.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_44.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_45.csv (Total rows: 1460)\n",
      "Saved train file: EURUSD_2024_46.csv (Total rows: 1232)\n"
     ]
    }
   ],
   "source": [
    "# Scaler instance ကို တည်ဆောက်ပါ\n",
    "scaler_manager = TimeSeriesScaler()\n",
    "\n",
    "# Function ကို ခေါ်ပါ\n",
    "split_time_series_v2(df, freq='W-FRI', symbol=symbol, cf=cf, scaler_manager=scaler_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c4024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
