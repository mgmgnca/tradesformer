## rollout/approx_kl (Approximate Kullback-Leibler Divergence)

![Ep approx_kl](../assets/approx_kl.png)

Approx. KL á€†á€­á€¯á€á€¬á€€
```
"á€šá€á€„á€º policy (Ï€_old) á€”á€²á€· á€¡á€žá€…á€ºá€•á€¼á€±á€¬á€„á€ºá€¸á€”á€±á€á€²á€· policy (Ï€_new) á€€á€¼á€¬á€¸á€™á€¾á€¬ á€˜á€šá€ºá€œá€±á€¬á€€á€ºá€€á€½á€¬á€žá€œá€²" á€†á€­á€¯á€á€¬ á€á€­á€¯á€„á€ºá€¸á€á€¬á€á€²á€· metric á€–á€¼á€…á€ºá€á€šá€ºá‹
```

á€†á€­á€¯á€œá€­á€¯á€á€¬á€€ â€” PPO á€Ÿá€¬ policy gradient method á€á€…á€ºá€á€¯á€–á€¼á€…á€ºá€á€²á€·á€¡á€á€½á€€á€º
á€”á€²á€· gradient step á€á€…á€ºá€á€¯á€•á€¼á€®á€¸á€á€­á€¯á€„á€ºá€¸ policy distribution á€€ á€•á€¼á€±á€¬á€„á€ºá€¸á€žá€½á€¬á€¸á€á€á€ºá€á€šá€ºá‹
á€¡á€²á€·á€’á€«á€€á€¼á€±á€¬á€„á€·á€º á€•á€¼á€±á€¬á€„á€ºá€¸á€œá€½á€”á€ºá€¸á€›á€„á€º unstable á€–á€¼á€…á€ºá€”á€­á€¯á€„á€ºá€á€šá€ºá‹

## Using in PPO
-   Clipping Loss á€™á€¾á€¬ policy ration (r_t) á€€á€­á€¯ clip á€œá€¯á€•á€ºá€á€²á€·á€¡á€á€« KL divergence á€€ indirect protection á€á€…á€ºá€á€¯á€–á€¼á€…á€ºá€á€šá€º
-   Monitor Metric á€¡á€”á€±á€”á€²á€·á€œá€Šá€ºá€¸ á€žá€¯á€¶á€¸á€á€šá€º

## Others
-   KL á€€á€­á€¯ adaptive clipping á€¡á€”á€±á€”á€²á€·á€œá€Šá€ºá€¸ á€žá€¯á€¶á€¸á€œá€­á€¯á€·á€›á€á€šá€º
    KL á€á€€á€ºá€œá€¬á€›á€„á€º clip_range á€œá€»á€±á€¬á€·
    KL á€”á€­á€™á€ºá€·á€”á€±á€›á€„á€º clip_range á€á€­á€¯á€¸


approx_kl --> á€…á€±á€¬á€„á€ºá€·á€€á€¼á€Šá€·á€ºá€–á€­á€¯á€·
clip_range --> á€á€¬á€¸á€†á€®á€¸á€–á€­á€¯á€·
-   policy á€¡á€žá€…á€ºá€”á€²á€· á€¡á€Ÿá€±á€¬á€„á€ºá€¸ á€™á€œá€½á€”á€ºá€¡á€±á€¬á€„á€º á€¡á€€á€”á€ºá€·á€‘á€¬á€¸á€á€²á€· control

r_t = Ï€_new / Ï€_old á€€ 1.0 á€¡á€á€½á€„á€ºá€¸

Îµ = 0.2 á€†á€­á€¯á€›á€„á€º --> r_t á€€á€­á€¯ [0.8, 1.2] á€‘á€²á€™á€¾á€¬á€•á€² á€á€½á€„á€·á€ºá€•á€¼á€¯á€á€šá€ºá‹ (1 + 0.2) and (1 - 0.2)

ðŸ§  á€á€…á€ºá€á€½á€”á€ºá€¸á€”á€²á€·á€†á€­á€¯á€›á€„á€º
clip_range á€žá€Šá€º á€œá€€á€ºá€”á€²á€·á€á€¬á€¸á€á€šá€ºá‹
approx_kl á€žá€Šá€º á€™á€»á€€á€ºá€œá€¯á€¶á€¸á€”á€²á€·á€…á€±á€¬á€„á€ºá€·á€á€šá€ºá‹



## Adaptive Clipping Logic
KL > target_kl á€›á€„á€º clip_range á€€á€­á€¯á€€á€»á€‰á€ºá€¸ (tighten)
KL < target_kl á€›á€„á€º clip_range á€€á€­á€¯á€€á€»á€šá€º (loosen)


## 0M - 1.5M 
-   á€¤á€€á€¬á€œá€á€½á€„á€º Agent á€žá€Šá€º á€…á€á€„á€ºá€žá€„á€ºá€šá€°á€”á€±á€†á€²á€–á€¼á€…á€ºá€•á€¼á€®á€¸áŠ Policy Update á€™á€»á€¬á€¸á€žá€Šá€º á€¡á€œá€½á€”á€ºá€žá€±á€¸á€„á€šá€ºá€žá€Šá€ºá‹ Policy Network á€žá€Šá€º á€žá€­á€žá€¬á€žá€±á€¬ á€•á€¼á€±á€¬á€„á€ºá€¸á€œá€²á€™á€¾á€¯á€™á€›á€¾á€­á€žá€±á€¸á€•á€«á‹

## 1.5M - 2.0M
-   á€¤á€€á€¬á€œá€¡á€á€½á€„á€ºá€¸ Policy Update á€™á€»á€¬á€¸ á€žá€­á€žá€­á€žá€¬á€žá€¬ á€€á€¼á€®á€¸á€™á€¬á€¸á€œá€¬á€•á€¼á€®á€¸ Policy á€¡á€žá€…á€ºá€žá€Šá€º Policy á€¡á€Ÿá€±á€¬á€„á€ºá€¸á€™á€¾ á€á€½á€²á€‘á€½á€€á€ºá€žá€½á€¬á€¸á€žá€Šá€ºá‹ áŽá€„á€ºá€¸á€žá€Šá€º Agent á€žá€Šá€º á€•á€­á€¯á€™á€­á€¯á€€á€±á€¬á€„á€ºá€¸á€™á€½á€”á€ºá€žá€±á€¬ Policy (á€™á€Ÿá€¬á€—á€»á€°á€Ÿá€¬) á€€á€¼á€®á€¸á€á€…á€ºá€á€¯á€€á€­á€¯ á€›á€¾á€¬á€–á€½á€±á€á€½á€±á€·á€›á€¾á€­á€á€¼á€„á€ºá€¸ (Rollout Reward á€á€€á€ºá€œá€¬á€á€¼á€„á€ºá€¸á€”á€¾á€„á€·á€º á€€á€­á€¯á€€á€ºá€Šá€®á€žá€Šá€º) á€€á€­á€¯ á€•á€¼á€žá€”á€­á€¯á€„á€ºá€žá€Šá€ºá‹

## 2.0M - 3.0M
-   KL á€á€”á€ºá€–á€­á€¯á€¸á€žá€Šá€º PPO á Target KL ($0.02$) á€‘á€€á€º á€žá€­á€žá€­á€žá€¬á€žá€¬ á€™á€¼á€„á€·á€ºá€™á€¬á€¸á€”á€±á€žá€Šá€º á€€á€­á€¯ á€á€½á€±á€·á€›á€žá€Šá€ºá‹


## á€†á€­á€¯á€¸á€€á€»á€­á€¯á€¸á€™á€»á€¬á€¸
-   Target KL á€€á€­á€¯ á€€á€»á€±á€¬á€ºá€œá€½á€”á€ºá€á€¼á€„á€ºá€¸á‹ PPO á€€á€­á€¯ 0.02 Target KL (clip_range á€žá€Šá€º 0.02) á€žá€á€ºá€™á€¾á€á€ºá€‘á€¬á€¸á€žá€±á€¬á€ºá€œá€Šá€ºá€¸
approx_kl á€žá€Šá€º Target á€€á€­á€¯ á€™á€»á€¬á€¸á€…á€½á€¬ á€€á€»á€±á€¬á€ºá€œá€½á€”á€ºá€”á€±á€•á€¼á€®á€¸ 0.03 - 0.04 á€á€”á€ºá€€á€»á€„á€ºá€á€½á€„á€ºá€›á€¾á€­á€”á€±á€žá€Šá€ºá‹
á€šá€„á€ºá€¸á€žá€Šá€º policy update á€¡á€œá€½á€”á€ºá€€á€¼á€®á€¸á€™á€¬á€¸á€”á€±á€á€¼á€„á€ºá€¸á€€á€­á€¯ á€•á€¼á€žá€žá€Šá€º

-   á€™á€á€Šá€ºá€„á€¼á€­á€™á€ºá€™á€¾á€¯ (Instability): KL á€á€”á€ºá€–á€­á€¯á€¸á€žá€Šá€º á€¡á€œá€½á€”á€ºá€¡á€™á€„á€ºá€¸ á€á€€á€ºá€œá€­á€¯á€€á€ºá€€á€»á€œá€­á€¯á€€á€ºá€–á€¼á€…á€ºá€”á€±á€•á€¼á€®á€¸ á€¡á€á€€á€ºá€€á€» á€•á€¼á€„á€ºá€¸á€‘á€”á€ºá€á€¼á€„á€ºá€¸á€žá€Šá€º
Batch Size (á€žá€­á€¯á€·á€™á€Ÿá€¯á€á€º) Learning Rate á€€á€¼á€®á€¸á€™á€¬á€¸á€œá€½á€”á€ºá€¸á€á€¼á€„á€ºá€¸á€€á€­á€¯ á€Šá€½á€”á€ºá€•á€¼á€”á€±á€žá€Šá€ºá‹

-   Over-Clipping: KL á€™á€¼á€„á€ºá€·á€™á€¬á€¸á€”á€±á€á€¼á€„á€ºá€¸á€žá€Šá€º train/clip_fraction (0.8) á€™á€¼á€„á€ºá€·á€™á€¬á€¸á€á€¼á€„á€ºá€¸á€”á€¾á€„á€ºá€·á€†á€€á€ºá€…á€•á€ºá€žá€Šá€«á‹ KL á€¡á€›á€™á€ºá€¸á€€á€¼á€®á€¸á€œá€¬á€á€²á€·á€¡á€á€« PPO á€€ clip á€œá€¯á€•á€ºá€á€¼á€„á€ºá€¸á€€á€­á€¯ á€•á€­á€¯á€™á€­á€¯á€•á€¼á€„á€ºá€¸á€‘á€”á€ºá€…á€½á€¬á€œá€¯á€•á€ºá€†á€±á€¬á€„á€ºá€•á€¼á€®á€¸ Policy Update á€™á€»á€¬á€¸á€€á€­á€¯ á€€á€”á€ºá€·á€žá€á€ºá€œá€­á€¯á€€á€ºá€žá€±á€¬á€€á€¼á€±á€¬á€„á€ºá€· á€žá€„á€ºá€šá€°á€™á€¾á€¯á€€á€­á€¯ á€‘á€­á€›á€±á€¬á€€á€ºá€™á€¾á€¯ á€€á€»á€†á€„á€ºá€¸á€žá€½á€¬á€¸á€”á€­á€¯á€„á€ºá€žá€Šá€ºá‹

## á€¡á€€á€¼á€¶á€•á€¼á€¯á€á€»á€€á€º
Policy Update á á€á€Šá€ºá€„á€¼á€­á€™á€ºá€™á€¾á€¯á€”á€¾á€„á€·á€º á€¡á€›á€Šá€ºá€¡á€žá€½á€±á€¸á€€á€­á€¯ á€™á€¼á€¾á€„á€·á€ºá€á€„á€ºá€›á€”á€º-
-   Learning Rate á€œá€»á€¾á€±á€¬á€·á€á€»á€€á€¼á€Šá€·á€ºá€á€¼á€„á€ºá€¸: 0.0001 á€€á€­á€¯ á€œá€»á€¾á€±á€¬á€·á€á€»á€€á€¼á€Šá€·á€ºá€•á€« á‹ áŽá€„á€ºá€¸á€žá€Šá€º Policy Update á á€á€¼á€±á€œá€¾á€™á€ºá€¸ á€¡á€›á€½á€šá€ºá€¡á€…á€¬á€¸á€€á€­á€¯ á€žá€±á€¸á€„á€šá€ºá€…á€±á€•á€¼á€®á€¸ KL Divergence á€€á€­á€¯ Target KL á€á€”á€ºá€¸á€€á€»á€„á€ºá€žá€­á€¯á€· á€•á€¼á€”á€ºá€†á€½á€²á€á€»á€”á€­á€¯á€„á€ºá€žá€Šá€ºá‹

-   n_epochs á€á€”á€ºá€–á€­á€¯á€¸á€€á€­á€¯ á€™á€¼á€¾á€„á€·á€ºá€á€„á€ºá€á€¼á€„á€ºá€¸: n_epochs (á€œá€€á€ºá€›á€¾á€­ 7) á€€á€­á€¯ á€™á€¼á€¾á€„á€·á€ºá€á€„á€ºá€•á€« (á€¥á€•á€™á€¬: 10 á€žá€­á€¯á€·á€™á€Ÿá€¯á€á€º 15)á‹ Rollout Data á€á€…á€ºá€á€¯á€á€Šá€ºá€¸á€€á€­á€¯ á€•á€­á€¯á€™á€­á€¯ á€€á€¼á€­á€™á€ºá€›á€± á€™á€»á€¬á€¸á€™á€»á€¬á€¸á€–á€¼á€„á€·á€º á€‘á€•á€ºá€á€«á€‘á€•á€ºá€á€« Update á€œá€¯á€•á€ºá€á€¼á€„á€ºá€¸á€žá€Šá€º KL á€á€”á€ºá€–á€­á€¯á€¸á€€á€­á€¯ á€œá€»á€¾á€±á€¬á€·á€á€»á€•á€¼á€®á€¸ á€á€Šá€ºá€„á€¼á€­á€™á€ºá€…á€±á€”á€­á€¯á€„á€ºá€žá€Šá€ºá‹