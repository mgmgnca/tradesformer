{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2892c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    A Transformer-based model for time series data.\n",
    "    This class projects input features to an embedding, adds positional\n",
    "    encodings, and then processes the inputs using a Transformer encoder.\n",
    "    Finally, a decoder layer is used to produce the output.\n",
    "    Args:\n",
    "        input_size (int): Number of features in the input time series data.\n",
    "        embed_dim (int): Dimensionality of the learned embedding space.\n",
    "        num_heads (int): Number of attention heads in each Transformer layer.\n",
    "        num_layers (int): Number of Transformer encoder layers.\n",
    "        sequence_length (int): Length of the input sequences (time steps).\n",
    "        dropout (float, optional): Dropout probability to apply in the\n",
    "            Transformer encoder layers. Defaults to 0.1.\n",
    "    Attributes:\n",
    "        model_type (str): Identifier for the model type ('Transformer').\n",
    "        embedding (nn.Linear): Linear layer for input feature embedding.\n",
    "        positional_encoding (torch.nn.Parameter): Parameter storing the\n",
    "            positional encodings used to retain temporal information.\n",
    "        transformer_encoder (nn.TransformerEncoder): Stack of Transformer\n",
    "            encoder layers with optional final LayerNorm.\n",
    "        decoder (nn.Linear): Linear layer used to produce the final output\n",
    "            dimensions.\n",
    "    Forward Inputs:\n",
    "        src (torch.Tensor): Input tensor of shape (batch_size, sequence_length,\n",
    "            input_size).\n",
    "    Forward Returns:\n",
    "        torch.Tensor: Output tensor of shape (batch_size, embed_dim) from the\n",
    "            last time step.\n",
    "    Raises:\n",
    "        ValueError: If the model output contains NaN or Inf values, indicating\n",
    "            numerical instability.\n",
    "    \"\"\"\n",
    "    # input_size: Input features အရေအတွက် (ဥပမာ 10၊ price + SMA/RSI indicators စတာ)။\n",
    "    # embed_dim: Internal embedding အတိုင်းအတာ (ဥပမာ 64၊ data ကို ပိုနက်ရှိုင်း အောင် ပြောင်း)။\n",
    "    # num_heads: Attention heads အရေအတွက် (multi-head attention အတွက်၊ မတူညီ အနေနဲ့ အာရုံ စိုက်)။\n",
    "    # num_layers: Encoder layers အရေအတွက် (ဥပမာ 2၊ ရိုးရှင်း ထားတာ)။\n",
    "    # sequence_length: Input sequence အရှည် (ဥပမာ 20 timesteps)။\n",
    "    # dropout=0.1: Overfitting ကနေ ကာကွယ် တဲ့ dropout rate။\n",
    "    def __init__(self, input_size, embed_dim, num_heads, num_layers,sequence_length, dropout=0.1):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Embedding layer to project input features to embed_dim dimensions\n",
    "        self.embedding = nn.Linear(input_size, embed_dim).to(device)\n",
    "\n",
    "        # Positional encoding parameter\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, sequence_length, embed_dim).to(device))\n",
    "\n",
    "        # Transformer encoder layer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dropout=dropout,\n",
    "            norm_first=True  # Apply LayerNorm before attention and feedforward\n",
    "        ).to(device)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "            norm=nn.LayerNorm(embed_dim).to(device) # Add LayerNorm at the end of the encoder\n",
    "        )\n",
    "\n",
    "        # Decoder layer to produce final output\n",
    "        self.decoder = nn.Linear(embed_dim, embed_dim).to(device)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # Apply embedding layer and add positional encoding\n",
    "        src = self.embedding(src) + self.positional_encoding\n",
    "\n",
    "        # Pass through the transformer encoder\n",
    "        output = self.transformer_encoder(src)\n",
    "\n",
    "        # Pass through the decoder layer\n",
    "        output = self.decoder(output)\n",
    "\n",
    "        # Check for NaN or Inf values for debugging\n",
    "        if torch.isnan(output).any() or torch.isinf(output).any():\n",
    "            logger.error(\"Transformer output contains NaN or Inf values\")\n",
    "            raise ValueError(\"Transformer output contains NaN or Inf values\")\n",
    "\n",
    "        # Return the output from the last time step\n",
    "        return output[:, -1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa2587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCombinedExtractor(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    A custom feature extractor that normalizes input observations and processes them\n",
    "    using a transformer-based architecture for dimensionality reduction and enhanced\n",
    "    feature representation.\n",
    "    Parameters:\n",
    "        observation_space (gym.spaces.Box): Defines the shape and limits of input data.\n",
    "        sequence_length (int): The length of the time series to be processed.\n",
    "    Attributes:\n",
    "        layernorm_before (nn.LayerNorm): Normalizes input data to improve training stability.\n",
    "        transformer (TimeSeriesTransformer): Processes normalized input sequences and extracts features.\n",
    "    Methods:\n",
    "        forward(observations):\n",
    "            Applies layer normalization to the incoming observations, then passes them\n",
    "            through the transformer. Raises a ValueError if invalid values (NaNs or inf)\n",
    "            are detected in the output.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, observation_space: gym.spaces.Box, sequence_length):\n",
    "        super(CustomCombinedExtractor, self).__init__(observation_space, features_dim=64)\n",
    "        num_features = observation_space.shape[1]  # Should be 10 in this case\n",
    "\n",
    "        # Ensure that embed_dim is divisible by num_heads\n",
    "        embed_dim = 64\n",
    "        num_heads = 2\n",
    "\n",
    "        self.layernorm_before = nn.LayerNorm(num_features) # Added Layer Normalization before transformer\n",
    "\n",
    "        self.transformer = TimeSeriesTransformer(\n",
    "            input_size=num_features,\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            num_layers=2,\n",
    "            sequence_length =sequence_length\n",
    "        )\n",
    "\n",
    "    def forward(self, observations):\n",
    "        # မူရင်း input tensor ရဲ့ device ကို မှတ်သားထားပါ\n",
    "        input_device = observations.device\n",
    "        \n",
    "        # Apply layer normalization\n",
    "        # Apply layer normalization, ဝင်လာတဲ့ observations ကို Transformer ရဲ့ device ပေါ်ကို ရွှေ့ပါ\n",
    "        normalized_observations = self.layernorm_before(observations.float().to(device)) # Ensure float type\n",
    "\n",
    "        x = self.transformer(normalized_observations)\n",
    "        if torch.isnan(x).any() or torch.isinf(x).any():\n",
    "            logger.error(\"Invalid values in transformer output\")\n",
    "            raise ValueError(\"Invalid values in transformer output\")\n",
    "        \n",
    "        # ⚠️ ပြင်ဆင်ချက်: Output tensor ကို မူရင်း input tensor ရဲ့ device သို့ ပြန်ပို့ပါ\n",
    "        # PPO Agent ရဲ့ Policy/Value Network က အလုပ်လုပ်တဲ့ device ပေါ်ကို ပြန်ပို့ဖို့ လိုပါတယ်။\n",
    "        # သို့သော်လည်း၊ Stable-Baselines3 က Policy/Value Network ကို နောက်ပိုင်းမှာ to(device) နဲ့ ရွှေ့တဲ့အတွက်\n",
    "        # ဒီနေရာမှာ အန္တရာယ်ကင်းအောင် မူရင်း input device ကို ပြန်ပို့တာ ဒါမှမဟုတ် Agent သုံးမယ့် device ပေါ်မှာပဲ ထားတာ နှစ်မျိုး လုပ်နိုင်ပါတယ်။\n",
    "        # အကောင်းဆုံးကတော့ Policy Network တွေက GPU ပေါ်မှာရှိရင် GPU မှာပဲ ထားခဲ့တာပါ။\n",
    "        \n",
    "        # သို့သော်လည်း၊ SB3 ရဲ့ စံနှုန်းကို လိုက်နာဖို့၊ CPU ပေါ်ကလာရင် CPU ကို ပြန်ပို့တာ ပိုကောင်းပါတယ်။\n",
    "        if str(input_device) == 'cpu':\n",
    "            return x.to(input_device)\n",
    "        else:\n",
    "             # Agent က GPU မှာ Run ရင်တော့ GPU မှာပဲ ထားခဲ့ပါ\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e58d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([4, 20, 10])\n"
     ]
    }
   ],
   "source": [
    "# Test အတွက် လိုအပ်တဲ့ parameters \n",
    "SEQ_LEN = 20\n",
    "INPUT_SIZE = 10\n",
    "EMBED_DIM = 64\n",
    "NUM_HEADS = 2\n",
    "NUM_LAYERS = 2\n",
    "BATCH_SIZE = 4 # တစ်ပြိုင်နက်တည်း ထည့်သွင်းမယ့် sample အရေအတွက်\n",
    "\n",
    "# Test အတွက် dummy data ကို ပြင်ဆင်ခြင်း\n",
    "# Shape: (Batch Size, Sequence Length, Input Size)\n",
    "dummy_observations = torch.randn(BATCH_SIZE, SEQ_LEN, INPUT_SIZE) \n",
    "\n",
    "# Dummy observation_space (gym.spaces.Box ကို အတုလုပ်သည်)\n",
    "class DummyObsSpace:\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "dummy_observation_space = DummyObsSpace((SEQ_LEN, INPUT_SIZE)) \n",
    "\n",
    "print(f\"Input Shape: {dummy_observations.shape}\")\n",
    "# Input Shape: torch.Size([4, 20, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb51a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Features Shape: torch.Size([4, 64])\n",
      "✅ Output Shape is Correct.\n",
      "Output Shape: torch.Size([4, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mgmgn\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Extractor ကို စတင်တည်ဆောက်\n",
    "extractor = CustomCombinedExtractor(\n",
    "    observation_space=dummy_observation_space, \n",
    "    sequence_length=SEQ_LEN\n",
    ").to(device) # Extractor ကို သတ်မှတ်ထားတဲ့ device ပေါ် ရွှေ့ပါ\n",
    "\n",
    "# 2. Forward Pass လုပ်ခြင်း\n",
    "# dummy_observations ကို device ပေါ်ကို ရွှေ့စရာမလို၊ extractor ရဲ့ forward ထဲမှာ သူ့ဘာသာ ရွှေ့ပါလိမ့်မယ်။\n",
    "output_features = extractor(dummy_observations) \n",
    "\n",
    "# 3. Output Shape ကို စစ်ဆေးခြင်း\n",
    "print(f\"Output Features Shape: {output_features.shape}\")\n",
    "\n",
    "# မျှော်မှန်းထားသော Output: (Batch Size, Feature Dimension/Embed Dim)\n",
    "EXPECTED_SHAPE = torch.Size([BATCH_SIZE, EMBED_DIM])\n",
    "\n",
    "assert output_features.shape == EXPECTED_SHAPE, \\\n",
    "    f\"Output shape error! Expected: {EXPECTED_SHAPE}, Got: {output_features.shape}\"\n",
    "print(\"✅ Output Shape is Correct.\")\n",
    "\n",
    "print(f\"Output Shape: {EXPECTED_SHAPE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2a971d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output is on the Correct Device: cpu.\n"
     ]
    }
   ],
   "source": [
    "# Output tensor က မှန်ကန်တဲ့ device ပေါ်မှာ ရှိမရှိ စစ်ဆေးခြင်း\n",
    "# သင့် code က global 'device' variable ကို သုံးထားတဲ့အတွက်၊ output က 'device' ပေါ်မှာ ရှိရပါမယ်။\n",
    "assert output_features.device == device, \\\n",
    "    f\"Device Error! Expected: {device}, Got: {output_features.device}\"\n",
    "print(f\"✅ Output is on the Correct Device: {device}.\")\n",
    "\n",
    "# (စမ်းသပ်ချက် အပို): CPU ပေါ်က input ဝင်လာရင်တောင် GPU ကို ရွှေ့သွားခြင်း ရှိ/မရှိ စစ်ဆေးပြီးသား ဖြစ်ပါတယ်။"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4957d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transformer output contains NaN or Inf values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NaN/Inf Error Handling is Working (Caught ValueError).\n"
     ]
    }
   ],
   "source": [
    "# NaN တန်ဖိုးပါတဲ့ input ကို ဖန်တီးခြင်း\n",
    "nan_observations = torch.full((BATCH_SIZE, SEQ_LEN, INPUT_SIZE), float('nan'))\n",
    "nan_observations[0, 0, 0] = 1.0 # NaN မဟုတ်တဲ့ တန်ဖိုးတစ်ခု ထည့်ကြည့်\n",
    "\n",
    "try:\n",
    "    extractor(nan_observations)\n",
    "except ValueError as e:\n",
    "    # NaN ပါရင် ValueError ထွက်လာရမယ်။\n",
    "    assert \"NaN or Inf values\" in str(e) or \"Invalid values\" in str(e)\n",
    "    print(\"✅ NaN/Inf Error Handling is Working (Caught ValueError).\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Unexpected Error Type: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89e7f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PPO Agent Successfully Trained with Custom Extractor on cpu.\n"
     ]
    }
   ],
   "source": [
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "\n",
    "# 1. Custom Environment (Env) ကို တည်ဆောက်ခြင်း\n",
    "# ဒါက test အတွက် အလွယ်ဆုံး environment ပုံစံ ဖြစ်ပါတယ်။\n",
    "class DummyTimeEnv(gym.Env):\n",
    "    def __init__(self, seq_len, input_size):\n",
    "        super().__init__()\n",
    "        # Observation space ကို CustomCombinedExtractor မျှော်မှန်းထားတဲ့အတိုင်း သတ်မှတ်\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf, \n",
    "            shape=(seq_len, input_size), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "        self.action_space = spaces.Discrete(3) # Buy, Sell, Hold\n",
    "        self.state = np.zeros((seq_len, input_size), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        # State ကို random အနေနဲ့ အနည်းငယ် ပြောင်းလဲ\n",
    "        self.state = np.roll(self.state, -1, axis=0) \n",
    "        self.state[-1] = np.random.randn(self.observation_space.shape[1]).astype(np.float32)\n",
    "        reward = 0.0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        return self.state, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.state = np.random.randn(*self.observation_space.shape).astype(np.float32)\n",
    "        info = {}\n",
    "        return self.state, info\n",
    "    \n",
    "# 2. Environment နှင့် Agent ကို တည်ဆောက်ခြင်း\n",
    "env = DummyTimeEnv(SEQ_LEN, INPUT_SIZE)\n",
    "\n",
    "try:\n",
    "    # PPO Agent ကို Custom Extractor နဲ့ သတ်မှတ်ပြီး GPU ပေါ်မှာ train ဖို့ စမ်းသပ်\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\", \n",
    "        env, \n",
    "        policy_kwargs=dict(\n",
    "            features_extractor_class=CustomCombinedExtractor, \n",
    "            features_extractor_kwargs=dict(sequence_length=SEQ_LEN)\n",
    "        ),\n",
    "        verbose=0,\n",
    "        device=device # Agent ကို သတ်မှတ်ထားတဲ့ device (GPU/CPU) ပေါ်မှာ ထားဖို့\n",
    "    )\n",
    "    \n",
    "    # 3. Agent ကို အတိုချုံး Train လုပ်ခြင်း (Test အောင်မြင်ကြောင်း သေချာစေရန်)\n",
    "    model.learn(total_timesteps=100)\n",
    "    print(f\"✅ PPO Agent Successfully Trained with Custom Extractor on {device}.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ PPO Integration Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57914339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
